{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import transforms\n",
    "from torchdrug import data, core, layers, tasks, metrics, utils, models\n",
    "from torchdrug.layers import functional\n",
    "from torchdrug.core import Registry as R\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "from torch.nn import functional as F\n",
    "from lib.tasks import NodePropertyPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_read_file() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m protein_view_transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mProteinView(view\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresidue\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([truncuate_transform, protein_view_transform])\n\u001b[0;32m----> 7\u001b[0m dataset \u001b[39m=\u001b[39m ATPBind(atom_feature\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, bond_feature\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m      8\u001b[0m                   residue_feature\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdefault\u001b[39;49m\u001b[39m\"\u001b[39;49m, transform\u001b[39m=\u001b[39;49mtransform)\n\u001b[1;32m     10\u001b[0m train_set, valid_set, test_set \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39msplit()\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain samples: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, valid samples: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m, test samples: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m     12\u001b[0m       (\u001b[39mlen\u001b[39m(train_set), \u001b[39mlen\u001b[39m(valid_set), \u001b[39mlen\u001b[39m(test_set)))\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39;49m(extras \u001b[39m+\u001b[39;49m args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/core/core.py:288\u001b[0m, in \u001b[0;36m_Configurable.__new__.<locals>.wrapper\u001b[0;34m(init, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m     config\u001b[39m.\u001b[39mpop(k)\n\u001b[1;32m    287\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(config)\n\u001b[0;32m--> 288\u001b[0m \u001b[39mreturn\u001b[39;00m init(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/atpbind/lib/datasets.py:16\u001b[0m, in \u001b[0;36mATPBind.__init__\u001b[0;34m(self, path, with_pdb, verbose, valid_ratio, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalid_ratio \u001b[39m=\u001b[39m valid_ratio\n\u001b[0;32m---> 16\u001b[0m sequences, targets \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_seq_target(path)\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_sequence(sequences, targets, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/atpbind/lib/datasets.py:46\u001b[0m, in \u001b[0;36mATPBind.get_seq_target\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     43\u001b[0m sequences, targets, pdb_ids \u001b[39m=\u001b[39m [], [], []\n\u001b[1;32m     45\u001b[0m \u001b[39mfor\u001b[39;00m file_name \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mtrain.txt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtest.txt\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m---> 46\u001b[0m     num_samples, seq, tar, pdb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_file(\n\u001b[1;32m     47\u001b[0m         os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, file_name)\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples\u001b[39m.\u001b[39mappend(num_samples)\n\u001b[1;32m     50\u001b[0m     sequences \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m seq\n",
      "\u001b[0;31mTypeError\u001b[0m: _read_file() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "from lib.datasets import ATPBind\n",
    "\n",
    "truncuate_transform = transforms.TruncateProtein(max_length=350, random=False)\n",
    "protein_view_transform = transforms.ProteinView(view='residue')\n",
    "transform = transforms.Compose([truncuate_transform, protein_view_transform])\n",
    "\n",
    "dataset = ATPBind(atom_feature=None, bond_feature=None,\n",
    "                  residue_feature=\"default\", transform=transform)\n",
    "\n",
    "train_set, valid_set, test_set = dataset.split()\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" %\n",
    "      (len(train_set), len(valid_set), len(test_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze_bert in https://github.com/aws-samples/lm-gvp/blob/0b7a6d96486e2ee222929917570432296554cfe7/lmgvp/modules.py#L47\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "def _freeze_bert(\n",
    "    bert_model: BertModel, freeze_bert=True, freeze_layer_count=-1\n",
    "):\n",
    "    \"\"\"Freeze parameters in BertModel (in place)\n",
    "\n",
    "    Args:\n",
    "        bert_model: HuggingFace bert model\n",
    "        freeze_bert: Bool whether or not to freeze the bert model\n",
    "        freeze_layer_count: If freeze_bert, up to what layer to freeze.\n",
    "\n",
    "    Returns:\n",
    "        bert_model\n",
    "    \"\"\"\n",
    "    if freeze_bert:\n",
    "        # freeze the entire bert model\n",
    "        for param in bert_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        # freeze the embeddings\n",
    "        for param in bert_model.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "        if freeze_layer_count != -1:\n",
    "            # freeze layers in bert_model.encoder\n",
    "            for layer in bert_model.encoder.layer[:freeze_layer_count]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cusom model Wrapping BERT: check https://torchdrug.ai/docs/notes/model.html\n",
    "class BertWrapModel(torch.nn.Module, core.Configurable):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(\n",
    "            \"Rostlab/prot_bert\", do_lower_case=False)\n",
    "        self.bert_model = BertModel.from_pretrained(\n",
    "            \"Rostlab/prot_bert\").to('cuda')\n",
    "        _freeze_bert(self.bert_model, freeze_bert=True, freeze_layer_count=-1)\n",
    "        self.input_dim = 21\n",
    "        self.output_dim = self.bert_model.config.hidden_size\n",
    "\n",
    "    def forward(self, graph, _, all_loss=None, metric=None):\n",
    "        # print(\"graph: \", graph)\n",
    "        # print(\"sequence: \", graph.to_sequence())\n",
    "        input = [seq.replace('.', ' ') for seq in graph.to_sequence()]\n",
    "\n",
    "        encoded_input = self.bert_tokenizer(\n",
    "            input, return_tensors='pt').to('cuda')\n",
    "        # print(\"Input size: \", encoded_input[\"input_ids\"].size())\n",
    "        x = self.bert_model(**encoded_input)\n",
    "        # print(\"Output size just after model: \", x.last_hidden_state.size())\n",
    "        \n",
    "        # skip residue feature for [CLS] and [SEP], since they are not in the original sequence\n",
    "        return {\"residue_feature\": torch.squeeze(x.last_hidden_state)[1:-1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:50:54   Preprocess training set\n",
      "14:50:54   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 1000,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'NodePropertyPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'metric': ('micro_auroc',\n",
      "                     'micro_auprc',\n",
      "                     'macro_auprc',\n",
      "                     'macro_auroc'),\n",
      "          'model': {'class': 'BertWrapModel'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'ATPBind',\n",
      "                          'path': None,\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fa4e9cc7ee0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7fa4e9cc75b0>]},\n",
      "                          'valid_ratio': 0.1,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(388, 429)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fa4e9cc7ee0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fa4e9cc75b0>]},\n",
      "                           'valid_ratio': 0.1,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 346)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fa4e9cc7ee0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fa4e9cc75b0>]},\n",
      "                           'valid_ratio': 0.1,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(346, 388)}}\n"
     ]
    }
   ],
   "source": [
    "bert_wrap_model = BertWrapModel()\n",
    "bert_task = NodePropertyPrediction(\n",
    "    bert_wrap_model, \n",
    "    normalization=False,\n",
    "    num_mlp_layer=2,\n",
    "    metric=(\"micro_auroc\", \"micro_auprc\", \"macro_auprc\", \"macro_auroc\")\n",
    ")\n",
    "optimizer = torch.optim.Adam(bert_task.parameters(), lr=1e-3)\n",
    "solver = core.Engine(bert_task, train_set, valid_set, test_set, optimizer, batch_size=1, log_interval=1000, gpus=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:51:01   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:51:01   Epoch 0 begin\n",
      "14:51:01   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:51:01   binary cross entropy: 0.690417\n",
      "14:51:22   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:51:22   Epoch 0 end\n",
      "14:51:22   duration: 28.34 secs\n",
      "14:51:22   speed: 12.21 batch / sec\n",
      "14:51:22   ETA: 8.97 mins\n",
      "14:51:22   max GPU memory: 9838.2 MiB\n",
      "14:51:22   ------------------------------\n",
      "14:51:22   average binary cross entropy: 0.177362\n",
      "14:51:22   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:51:22   Epoch 1 begin\n",
      "14:51:44   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:51:44   Epoch 1 end\n",
      "14:51:44   duration: 21.22 secs\n",
      "14:51:44   speed: 16.30 batch / sec\n",
      "14:51:44   ETA: 7.43 mins\n",
      "14:51:44   max GPU memory: 9838.2 MiB\n",
      "14:51:44   ------------------------------\n",
      "14:51:44   average binary cross entropy: 0.147952\n",
      "14:51:44   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:51:44   Epoch 2 begin\n",
      "14:52:02   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:52:02   binary cross entropy: 0.192765\n",
      "14:52:05   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:52:05   Epoch 2 end\n",
      "14:52:05   duration: 21.24 secs\n",
      "14:52:05   speed: 16.29 batch / sec\n",
      "14:52:05   ETA: 6.69 mins\n",
      "14:52:05   max GPU memory: 9838.2 MiB\n",
      "14:52:05   ------------------------------\n",
      "14:52:05   average binary cross entropy: 0.138363\n",
      "14:52:05   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:52:05   Epoch 3 begin\n",
      "14:52:26   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:52:26   Epoch 3 end\n",
      "14:52:26   duration: 21.32 secs\n",
      "14:52:26   speed: 16.23 batch / sec\n",
      "14:52:26   ETA: 6.14 mins\n",
      "14:52:26   max GPU memory: 9838.2 MiB\n",
      "14:52:26   ------------------------------\n",
      "14:52:26   average binary cross entropy: 0.128855\n",
      "14:52:26   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:52:26   Epoch 4 begin\n",
      "14:52:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:52:47   Epoch 4 end\n",
      "14:52:47   duration: 20.92 secs\n",
      "14:52:47   speed: 16.54 batch / sec\n",
      "14:52:47   ETA: 5.65 mins\n",
      "14:52:47   max GPU memory: 9838.2 MiB\n",
      "14:52:47   ------------------------------\n",
      "14:52:47   average binary cross entropy: 0.117088\n",
      "14:52:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:52:47   Epoch 5 begin\n",
      "14:53:03   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:53:03   binary cross entropy: 0.0604851\n",
      "14:53:08   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:53:08   Epoch 5 end\n",
      "14:53:08   duration: 20.85 secs\n",
      "14:53:08   speed: 16.59 batch / sec\n",
      "14:53:08   ETA: 5.21 mins\n",
      "14:53:08   max GPU memory: 9838.2 MiB\n",
      "14:53:08   ------------------------------\n",
      "14:53:08   average binary cross entropy: 0.102169\n",
      "14:53:08   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:53:08   Epoch 6 begin\n",
      "14:53:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:53:29   Epoch 6 end\n",
      "14:53:29   duration: 20.88 secs\n",
      "14:53:29   speed: 16.57 batch / sec\n",
      "14:53:29   ETA: 4.79 mins\n",
      "14:53:29   max GPU memory: 9838.2 MiB\n",
      "14:53:29   ------------------------------\n",
      "14:53:29   average binary cross entropy: 0.0881799\n",
      "14:53:29   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:53:29   Epoch 7 begin\n",
      "14:53:50   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:53:50   Epoch 7 end\n",
      "14:53:50   duration: 20.85 secs\n",
      "14:53:50   speed: 16.59 batch / sec\n",
      "14:53:50   ETA: 4.39 mins\n",
      "14:53:50   max GPU memory: 9838.2 MiB\n",
      "14:53:50   ------------------------------\n",
      "14:53:50   average binary cross entropy: 0.0707078\n",
      "14:53:50   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:53:50   Epoch 8 begin\n",
      "14:54:04   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:54:04   binary cross entropy: 0.0458535\n",
      "14:54:10   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:54:10   Epoch 8 end\n",
      "14:54:10   duration: 20.85 secs\n",
      "14:54:10   speed: 16.60 batch / sec\n",
      "14:54:10   ETA: 4.00 mins\n",
      "14:54:10   max GPU memory: 9838.2 MiB\n",
      "14:54:10   ------------------------------\n",
      "14:54:10   average binary cross entropy: 0.0585179\n",
      "14:54:10   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:54:10   Epoch 9 begin\n",
      "14:54:31   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:54:31   Epoch 9 end\n",
      "14:54:31   duration: 20.84 secs\n",
      "14:54:31   speed: 16.60 batch / sec\n",
      "14:54:31   ETA: 3.62 mins\n",
      "14:54:31   max GPU memory: 9838.2 MiB\n",
      "14:54:31   ------------------------------\n",
      "14:54:31   average binary cross entropy: 0.0435468\n",
      "14:54:31   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:54:31   Epoch 10 begin\n",
      "14:54:52   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:54:52   Epoch 10 end\n",
      "14:54:52   duration: 20.89 secs\n",
      "14:54:52   speed: 16.56 batch / sec\n",
      "14:54:52   ETA: 3.25 mins\n",
      "14:54:52   max GPU memory: 9838.2 MiB\n",
      "14:54:52   ------------------------------\n",
      "14:54:52   average binary cross entropy: 0.0345904\n",
      "14:54:52   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:54:52   Epoch 11 begin\n",
      "14:55:04   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:55:04   binary cross entropy: 0.0373256\n",
      "14:55:13   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:55:13   Epoch 11 end\n",
      "14:55:13   duration: 20.83 secs\n",
      "14:55:13   speed: 16.61 batch / sec\n",
      "14:55:13   ETA: 2.88 mins\n",
      "14:55:13   max GPU memory: 9838.2 MiB\n",
      "14:55:13   ------------------------------\n",
      "14:55:13   average binary cross entropy: 0.0311507\n",
      "14:55:13   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:55:13   Epoch 12 begin\n",
      "14:55:34   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:55:34   Epoch 12 end\n",
      "14:55:34   duration: 20.85 secs\n",
      "14:55:34   speed: 16.60 batch / sec\n",
      "14:55:34   ETA: 2.51 mins\n",
      "14:55:34   max GPU memory: 9838.2 MiB\n",
      "14:55:34   ------------------------------\n",
      "14:55:34   average binary cross entropy: 0.0245645\n",
      "14:55:34   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:55:34   Epoch 13 begin\n",
      "14:55:55   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:55:55   Epoch 13 end\n",
      "14:55:55   duration: 20.81 secs\n",
      "14:55:55   speed: 16.62 batch / sec\n",
      "14:55:55   ETA: 2.15 mins\n",
      "14:55:55   max GPU memory: 9838.2 MiB\n",
      "14:55:55   ------------------------------\n",
      "14:55:55   average binary cross entropy: 0.0251959\n",
      "14:55:55   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:55:55   Epoch 14 begin\n",
      "14:56:04   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:56:04   binary cross entropy: 0.00415622\n",
      "14:56:15   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:56:15   Epoch 14 end\n",
      "14:56:15   duration: 20.83 secs\n",
      "14:56:15   speed: 16.61 batch / sec\n",
      "14:56:15   ETA: 1.79 mins\n",
      "14:56:15   max GPU memory: 9838.2 MiB\n",
      "14:56:15   ------------------------------\n",
      "14:56:15   average binary cross entropy: 0.0138398\n",
      "14:56:15   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:56:15   Epoch 15 begin\n",
      "14:56:36   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:56:36   Epoch 15 end\n",
      "14:56:36   duration: 20.81 secs\n",
      "14:56:36   speed: 16.62 batch / sec\n",
      "14:56:36   ETA: 1.43 mins\n",
      "14:56:36   max GPU memory: 9838.2 MiB\n",
      "14:56:36   ------------------------------\n",
      "14:56:36   average binary cross entropy: 0.0100652\n",
      "14:56:36   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:56:36   Epoch 16 begin\n",
      "14:56:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:56:57   Epoch 16 end\n",
      "14:56:57   duration: 20.81 secs\n",
      "14:56:57   speed: 16.63 batch / sec\n",
      "14:56:57   ETA: 1.07 mins\n",
      "14:56:57   max GPU memory: 9838.2 MiB\n",
      "14:56:57   ------------------------------\n",
      "14:56:57   average binary cross entropy: 0.0100388\n",
      "14:56:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:56:57   Epoch 17 begin\n",
      "14:57:04   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:57:04   binary cross entropy: 0.000998659\n",
      "14:57:18   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:57:18   Epoch 17 end\n",
      "14:57:18   duration: 20.81 secs\n",
      "14:57:18   speed: 16.63 batch / sec\n",
      "14:57:18   ETA: 42.66 secs\n",
      "14:57:18   max GPU memory: 9838.2 MiB\n",
      "14:57:18   ------------------------------\n",
      "14:57:18   average binary cross entropy: 0.00724824\n",
      "14:57:18   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:57:18   Epoch 18 begin\n",
      "14:57:39   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:57:39   Epoch 18 end\n",
      "14:57:39   duration: 20.81 secs\n",
      "14:57:39   speed: 16.63 batch / sec\n",
      "14:57:39   ETA: 21.30 secs\n",
      "14:57:39   max GPU memory: 9838.2 MiB\n",
      "14:57:39   ------------------------------\n",
      "14:57:39   average binary cross entropy: 0.0103071\n",
      "14:57:39   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:57:39   Epoch 19 begin\n",
      "14:58:00   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:58:00   Epoch 19 end\n",
      "14:58:00   duration: 20.81 secs\n",
      "14:58:00   speed: 16.63 batch / sec\n",
      "14:58:00   ETA: 0.00 secs\n",
      "14:58:00   max GPU memory: 9838.2 MiB\n",
      "14:58:00   ------------------------------\n",
      "14:58:00   average binary cross entropy: 0.00779561\n",
      "14:58:00   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:58:00   Evaluate on valid\n",
      "14:58:02   ------------------------------\n",
      "14:58:02   macro_auprc: 0.413807\n",
      "14:58:02   macro_auroc: 0.844634\n",
      "14:58:02   micro_auprc: 0.439233\n",
      "14:58:02   micro_auroc: 0.856541\n",
      "14:58:02   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "14:58:02   Evaluate on test\n",
      "14:58:04   ------------------------------\n",
      "14:58:04   macro_auprc: 0.440768\n",
      "14:58:04   macro_auroc: 0.814328\n",
      "14:58:04   micro_auprc: 0.398867\n",
      "14:58:04   micro_auroc: 0.835859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'micro_auroc': tensor(0.8359, device='cuda:0'),\n",
       " 'micro_auprc': tensor(0.3989, device='cuda:0'),\n",
       " 'macro_auprc': tensor(0.4408, device='cuda:0'),\n",
       " 'macro_auroc': tensor(0.8143, device='cuda:0')}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.train(num_epoch=20)\n",
    "solver.evaluate(\"valid\")\n",
    "solver.evaluate(\"test\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc",
   "language": "python",
   "name": "jc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
