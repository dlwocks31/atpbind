{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get dataset atpbind3d\n",
      "Split num:  [337, 41, 41]\n",
      "train samples: 337, valid samples: 41, test samples: 41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from lib.pipeline import Pipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "GPU = 1\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    model='lm-gearnet',\n",
    "    dataset='atpbind3d',\n",
    "    gpus=[GPU],\n",
    "    model_kwargs={\n",
    "        'gpu': GPU,\n",
    "        'gearnet_hidden_dim_size': 512,\n",
    "        'gearnet_hidden_dim_count': 4,\n",
    "        'bert_freeze': False,\n",
    "        'bert_freeze_layer_count': 28,\n",
    "    },\n",
    "    optimizer_kwargs={\n",
    "        'lr': 2e-4,\n",
    "        'weight_decay': 0.0001,\n",
    "    },\n",
    "    task_kwargs={\n",
    "        'use_rus': True,\n",
    "        'rus_seed': 0,\n",
    "        'undersample_rate': 0.05,\n",
    "    },\n",
    "    batch_size=8,\n",
    "    optimizer=\"adamw\",\n",
    ")\n",
    "state_dict = torch.load('ResidueType_lmg_4_512_0.57268.pth',\n",
    "                        map_location=f'cuda:{GPU}')\n",
    "pipeline.model.gearnet.load_state_dict(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialLR(torch.optim.lr_scheduler._LRScheduler):\n",
    "    \"\"\"Decays the learning rate of each parameter group by gamma every epoch.\n",
    "    When last_epoch=-1, sets initial lr as lr.\n",
    "\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        gamma (float): Multiplicative factor of learning rate decay.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "        verbose (bool): If ``True``, prints a message to stdout for\n",
    "            each update. Default: ``False``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, gamma, last_epoch=-1, verbose=False):\n",
    "        self.gamma = gamma\n",
    "        super(ExponentialLR, self).__init__(optimizer, last_epoch, verbose)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
    "                          \"please use `get_last_lr()`.\", UserWarning)\n",
    "\n",
    "        if self.last_epoch == 0:\n",
    "            return [group['lr'] for group in self.optimizer.param_groups]\n",
    "        return [group['lr'] * self.gamma\n",
    "                for group in self.optimizer.param_groups]\n",
    "\n",
    "    def _get_closed_form_lr(self):\n",
    "        return [base_lr * self.gamma ** self.last_epoch\n",
    "                for base_lr in self.base_lrs]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.solver.scheduler = ExponentialLR(\n",
    "    gamma=0.925, # 9번 돌리면 0.5배로 줄어듬\n",
    "    optimizer=pipeline.solver.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensitivity': 0.8915, 'specificity': 0.7183, 'accuracy': 0.7272, 'precision': 0.1474, 'mcc': 0.2913, 'micro_auroc': 0.9078, 'train_bce': 0.0419, 'valid_bce': 0.0314, 'valid_mcc': 0.3499}\n",
      "{'sensitivity': 0.8453, 'specificity': 0.8469, 'accuracy': 0.8469, 'precision': 0.2317, 'mcc': 0.3919, 'micro_auroc': 0.9262, 'train_bce': 0.0263, 'valid_bce': 0.029, 'valid_mcc': 0.413}\n",
      "{'sensitivity': 0.7002, 'specificity': 0.9172, 'accuracy': 0.906, 'precision': 0.3161, 'mcc': 0.4293, 'micro_auroc': 0.9217, 'train_bce': 0.0209, 'valid_bce': 0.0291, 'valid_mcc': 0.5106}\n",
      "{'sensitivity': 0.8006, 'specificity': 0.886, 'accuracy': 0.8815, 'precision': 0.2772, 'mcc': 0.4266, 'micro_auroc': 0.9195, 'train_bce': 0.0157, 'valid_bce': 0.0255, 'valid_mcc': 0.473}\n",
      "{'sensitivity': 0.5439, 'specificity': 0.9788, 'accuracy': 0.9563, 'precision': 0.5839, 'mcc': 0.5406, 'micro_auroc': 0.9136, 'train_bce': 0.0112, 'valid_bce': 0.0513, 'valid_mcc': 0.55}\n",
      "{'sensitivity': 0.5805, 'specificity': 0.9575, 'accuracy': 0.938, 'precision': 0.4272, 'mcc': 0.4661, 'micro_auroc': 0.9053, 'train_bce': 0.0076, 'valid_bce': 0.0446, 'valid_mcc': 0.5186}\n",
      "{'sensitivity': 0.5933, 'specificity': 0.9667, 'accuracy': 0.9474, 'precision': 0.4934, 'mcc': 0.5135, 'micro_auroc': 0.9146, 'train_bce': 0.0069, 'valid_bce': 0.044, 'valid_mcc': 0.5515}\n",
      "{'sensitivity': 0.6571, 'specificity': 0.9446, 'accuracy': 0.9297, 'precision': 0.3931, 'mcc': 0.4742, 'micro_auroc': 0.9178, 'train_bce': 0.005, 'valid_bce': 0.0431, 'valid_mcc': 0.5612}\n",
      "{'sensitivity': 0.6204, 'specificity': 0.974, 'accuracy': 0.9556, 'precision': 0.5654, 'mcc': 0.5689, 'micro_auroc': 0.9145, 'train_bce': 0.0038, 'valid_bce': 0.0515, 'valid_mcc': 0.582}\n",
      "{'sensitivity': 0.4625, 'specificity': 0.989, 'accuracy': 0.9618, 'precision': 0.6971, 'mcc': 0.5493, 'micro_auroc': 0.8999, 'train_bce': 0.0034, 'valid_bce': 0.0877, 'valid_mcc': 0.5728}\n",
      "{'sensitivity': 0.5199, 'specificity': 0.9843, 'accuracy': 0.9603, 'precision': 0.6443, 'mcc': 0.5584, 'micro_auroc': 0.9064, 'train_bce': 0.0033, 'valid_bce': 0.0701, 'valid_mcc': 0.5938}\n",
      "{'sensitivity': 0.5008, 'specificity': 0.9763, 'accuracy': 0.9517, 'precision': 0.5358, 'mcc': 0.4926, 'micro_auroc': 0.8997, 'train_bce': 0.003, 'valid_bce': 0.0739, 'valid_mcc': 0.5684}\n",
      "{'sensitivity': 0.4561, 'specificity': 0.9925, 'accuracy': 0.9647, 'precision': 0.7688, 'mcc': 0.5761, 'micro_auroc': 0.9051, 'train_bce': 0.0139, 'valid_bce': 0.1073, 'valid_mcc': 0.5894}\n",
      "{'sensitivity': 0.6061, 'specificity': 0.9727, 'accuracy': 0.9537, 'precision': 0.5483, 'mcc': 0.5521, 'micro_auroc': 0.9022, 'train_bce': 0.0058, 'valid_bce': 0.0551, 'valid_mcc': 0.5543}\n",
      "{'sensitivity': 0.5726, 'specificity': 0.9675, 'accuracy': 0.9471, 'precision': 0.4904, 'mcc': 0.5021, 'micro_auroc': 0.899, 'train_bce': 0.0034, 'valid_bce': 0.0652, 'valid_mcc': 0.5373}\n",
      "{'sensitivity': 0.547, 'specificity': 0.9832, 'accuracy': 0.9606, 'precision': 0.6399, 'mcc': 0.5712, 'micro_auroc': 0.9015, 'train_bce': 0.0023, 'valid_bce': 0.0692, 'valid_mcc': 0.5761}\n",
      "{'sensitivity': 0.5295, 'specificity': 0.9839, 'accuracy': 0.9604, 'precision': 0.6422, 'mcc': 0.5627, 'micro_auroc': 0.8912, 'train_bce': 0.0017, 'valid_bce': 0.0722, 'valid_mcc': 0.5854}\n",
      "{'sensitivity': 0.512, 'specificity': 0.9867, 'accuracy': 0.9621, 'precision': 0.6772, 'mcc': 0.5697, 'micro_auroc': 0.8868, 'train_bce': 0.0014, 'valid_bce': 0.0772, 'valid_mcc': 0.5862}\n",
      "{'sensitivity': 0.496, 'specificity': 0.9895, 'accuracy': 0.9639, 'precision': 0.7199, 'mcc': 0.58, 'micro_auroc': 0.8904, 'train_bce': 0.0015, 'valid_bce': 0.0855, 'valid_mcc': 0.5864}\n",
      "{'sensitivity': 0.4593, 'specificity': 0.9916, 'accuracy': 0.9641, 'precision': 0.75, 'mcc': 0.5702, 'micro_auroc': 0.8801, 'train_bce': 0.0014, 'valid_bce': 0.0949, 'valid_mcc': 0.5843}\n",
      "{'sensitivity': 0.4976, 'specificity': 0.989, 'accuracy': 0.9636, 'precision': 0.7123, 'mcc': 0.5775, 'micro_auroc': 0.882, 'train_bce': 0.0012, 'valid_bce': 0.0861, 'valid_mcc': 0.588}\n",
      "{'sensitivity': 0.4625, 'specificity': 0.991, 'accuracy': 0.9637, 'precision': 0.7379, 'mcc': 0.5671, 'micro_auroc': 0.8825, 'train_bce': 0.0011, 'valid_bce': 0.0944, 'valid_mcc': 0.5864}\n",
      "{'sensitivity': 0.4753, 'specificity': 0.9915, 'accuracy': 0.9647, 'precision': 0.7525, 'mcc': 0.5815, 'micro_auroc': 0.8845, 'train_bce': 0.0007, 'valid_bce': 0.094, 'valid_mcc': 0.598}\n",
      "{'sensitivity': 0.4577, 'specificity': 0.9917, 'accuracy': 0.9641, 'precision': 0.7513, 'mcc': 0.5698, 'micro_auroc': 0.8807, 'train_bce': 0.001, 'valid_bce': 0.0961, 'valid_mcc': 0.5852}\n",
      "{'sensitivity': 0.4482, 'specificity': 0.9924, 'accuracy': 0.9642, 'precision': 0.7636, 'mcc': 0.5687, 'micro_auroc': 0.8781, 'train_bce': 0.0007, 'valid_bce': 0.0996, 'valid_mcc': 0.5839}\n",
      "{'sensitivity': 0.4896, 'specificity': 0.9905, 'accuracy': 0.9646, 'precision': 0.738, 'mcc': 0.5841, 'micro_auroc': 0.8835, 'train_bce': 0.0006, 'valid_bce': 0.0914, 'valid_mcc': 0.5935}\n",
      "{'sensitivity': 0.4577, 'specificity': 0.9923, 'accuracy': 0.9646, 'precision': 0.7653, 'mcc': 0.5757, 'micro_auroc': 0.8752, 'train_bce': 0.0007, 'valid_bce': 0.1021, 'valid_mcc': 0.5777}\n",
      "{'sensitivity': 0.4482, 'specificity': 0.9932, 'accuracy': 0.965, 'precision': 0.7827, 'mcc': 0.5766, 'micro_auroc': 0.8756, 'train_bce': 0.0007, 'valid_bce': 0.1042, 'valid_mcc': 0.5868}\n",
      "{'sensitivity': 0.4561, 'specificity': 0.9919, 'accuracy': 0.9642, 'precision': 0.7546, 'mcc': 0.5701, 'micro_auroc': 0.8744, 'train_bce': 0.0006, 'valid_bce': 0.1017, 'valid_mcc': 0.5895}\n",
      "{'sensitivity': 0.4561, 'specificity': 0.9924, 'accuracy': 0.9646, 'precision': 0.7668, 'mcc': 0.5752, 'micro_auroc': 0.8783, 'train_bce': 0.0008, 'valid_bce': 0.1012, 'valid_mcc': 0.59}\n",
      "{'sensitivity': 0.4035, 'specificity': 0.9944, 'accuracy': 0.9638, 'precision': 0.7981, 'mcc': 0.5522, 'micro_auroc': 0.8679, 'train_bce': 0.0007, 'valid_bce': 0.1147, 'valid_mcc': 0.5853}\n",
      "{'sensitivity': 0.4466, 'specificity': 0.9932, 'accuracy': 0.9649, 'precision': 0.7821, 'mcc': 0.5753, 'micro_auroc': 0.8734, 'train_bce': 0.0005, 'valid_bce': 0.1067, 'valid_mcc': 0.5903}\n",
      "{'sensitivity': 0.4466, 'specificity': 0.9922, 'accuracy': 0.964, 'precision': 0.7588, 'mcc': 0.5657, 'micro_auroc': 0.8709, 'train_bce': 0.0005, 'valid_bce': 0.1087, 'valid_mcc': 0.5876}\n",
      "{'sensitivity': 0.4434, 'specificity': 0.9929, 'accuracy': 0.9644, 'precision': 0.7722, 'mcc': 0.5691, 'micro_auroc': 0.8708, 'train_bce': 0.0005, 'valid_bce': 0.1078, 'valid_mcc': 0.5853}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipeline\u001b[39m.\u001b[39;49mtrain_until_fit(\n\u001b[1;32m      2\u001b[0m     patience\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m )\n",
      "File \u001b[0;32m~/atpbind/lib/pipeline.py:181\u001b[0m, in \u001b[0;36mPipeline.train_until_fit\u001b[0;34m(self, patience, early_stop_metric, return_state_dict)\u001b[0m\n\u001b[1;32m    179\u001b[0m cm \u001b[39m=\u001b[39m contextlib\u001b[39m.\u001b[39mnullcontext() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39melse\u001b[39;00m DisableLogger()\n\u001b[1;32m    180\u001b[0m \u001b[39mwith\u001b[39;00m cm:\n\u001b[0;32m--> 181\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(num_epoch\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    182\u001b[0m     cur_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate()\n\u001b[1;32m    183\u001b[0m     cur_result[\u001b[39m'\u001b[39m\u001b[39mtrain_bce\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_last_bce()\n",
      "File \u001b[0;32m~/atpbind/lib/pipeline.py:168\u001b[0m, in \u001b[0;36mPipeline.train\u001b[0;34m(self, num_epoch)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, num_epoch):\n\u001b[0;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msolver\u001b[39m.\u001b[39;49mtrain(num_epoch\u001b[39m=\u001b[39;49mnum_epoch)\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/core/engine.py:155\u001b[0m, in \u001b[0;36mEngine.train\u001b[0;34m(self, num_epoch, batch_per_epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    153\u001b[0m     batch \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcuda(batch, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 155\u001b[0m loss, metric \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loss\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLoss doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt require grad. Did you define any loss in the task?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/atpbind/lib/tasks.py:100\u001b[0m, in \u001b[0;36mNodePropertyPrediction.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     97\u001b[0m all_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m metric \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 100\u001b[0m pred, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_and_target(batch, all_loss, metric)\n\u001b[1;32m    101\u001b[0m labeled \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mtorch\u001b[39m.\u001b[39misnan(target[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m&\u001b[39m target[\u001b[39m\"\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    103\u001b[0m \u001b[39mfor\u001b[39;00m criterion, weight \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/tasks/task.py:30\u001b[0m, in \u001b[0;36mTask.predict_and_target\u001b[0;34m(self, batch, all_loss, metric)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_and_target\u001b[39m(\u001b[39mself\u001b[39m, batch, all_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, metric\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(batch, all_loss, metric), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget(batch)\n",
      "File \u001b[0;32m~/atpbind/lib/tasks.py:77\u001b[0m, in \u001b[0;36mNodePropertyPrediction.predict\u001b[0;34m(self, batch, all_loss, metric)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39msparse\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m node_feature\u001b[39m.\u001b[39mtype():\n\u001b[1;32m     76\u001b[0m     node_feature \u001b[39m=\u001b[39m node_feature\u001b[39m.\u001b[39mto_dense()\n\u001b[0;32m---> 77\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(graph, node_feature, all_loss\u001b[39m=\u001b[39;49mall_loss, metric\u001b[39m=\u001b[39;49mmetric)\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mview \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mnode\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39matom\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     79\u001b[0m     output_feature \u001b[39m=\u001b[39m output[\u001b[39m\"\u001b[39m\u001b[39mnode_feature\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/atpbind/lib/custom_models.py:76\u001b[0m, in \u001b[0;36mLMGearNetModel.forward\u001b[0;34m(self, graph, _, all_loss, metric)\u001b[0m\n\u001b[1;32m     73\u001b[0m input_len \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(seq\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m \u001b[39minput\u001b[39m]\n\u001b[1;32m     75\u001b[0m \u001b[39m# At large batch size, tokenization becomes the bottleneck\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m encoded_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbert_tokenizer(\n\u001b[1;32m     77\u001b[0m     \u001b[39minput\u001b[39;49m, return_tensors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mpt\u001b[39;49m\u001b[39m'\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     78\u001b[0m embedding_rpr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbert_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mencoded_input)\n\u001b[1;32m     80\u001b[0m lm_residue_feature \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2561\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2559\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2560\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2561\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_one(text\u001b[39m=\u001b[39;49mtext, text_pair\u001b[39m=\u001b[39;49mtext_pair, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mall_kwargs)\n\u001b[1;32m   2562\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2563\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2647\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2642\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2643\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch length of `text`: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text)\u001b[39m}\u001b[39;00m\u001b[39m does not match batch length of `text_pair`:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2644\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(text_pair)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2645\u001b[0m         )\n\u001b[1;32m   2646\u001b[0m     batch_text_or_text_pairs \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(text, text_pair)) \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m text\n\u001b[0;32m-> 2647\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_encode_plus(\n\u001b[1;32m   2648\u001b[0m         batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2649\u001b[0m         add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2650\u001b[0m         padding\u001b[39m=\u001b[39;49mpadding,\n\u001b[1;32m   2651\u001b[0m         truncation\u001b[39m=\u001b[39;49mtruncation,\n\u001b[1;32m   2652\u001b[0m         max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2653\u001b[0m         stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2654\u001b[0m         is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2655\u001b[0m         pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2656\u001b[0m         return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2657\u001b[0m         return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2658\u001b[0m         return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2659\u001b[0m         return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2660\u001b[0m         return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2661\u001b[0m         return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2662\u001b[0m         return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2663\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2664\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2665\u001b[0m     )\n\u001b[1;32m   2666\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2667\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_plus(\n\u001b[1;32m   2668\u001b[0m         text\u001b[39m=\u001b[39mtext,\n\u001b[1;32m   2669\u001b[0m         text_pair\u001b[39m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2685\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2686\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2838\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2828\u001b[0m \u001b[39m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2829\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2830\u001b[0m     padding\u001b[39m=\u001b[39mpadding,\n\u001b[1;32m   2831\u001b[0m     truncation\u001b[39m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2835\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   2836\u001b[0m )\n\u001b[0;32m-> 2838\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_encode_plus(\n\u001b[1;32m   2839\u001b[0m     batch_text_or_text_pairs\u001b[39m=\u001b[39;49mbatch_text_or_text_pairs,\n\u001b[1;32m   2840\u001b[0m     add_special_tokens\u001b[39m=\u001b[39;49madd_special_tokens,\n\u001b[1;32m   2841\u001b[0m     padding_strategy\u001b[39m=\u001b[39;49mpadding_strategy,\n\u001b[1;32m   2842\u001b[0m     truncation_strategy\u001b[39m=\u001b[39;49mtruncation_strategy,\n\u001b[1;32m   2843\u001b[0m     max_length\u001b[39m=\u001b[39;49mmax_length,\n\u001b[1;32m   2844\u001b[0m     stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m   2845\u001b[0m     is_split_into_words\u001b[39m=\u001b[39;49mis_split_into_words,\n\u001b[1;32m   2846\u001b[0m     pad_to_multiple_of\u001b[39m=\u001b[39;49mpad_to_multiple_of,\n\u001b[1;32m   2847\u001b[0m     return_tensors\u001b[39m=\u001b[39;49mreturn_tensors,\n\u001b[1;32m   2848\u001b[0m     return_token_type_ids\u001b[39m=\u001b[39;49mreturn_token_type_ids,\n\u001b[1;32m   2849\u001b[0m     return_attention_mask\u001b[39m=\u001b[39;49mreturn_attention_mask,\n\u001b[1;32m   2850\u001b[0m     return_overflowing_tokens\u001b[39m=\u001b[39;49mreturn_overflowing_tokens,\n\u001b[1;32m   2851\u001b[0m     return_special_tokens_mask\u001b[39m=\u001b[39;49mreturn_special_tokens_mask,\n\u001b[1;32m   2852\u001b[0m     return_offsets_mapping\u001b[39m=\u001b[39;49mreturn_offsets_mapping,\n\u001b[1;32m   2853\u001b[0m     return_length\u001b[39m=\u001b[39;49mreturn_length,\n\u001b[1;32m   2854\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2855\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2856\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/tokenization_utils.py:733\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     ids, pair_ids \u001b[39m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 733\u001b[0m first_ids \u001b[39m=\u001b[39m get_input_ids(ids)\n\u001b[1;32m    734\u001b[0m second_ids \u001b[39m=\u001b[39m get_input_ids(pair_ids) \u001b[39mif\u001b[39;00m pair_ids \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    735\u001b[0m input_ids\u001b[39m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/tokenization_utils.py:700\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_input_ids\u001b[39m(text):\n\u001b[1;32m    699\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 700\u001b[0m         tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize(text, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    701\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    702\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(text) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/tokenization_utils.py:547\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         tokenized_text\u001b[39m.\u001b[39mappend(token)\n\u001b[1;32m    546\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m         tokenized_text\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenize(token))\n\u001b[1;32m    548\u001b[0m \u001b[39m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/models/bert/tokenization_bert.py:244\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    242\u001b[0m split_tokens \u001b[39m=\u001b[39m []\n\u001b[1;32m    243\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_basic_tokenize:\n\u001b[0;32m--> 244\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasic_tokenizer\u001b[39m.\u001b[39;49mtokenize(text, never_split\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mall_special_tokens):\n\u001b[1;32m    245\u001b[0m         \u001b[39m# If the token is part of the never_split set\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         \u001b[39mif\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbasic_tokenizer\u001b[39m.\u001b[39mnever_split:\n\u001b[1;32m    247\u001b[0m             split_tokens\u001b[39m.\u001b[39mappend(token)\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/models/bert/tokenization_bert.py:410\u001b[0m, in \u001b[0;36mBasicTokenizer.tokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[39m# union() returns a new set by concatenating the two sets.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m never_split \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnever_split\u001b[39m.\u001b[39munion(\u001b[39mset\u001b[39m(never_split)) \u001b[39mif\u001b[39;00m never_split \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnever_split\n\u001b[0;32m--> 410\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_clean_text(text)\n\u001b[1;32m    412\u001b[0m \u001b[39m# This was added on November 1st, 2018 for the multilingual and Chinese\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[39m# models. This is also applied to the English models now, but it doesn't\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39m# matter since the English models were not trained on any Chinese data\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39m# and generally don't have any Chinese data in them (there are Chinese\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[39m# characters in the vocabulary because Wikipedia does have some Chinese\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m# words in the English Wikipedia.).\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenize_chinese_chars:\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/models/bert/tokenization_bert.py:512\u001b[0m, in \u001b[0;36mBasicTokenizer._clean_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39mif\u001b[39;00m cp \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m cp \u001b[39m==\u001b[39m \u001b[39m0xFFFD\u001b[39m \u001b[39mor\u001b[39;00m _is_control(char):\n\u001b[1;32m    511\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m \u001b[39mif\u001b[39;00m _is_whitespace(char):\n\u001b[1;32m    513\u001b[0m     output\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    514\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/transformers/tokenization_utils.py:272\u001b[0m, in \u001b[0;36m_is_whitespace\u001b[0;34m(char)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Checks whether `char` is a whitespace character.\"\"\"\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39m# \\t, \\n, and \\r are technically control characters but we treat them\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[39m# as whitespace since they are generally considered as such.\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m \u001b[39mif\u001b[39;00m char \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m char \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39mor\u001b[39;00m char \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m char \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    274\u001b[0m cat \u001b[39m=\u001b[39m unicodedata\u001b[39m.\u001b[39mcategory(char)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline.train_until_fit(\n",
    "    patience=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(lr, gamma):\n",
    "    pipeline = Pipeline(\n",
    "        model='lm-gearnet',\n",
    "        dataset='atpbind3d',\n",
    "        gpus=[GPU],\n",
    "        model_kwargs={\n",
    "            'gpu': GPU,\n",
    "            'gearnet_hidden_dim_size': 512,\n",
    "            'gearnet_hidden_dim_count': 4,\n",
    "            'bert_freeze': False,\n",
    "            'bert_freeze_layer_count': 28,\n",
    "        },\n",
    "        optimizer_kwargs={\n",
    "            'lr': lr,\n",
    "            'weight_decay': 0.0001,\n",
    "        },\n",
    "        task_kwargs={\n",
    "            'use_rus': True,\n",
    "            'rus_seed': 0,\n",
    "            'undersample_rate': 0.05,\n",
    "        },\n",
    "        batch_size=8,\n",
    "        optimizer=\"adamw\",\n",
    "    )\n",
    "    state_dict = torch.load('ResidueType_lmg_4_512_0.57268.pth',\n",
    "                            map_location=f'cuda:{GPU}')\n",
    "    pipeline.model.gearnet.load_state_dict(state_dict)\n",
    "    \n",
    "    pipeline.solver.scheduler = ExponentialLR(\n",
    "        gamma=gamma, \n",
    "        optimizer=pipeline.solver.optimizer\n",
    "    )\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "pipeline = make_pipeline(lr=5e-4, gamma=0.917) # 8번 돌리면 0.5배로 줄어듬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensitivity': 0.8501, 'specificity': 0.8051, 'accuracy': 0.8075, 'precision': 0.1924, 'mcc': 0.3457, 'micro_auroc': 0.9061, 'train_bce': 0.0439, 'valid_bce': 0.0274, 'valid_mcc': 0.3868}\n",
      "{'sensitivity': 0.4577, 'specificity': 0.9793, 'accuracy': 0.9523, 'precision': 0.5467, 'mcc': 0.4755, 'micro_auroc': 0.8979, 'train_bce': 0.0289, 'valid_bce': 0.0505, 'valid_mcc': 0.5193}\n",
      "{'sensitivity': 0.8724, 'specificity': 0.8082, 'accuracy': 0.8115, 'precision': 0.199, 'mcc': 0.36, 'micro_auroc': 0.9253, 'train_bce': 0.0227, 'valid_bce': 0.0281, 'valid_mcc': 0.4118}\n",
      "{'sensitivity': 0.6746, 'specificity': 0.9449, 'accuracy': 0.9309, 'precision': 0.4006, 'mcc': 0.4865, 'micro_auroc': 0.9301, 'train_bce': 0.0209, 'valid_bce': 0.0295, 'valid_mcc': 0.4875}\n",
      "{'sensitivity': 0.7097, 'specificity': 0.9402, 'accuracy': 0.9282, 'precision': 0.3931, 'mcc': 0.4947, 'micro_auroc': 0.9243, 'train_bce': 0.0138, 'valid_bce': 0.0386, 'valid_mcc': 0.5455}\n",
      "{'sensitivity': 0.5981, 'specificity': 0.9684, 'accuracy': 0.9492, 'precision': 0.5081, 'mcc': 0.5247, 'micro_auroc': 0.9227, 'train_bce': 0.0093, 'valid_bce': 0.0452, 'valid_mcc': 0.5305}\n",
      "{'sensitivity': 0.5949, 'specificity': 0.97, 'accuracy': 0.9506, 'precision': 0.5202, 'mcc': 0.5304, 'micro_auroc': 0.9256, 'train_bce': 0.0078, 'valid_bce': 0.0535, 'valid_mcc': 0.5926}\n",
      "{'sensitivity': 0.6587, 'specificity': 0.9645, 'accuracy': 0.9486, 'precision': 0.503, 'mcc': 0.5492, 'micro_auroc': 0.9255, 'train_bce': 0.0063, 'valid_bce': 0.0439, 'valid_mcc': 0.5968}\n",
      "{'sensitivity': 0.7432, 'specificity': 0.9501, 'accuracy': 0.9394, 'precision': 0.4485, 'mcc': 0.5485, 'micro_auroc': 0.9335, 'train_bce': 0.0048, 'valid_bce': 0.0368, 'valid_mcc': 0.5643}\n",
      "{'sensitivity': 0.5486, 'specificity': 0.9836, 'accuracy': 0.9611, 'precision': 0.6466, 'mcc': 0.5755, 'micro_auroc': 0.9208, 'train_bce': 0.0035, 'valid_bce': 0.0762, 'valid_mcc': 0.6139}\n",
      "{'sensitivity': 0.5694, 'specificity': 0.9801, 'accuracy': 0.9588, 'precision': 0.6092, 'mcc': 0.5673, 'micro_auroc': 0.9198, 'train_bce': 0.0031, 'valid_bce': 0.0704, 'valid_mcc': 0.6073}\n",
      "{'sensitivity': 0.5965, 'specificity': 0.9754, 'accuracy': 0.9558, 'precision': 0.5701, 'mcc': 0.5598, 'micro_auroc': 0.925, 'train_bce': 0.0023, 'valid_bce': 0.0668, 'valid_mcc': 0.6073}\n",
      "{'sensitivity': 0.37, 'specificity': 0.9951, 'accuracy': 0.9627, 'precision': 0.8056, 'mcc': 0.531, 'micro_auroc': 0.8962, 'train_bce': 0.0059, 'valid_bce': 0.1428, 'valid_mcc': 0.5944}\n",
      "{'sensitivity': 0.555, 'specificity': 0.9795, 'accuracy': 0.9575, 'precision': 0.5969, 'mcc': 0.5533, 'micro_auroc': 0.914, 'train_bce': 0.0057, 'valid_bce': 0.071, 'valid_mcc': 0.5953}\n",
      "{'sensitivity': 0.6268, 'specificity': 0.9718, 'accuracy': 0.9539, 'precision': 0.5481, 'mcc': 0.5619, 'micro_auroc': 0.9272, 'train_bce': 0.0031, 'valid_bce': 0.0597, 'valid_mcc': 0.594}\n",
      "{'sensitivity': 0.5407, 'specificity': 0.9848, 'accuracy': 0.9618, 'precision': 0.6608, 'mcc': 0.5781, 'micro_auroc': 0.9205, 'train_bce': 0.0026, 'valid_bce': 0.0791, 'valid_mcc': 0.5972}\n",
      "{'sensitivity': 0.5502, 'specificity': 0.9815, 'accuracy': 0.9592, 'precision': 0.6194, 'mcc': 0.5625, 'micro_auroc': 0.9148, 'train_bce': 0.0015, 'valid_bce': 0.0727, 'valid_mcc': 0.6088}\n",
      "{'sensitivity': 0.5183, 'specificity': 0.9874, 'accuracy': 0.9631, 'precision': 0.6915, 'mcc': 0.5801, 'micro_auroc': 0.9093, 'train_bce': 0.0014, 'valid_bce': 0.0912, 'valid_mcc': 0.614}\n",
      "{'sensitivity': 0.5678, 'specificity': 0.9816, 'accuracy': 0.9602, 'precision': 0.6279, 'mcc': 0.5762, 'micro_auroc': 0.9156, 'train_bce': 0.0011, 'valid_bce': 0.0788, 'valid_mcc': 0.6111}\n",
      "{'sensitivity': 0.4833, 'specificity': 0.9904, 'accuracy': 0.9642, 'precision': 0.7337, 'mcc': 0.5783, 'micro_auroc': 0.9047, 'train_bce': 0.0016, 'valid_bce': 0.1001, 'valid_mcc': 0.6174}\n",
      "{'sensitivity': 0.512, 'specificity': 0.9881, 'accuracy': 0.9634, 'precision': 0.7009, 'mcc': 0.5808, 'micro_auroc': 0.9075, 'train_bce': 0.0011, 'valid_bce': 0.0923, 'valid_mcc': 0.6112}\n",
      "{'sensitivity': 0.4274, 'specificity': 0.9928, 'accuracy': 0.9635, 'precision': 0.7635, 'mcc': 0.555, 'micro_auroc': 0.8975, 'train_bce': 0.0009, 'valid_bce': 0.1231, 'valid_mcc': 0.6154}\n",
      "{'sensitivity': 0.555, 'specificity': 0.9828, 'accuracy': 0.9606, 'precision': 0.6374, 'mcc': 0.5743, 'micro_auroc': 0.9088, 'train_bce': 0.0006, 'valid_bce': 0.0802, 'valid_mcc': 0.6158}\n",
      "{'sensitivity': 0.4131, 'specificity': 0.9936, 'accuracy': 0.9636, 'precision': 0.7801, 'mcc': 0.5519, 'micro_auroc': 0.8915, 'train_bce': 0.0009, 'valid_bce': 0.1262, 'valid_mcc': 0.6108}\n",
      "{'sensitivity': 0.4306, 'specificity': 0.9924, 'accuracy': 0.9633, 'precision': 0.7563, 'mcc': 0.5542, 'micro_auroc': 0.8944, 'train_bce': 0.0007, 'valid_bce': 0.1195, 'valid_mcc': 0.6089}\n",
      "{'sensitivity': 0.4848, 'specificity': 0.9901, 'accuracy': 0.9639, 'precision': 0.7273, 'mcc': 0.5764, 'micro_auroc': 0.8995, 'train_bce': 0.0005, 'valid_bce': 0.1043, 'valid_mcc': 0.6136}\n",
      "{'sensitivity': 0.4673, 'specificity': 0.9915, 'accuracy': 0.9644, 'precision': 0.7513, 'mcc': 0.5759, 'micro_auroc': 0.8951, 'train_bce': 0.0005, 'valid_bce': 0.1149, 'valid_mcc': 0.6124}\n",
      "{'sensitivity': 0.4242, 'specificity': 0.9935, 'accuracy': 0.964, 'precision': 0.7801, 'mcc': 0.5595, 'micro_auroc': 0.8893, 'train_bce': 0.0004, 'valid_bce': 0.1315, 'valid_mcc': 0.6111}\n",
      "{'sensitivity': 0.4641, 'specificity': 0.9914, 'accuracy': 0.9641, 'precision': 0.7462, 'mcc': 0.5717, 'micro_auroc': 0.8915, 'train_bce': 0.0002, 'valid_bce': 0.1188, 'valid_mcc': 0.613}\n",
      "{'sensitivity': 0.453, 'specificity': 0.9926, 'accuracy': 0.9646, 'precision': 0.7696, 'mcc': 0.5744, 'micro_auroc': 0.8912, 'train_bce': 0.0003, 'valid_bce': 0.1255, 'valid_mcc': 0.6156}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sensitivity': 0.8501,\n",
       "  'specificity': 0.8051,\n",
       "  'accuracy': 0.8075,\n",
       "  'precision': 0.1924,\n",
       "  'mcc': 0.3457,\n",
       "  'micro_auroc': 0.9061,\n",
       "  'train_bce': 0.0439,\n",
       "  'valid_bce': 0.0274,\n",
       "  'valid_mcc': 0.3868},\n",
       " {'sensitivity': 0.4577,\n",
       "  'specificity': 0.9793,\n",
       "  'accuracy': 0.9523,\n",
       "  'precision': 0.5467,\n",
       "  'mcc': 0.4755,\n",
       "  'micro_auroc': 0.8979,\n",
       "  'train_bce': 0.0289,\n",
       "  'valid_bce': 0.0505,\n",
       "  'valid_mcc': 0.5193},\n",
       " {'sensitivity': 0.8724,\n",
       "  'specificity': 0.8082,\n",
       "  'accuracy': 0.8115,\n",
       "  'precision': 0.199,\n",
       "  'mcc': 0.36,\n",
       "  'micro_auroc': 0.9253,\n",
       "  'train_bce': 0.0227,\n",
       "  'valid_bce': 0.0281,\n",
       "  'valid_mcc': 0.4118},\n",
       " {'sensitivity': 0.6746,\n",
       "  'specificity': 0.9449,\n",
       "  'accuracy': 0.9309,\n",
       "  'precision': 0.4006,\n",
       "  'mcc': 0.4865,\n",
       "  'micro_auroc': 0.9301,\n",
       "  'train_bce': 0.0209,\n",
       "  'valid_bce': 0.0295,\n",
       "  'valid_mcc': 0.4875},\n",
       " {'sensitivity': 0.7097,\n",
       "  'specificity': 0.9402,\n",
       "  'accuracy': 0.9282,\n",
       "  'precision': 0.3931,\n",
       "  'mcc': 0.4947,\n",
       "  'micro_auroc': 0.9243,\n",
       "  'train_bce': 0.0138,\n",
       "  'valid_bce': 0.0386,\n",
       "  'valid_mcc': 0.5455},\n",
       " {'sensitivity': 0.5981,\n",
       "  'specificity': 0.9684,\n",
       "  'accuracy': 0.9492,\n",
       "  'precision': 0.5081,\n",
       "  'mcc': 0.5247,\n",
       "  'micro_auroc': 0.9227,\n",
       "  'train_bce': 0.0093,\n",
       "  'valid_bce': 0.0452,\n",
       "  'valid_mcc': 0.5305},\n",
       " {'sensitivity': 0.5949,\n",
       "  'specificity': 0.97,\n",
       "  'accuracy': 0.9506,\n",
       "  'precision': 0.5202,\n",
       "  'mcc': 0.5304,\n",
       "  'micro_auroc': 0.9256,\n",
       "  'train_bce': 0.0078,\n",
       "  'valid_bce': 0.0535,\n",
       "  'valid_mcc': 0.5926},\n",
       " {'sensitivity': 0.6587,\n",
       "  'specificity': 0.9645,\n",
       "  'accuracy': 0.9486,\n",
       "  'precision': 0.503,\n",
       "  'mcc': 0.5492,\n",
       "  'micro_auroc': 0.9255,\n",
       "  'train_bce': 0.0063,\n",
       "  'valid_bce': 0.0439,\n",
       "  'valid_mcc': 0.5968},\n",
       " {'sensitivity': 0.7432,\n",
       "  'specificity': 0.9501,\n",
       "  'accuracy': 0.9394,\n",
       "  'precision': 0.4485,\n",
       "  'mcc': 0.5485,\n",
       "  'micro_auroc': 0.9335,\n",
       "  'train_bce': 0.0048,\n",
       "  'valid_bce': 0.0368,\n",
       "  'valid_mcc': 0.5643},\n",
       " {'sensitivity': 0.5486,\n",
       "  'specificity': 0.9836,\n",
       "  'accuracy': 0.9611,\n",
       "  'precision': 0.6466,\n",
       "  'mcc': 0.5755,\n",
       "  'micro_auroc': 0.9208,\n",
       "  'train_bce': 0.0035,\n",
       "  'valid_bce': 0.0762,\n",
       "  'valid_mcc': 0.6139},\n",
       " {'sensitivity': 0.5694,\n",
       "  'specificity': 0.9801,\n",
       "  'accuracy': 0.9588,\n",
       "  'precision': 0.6092,\n",
       "  'mcc': 0.5673,\n",
       "  'micro_auroc': 0.9198,\n",
       "  'train_bce': 0.0031,\n",
       "  'valid_bce': 0.0704,\n",
       "  'valid_mcc': 0.6073},\n",
       " {'sensitivity': 0.5965,\n",
       "  'specificity': 0.9754,\n",
       "  'accuracy': 0.9558,\n",
       "  'precision': 0.5701,\n",
       "  'mcc': 0.5598,\n",
       "  'micro_auroc': 0.925,\n",
       "  'train_bce': 0.0023,\n",
       "  'valid_bce': 0.0668,\n",
       "  'valid_mcc': 0.6073},\n",
       " {'sensitivity': 0.37,\n",
       "  'specificity': 0.9951,\n",
       "  'accuracy': 0.9627,\n",
       "  'precision': 0.8056,\n",
       "  'mcc': 0.531,\n",
       "  'micro_auroc': 0.8962,\n",
       "  'train_bce': 0.0059,\n",
       "  'valid_bce': 0.1428,\n",
       "  'valid_mcc': 0.5944},\n",
       " {'sensitivity': 0.555,\n",
       "  'specificity': 0.9795,\n",
       "  'accuracy': 0.9575,\n",
       "  'precision': 0.5969,\n",
       "  'mcc': 0.5533,\n",
       "  'micro_auroc': 0.914,\n",
       "  'train_bce': 0.0057,\n",
       "  'valid_bce': 0.071,\n",
       "  'valid_mcc': 0.5953},\n",
       " {'sensitivity': 0.6268,\n",
       "  'specificity': 0.9718,\n",
       "  'accuracy': 0.9539,\n",
       "  'precision': 0.5481,\n",
       "  'mcc': 0.5619,\n",
       "  'micro_auroc': 0.9272,\n",
       "  'train_bce': 0.0031,\n",
       "  'valid_bce': 0.0597,\n",
       "  'valid_mcc': 0.594},\n",
       " {'sensitivity': 0.5407,\n",
       "  'specificity': 0.9848,\n",
       "  'accuracy': 0.9618,\n",
       "  'precision': 0.6608,\n",
       "  'mcc': 0.5781,\n",
       "  'micro_auroc': 0.9205,\n",
       "  'train_bce': 0.0026,\n",
       "  'valid_bce': 0.0791,\n",
       "  'valid_mcc': 0.5972},\n",
       " {'sensitivity': 0.5502,\n",
       "  'specificity': 0.9815,\n",
       "  'accuracy': 0.9592,\n",
       "  'precision': 0.6194,\n",
       "  'mcc': 0.5625,\n",
       "  'micro_auroc': 0.9148,\n",
       "  'train_bce': 0.0015,\n",
       "  'valid_bce': 0.0727,\n",
       "  'valid_mcc': 0.6088},\n",
       " {'sensitivity': 0.5183,\n",
       "  'specificity': 0.9874,\n",
       "  'accuracy': 0.9631,\n",
       "  'precision': 0.6915,\n",
       "  'mcc': 0.5801,\n",
       "  'micro_auroc': 0.9093,\n",
       "  'train_bce': 0.0014,\n",
       "  'valid_bce': 0.0912,\n",
       "  'valid_mcc': 0.614},\n",
       " {'sensitivity': 0.5678,\n",
       "  'specificity': 0.9816,\n",
       "  'accuracy': 0.9602,\n",
       "  'precision': 0.6279,\n",
       "  'mcc': 0.5762,\n",
       "  'micro_auroc': 0.9156,\n",
       "  'train_bce': 0.0011,\n",
       "  'valid_bce': 0.0788,\n",
       "  'valid_mcc': 0.6111},\n",
       " {'sensitivity': 0.4833,\n",
       "  'specificity': 0.9904,\n",
       "  'accuracy': 0.9642,\n",
       "  'precision': 0.7337,\n",
       "  'mcc': 0.5783,\n",
       "  'micro_auroc': 0.9047,\n",
       "  'train_bce': 0.0016,\n",
       "  'valid_bce': 0.1001,\n",
       "  'valid_mcc': 0.6174},\n",
       " {'sensitivity': 0.512,\n",
       "  'specificity': 0.9881,\n",
       "  'accuracy': 0.9634,\n",
       "  'precision': 0.7009,\n",
       "  'mcc': 0.5808,\n",
       "  'micro_auroc': 0.9075,\n",
       "  'train_bce': 0.0011,\n",
       "  'valid_bce': 0.0923,\n",
       "  'valid_mcc': 0.6112},\n",
       " {'sensitivity': 0.4274,\n",
       "  'specificity': 0.9928,\n",
       "  'accuracy': 0.9635,\n",
       "  'precision': 0.7635,\n",
       "  'mcc': 0.555,\n",
       "  'micro_auroc': 0.8975,\n",
       "  'train_bce': 0.0009,\n",
       "  'valid_bce': 0.1231,\n",
       "  'valid_mcc': 0.6154},\n",
       " {'sensitivity': 0.555,\n",
       "  'specificity': 0.9828,\n",
       "  'accuracy': 0.9606,\n",
       "  'precision': 0.6374,\n",
       "  'mcc': 0.5743,\n",
       "  'micro_auroc': 0.9088,\n",
       "  'train_bce': 0.0006,\n",
       "  'valid_bce': 0.0802,\n",
       "  'valid_mcc': 0.6158},\n",
       " {'sensitivity': 0.4131,\n",
       "  'specificity': 0.9936,\n",
       "  'accuracy': 0.9636,\n",
       "  'precision': 0.7801,\n",
       "  'mcc': 0.5519,\n",
       "  'micro_auroc': 0.8915,\n",
       "  'train_bce': 0.0009,\n",
       "  'valid_bce': 0.1262,\n",
       "  'valid_mcc': 0.6108},\n",
       " {'sensitivity': 0.4306,\n",
       "  'specificity': 0.9924,\n",
       "  'accuracy': 0.9633,\n",
       "  'precision': 0.7563,\n",
       "  'mcc': 0.5542,\n",
       "  'micro_auroc': 0.8944,\n",
       "  'train_bce': 0.0007,\n",
       "  'valid_bce': 0.1195,\n",
       "  'valid_mcc': 0.6089},\n",
       " {'sensitivity': 0.4848,\n",
       "  'specificity': 0.9901,\n",
       "  'accuracy': 0.9639,\n",
       "  'precision': 0.7273,\n",
       "  'mcc': 0.5764,\n",
       "  'micro_auroc': 0.8995,\n",
       "  'train_bce': 0.0005,\n",
       "  'valid_bce': 0.1043,\n",
       "  'valid_mcc': 0.6136},\n",
       " {'sensitivity': 0.4673,\n",
       "  'specificity': 0.9915,\n",
       "  'accuracy': 0.9644,\n",
       "  'precision': 0.7513,\n",
       "  'mcc': 0.5759,\n",
       "  'micro_auroc': 0.8951,\n",
       "  'train_bce': 0.0005,\n",
       "  'valid_bce': 0.1149,\n",
       "  'valid_mcc': 0.6124},\n",
       " {'sensitivity': 0.4242,\n",
       "  'specificity': 0.9935,\n",
       "  'accuracy': 0.964,\n",
       "  'precision': 0.7801,\n",
       "  'mcc': 0.5595,\n",
       "  'micro_auroc': 0.8893,\n",
       "  'train_bce': 0.0004,\n",
       "  'valid_bce': 0.1315,\n",
       "  'valid_mcc': 0.6111},\n",
       " {'sensitivity': 0.4641,\n",
       "  'specificity': 0.9914,\n",
       "  'accuracy': 0.9641,\n",
       "  'precision': 0.7462,\n",
       "  'mcc': 0.5717,\n",
       "  'micro_auroc': 0.8915,\n",
       "  'train_bce': 0.0002,\n",
       "  'valid_bce': 0.1188,\n",
       "  'valid_mcc': 0.613},\n",
       " {'sensitivity': 0.453,\n",
       "  'specificity': 0.9926,\n",
       "  'accuracy': 0.9646,\n",
       "  'precision': 0.7696,\n",
       "  'mcc': 0.5744,\n",
       "  'micro_auroc': 0.8912,\n",
       "  'train_bce': 0.0003,\n",
       "  'valid_bce': 0.1255,\n",
       "  'valid_mcc': 0.6156}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.train_until_fit(\n",
    "    patience=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensitivity': 0.874, 'specificity': 0.7258, 'accuracy': 0.7335, 'precision': 0.1483, 'mcc': 0.2887, 'micro_auroc': 0.8953, 'train_bce': 0.0457, 'valid_bce': 0.0315, 'valid_mcc': 0.3598}\n",
      "{'sensitivity': 0.4833, 'specificity': 0.975, 'accuracy': 0.9495, 'precision': 0.5136, 'mcc': 0.4716, 'micro_auroc': 0.9103, 'train_bce': 0.0305, 'valid_bce': 0.0477, 'valid_mcc': 0.4958}\n",
      "{'sensitivity': 0.7911, 'specificity': 0.885, 'accuracy': 0.8801, 'precision': 0.2731, 'mcc': 0.4196, 'micro_auroc': 0.9208, 'train_bce': 0.0221, 'valid_bce': 0.027, 'valid_mcc': 0.4661}\n",
      "{'sensitivity': 0.5104, 'specificity': 0.9647, 'accuracy': 0.9412, 'precision': 0.4414, 'mcc': 0.4437, 'micro_auroc': 0.8925, 'train_bce': 0.0215, 'valid_bce': 0.0531, 'valid_mcc': 0.5022}\n",
      "{'sensitivity': 0.7018, 'specificity': 0.956, 'accuracy': 0.9428, 'precision': 0.4656, 'mcc': 0.5434, 'micro_auroc': 0.929, 'train_bce': 0.0131, 'valid_bce': 0.0374, 'valid_mcc': 0.5415}\n",
      "{'sensitivity': 0.4833, 'specificity': 0.9818, 'accuracy': 0.956, 'precision': 0.5918, 'mcc': 0.5121, 'micro_auroc': 0.9176, 'train_bce': 0.0088, 'valid_bce': 0.064, 'valid_mcc': 0.5395}\n",
      "{'sensitivity': 0.6188, 'specificity': 0.9741, 'accuracy': 0.9557, 'precision': 0.5664, 'mcc': 0.5687, 'micro_auroc': 0.9283, 'train_bce': 0.0074, 'valid_bce': 0.0529, 'valid_mcc': 0.5851}\n",
      "{'sensitivity': 0.74, 'specificity': 0.9422, 'accuracy': 0.9318, 'precision': 0.4117, 'mcc': 0.5204, 'micro_auroc': 0.9312, 'train_bce': 0.0051, 'valid_bce': 0.0396, 'valid_mcc': 0.5576}\n",
      "{'sensitivity': 0.6523, 'specificity': 0.9723, 'accuracy': 0.9557, 'precision': 0.5626, 'mcc': 0.5826, 'micro_auroc': 0.9304, 'train_bce': 0.0045, 'valid_bce': 0.0503, 'valid_mcc': 0.5974}\n",
      "{'sensitivity': 0.6635, 'specificity': 0.9654, 'accuracy': 0.9498, 'precision': 0.5117, 'mcc': 0.5568, 'micro_auroc': 0.9223, 'train_bce': 0.0041, 'valid_bce': 0.05, 'valid_mcc': 0.554}\n",
      "{'sensitivity': 0.5678, 'specificity': 0.9826, 'accuracy': 0.9611, 'precision': 0.6403, 'mcc': 0.5826, 'micro_auroc': 0.9268, 'train_bce': 0.0034, 'valid_bce': 0.0696, 'valid_mcc': 0.6024}\n",
      "{'sensitivity': 0.6204, 'specificity': 0.9746, 'accuracy': 0.9563, 'precision': 0.5721, 'mcc': 0.5727, 'micro_auroc': 0.9329, 'train_bce': 0.0023, 'valid_bce': 0.0623, 'valid_mcc': 0.6103}\n",
      "{'sensitivity': 0.4434, 'specificity': 0.993, 'accuracy': 0.9646, 'precision': 0.7765, 'mcc': 0.5709, 'micro_auroc': 0.9257, 'train_bce': 0.0031, 'valid_bce': 0.112, 'valid_mcc': 0.6137}\n",
      "{'sensitivity': 0.5502, 'specificity': 0.9853, 'accuracy': 0.9627, 'precision': 0.6712, 'mcc': 0.5886, 'micro_auroc': 0.9227, 'train_bce': 0.0042, 'valid_bce': 0.072, 'valid_mcc': 0.5967}\n",
      "{'sensitivity': 0.5199, 'specificity': 0.9877, 'accuracy': 0.9635, 'precision': 0.6981, 'mcc': 0.5842, 'micro_auroc': 0.9161, 'train_bce': 0.0021, 'valid_bce': 0.0859, 'valid_mcc': 0.6083}\n",
      "{'sensitivity': 0.5455, 'specificity': 0.9855, 'accuracy': 0.9627, 'precision': 0.6732, 'mcc': 0.5869, 'micro_auroc': 0.919, 'train_bce': 0.0029, 'valid_bce': 0.0797, 'valid_mcc': 0.6027}\n",
      "{'sensitivity': 0.5518, 'specificity': 0.9834, 'accuracy': 0.9611, 'precision': 0.6455, 'mcc': 0.5767, 'micro_auroc': 0.9157, 'train_bce': 0.0015, 'valid_bce': 0.0769, 'valid_mcc': 0.6129}\n",
      "{'sensitivity': 0.5104, 'specificity': 0.9883, 'accuracy': 0.9636, 'precision': 0.7048, 'mcc': 0.5817, 'micro_auroc': 0.912, 'train_bce': 0.001, 'valid_bce': 0.0912, 'valid_mcc': 0.6155}\n",
      "{'sensitivity': 0.5407, 'specificity': 0.9848, 'accuracy': 0.9618, 'precision': 0.6595, 'mcc': 0.5775, 'micro_auroc': 0.92, 'train_bce': 0.0012, 'valid_bce': 0.0813, 'valid_mcc': 0.6188}\n",
      "{'sensitivity': 0.5311, 'specificity': 0.9875, 'accuracy': 0.9638, 'precision': 0.6981, 'mcc': 0.5907, 'micro_auroc': 0.9119, 'train_bce': 0.0015, 'valid_bce': 0.0894, 'valid_mcc': 0.6229}\n",
      "{'sensitivity': 0.4833, 'specificity': 0.9904, 'accuracy': 0.9642, 'precision': 0.7337, 'mcc': 0.5783, 'micro_auroc': 0.9098, 'train_bce': 0.0011, 'valid_bce': 0.0993, 'valid_mcc': 0.6374}\n",
      "{'sensitivity': 0.4322, 'specificity': 0.9941, 'accuracy': 0.965, 'precision': 0.7994, 'mcc': 0.5726, 'micro_auroc': 0.9053, 'train_bce': 0.0008, 'valid_bce': 0.1224, 'valid_mcc': 0.6286}\n",
      "{'sensitivity': 0.5295, 'specificity': 0.9874, 'accuracy': 0.9637, 'precision': 0.696, 'mcc': 0.5888, 'micro_auroc': 0.9119, 'train_bce': 0.0006, 'valid_bce': 0.0918, 'valid_mcc': 0.6321}\n",
      "{'sensitivity': 0.3971, 'specificity': 0.9949, 'accuracy': 0.964, 'precision': 0.8111, 'mcc': 0.5527, 'micro_auroc': 0.8909, 'train_bce': 0.0009, 'valid_bce': 0.1326, 'valid_mcc': 0.6276}\n",
      "{'sensitivity': 0.4657, 'specificity': 0.9926, 'accuracy': 0.9653, 'precision': 0.7745, 'mcc': 0.5847, 'micro_auroc': 0.9005, 'train_bce': 0.0007, 'valid_bce': 0.1132, 'valid_mcc': 0.6246}\n",
      "{'sensitivity': 0.4737, 'specificity': 0.9919, 'accuracy': 0.9651, 'precision': 0.7615, 'mcc': 0.5843, 'micro_auroc': 0.9012, 'train_bce': 0.0006, 'valid_bce': 0.1149, 'valid_mcc': 0.6292}\n",
      "{'sensitivity': 0.488, 'specificity': 0.9916, 'accuracy': 0.9656, 'precision': 0.7612, 'mcc': 0.5933, 'micro_auroc': 0.903, 'train_bce': 0.0005, 'valid_bce': 0.1111, 'valid_mcc': 0.6257}\n",
      "{'sensitivity': 0.445, 'specificity': 0.9936, 'accuracy': 0.9652, 'precision': 0.7926, 'mcc': 0.5785, 'micro_auroc': 0.8986, 'train_bce': 0.0005, 'valid_bce': 0.126, 'valid_mcc': 0.6295}\n",
      "{'sensitivity': 0.4641, 'specificity': 0.9927, 'accuracy': 0.9653, 'precision': 0.776, 'mcc': 0.5843, 'micro_auroc': 0.9012, 'train_bce': 0.0002, 'valid_bce': 0.1233, 'valid_mcc': 0.6336}\n",
      "{'sensitivity': 0.4498, 'specificity': 0.9938, 'accuracy': 0.9656, 'precision': 0.7989, 'mcc': 0.5842, 'micro_auroc': 0.8961, 'train_bce': 0.0003, 'valid_bce': 0.1302, 'valid_mcc': 0.6317}\n",
      "{'sensitivity': 0.4019, 'specificity': 0.9951, 'accuracy': 0.9644, 'precision': 0.8182, 'mcc': 0.5588, 'micro_auroc': 0.8873, 'train_bce': 0.0006, 'valid_bce': 0.1461, 'valid_mcc': 0.6119}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sensitivity': 0.874,\n",
       "  'specificity': 0.7258,\n",
       "  'accuracy': 0.7335,\n",
       "  'precision': 0.1483,\n",
       "  'mcc': 0.2887,\n",
       "  'micro_auroc': 0.8953,\n",
       "  'train_bce': 0.0457,\n",
       "  'valid_bce': 0.0315,\n",
       "  'valid_mcc': 0.3598},\n",
       " {'sensitivity': 0.4833,\n",
       "  'specificity': 0.975,\n",
       "  'accuracy': 0.9495,\n",
       "  'precision': 0.5136,\n",
       "  'mcc': 0.4716,\n",
       "  'micro_auroc': 0.9103,\n",
       "  'train_bce': 0.0305,\n",
       "  'valid_bce': 0.0477,\n",
       "  'valid_mcc': 0.4958},\n",
       " {'sensitivity': 0.7911,\n",
       "  'specificity': 0.885,\n",
       "  'accuracy': 0.8801,\n",
       "  'precision': 0.2731,\n",
       "  'mcc': 0.4196,\n",
       "  'micro_auroc': 0.9208,\n",
       "  'train_bce': 0.0221,\n",
       "  'valid_bce': 0.027,\n",
       "  'valid_mcc': 0.4661},\n",
       " {'sensitivity': 0.5104,\n",
       "  'specificity': 0.9647,\n",
       "  'accuracy': 0.9412,\n",
       "  'precision': 0.4414,\n",
       "  'mcc': 0.4437,\n",
       "  'micro_auroc': 0.8925,\n",
       "  'train_bce': 0.0215,\n",
       "  'valid_bce': 0.0531,\n",
       "  'valid_mcc': 0.5022},\n",
       " {'sensitivity': 0.7018,\n",
       "  'specificity': 0.956,\n",
       "  'accuracy': 0.9428,\n",
       "  'precision': 0.4656,\n",
       "  'mcc': 0.5434,\n",
       "  'micro_auroc': 0.929,\n",
       "  'train_bce': 0.0131,\n",
       "  'valid_bce': 0.0374,\n",
       "  'valid_mcc': 0.5415},\n",
       " {'sensitivity': 0.4833,\n",
       "  'specificity': 0.9818,\n",
       "  'accuracy': 0.956,\n",
       "  'precision': 0.5918,\n",
       "  'mcc': 0.5121,\n",
       "  'micro_auroc': 0.9176,\n",
       "  'train_bce': 0.0088,\n",
       "  'valid_bce': 0.064,\n",
       "  'valid_mcc': 0.5395},\n",
       " {'sensitivity': 0.6188,\n",
       "  'specificity': 0.9741,\n",
       "  'accuracy': 0.9557,\n",
       "  'precision': 0.5664,\n",
       "  'mcc': 0.5687,\n",
       "  'micro_auroc': 0.9283,\n",
       "  'train_bce': 0.0074,\n",
       "  'valid_bce': 0.0529,\n",
       "  'valid_mcc': 0.5851},\n",
       " {'sensitivity': 0.74,\n",
       "  'specificity': 0.9422,\n",
       "  'accuracy': 0.9318,\n",
       "  'precision': 0.4117,\n",
       "  'mcc': 0.5204,\n",
       "  'micro_auroc': 0.9312,\n",
       "  'train_bce': 0.0051,\n",
       "  'valid_bce': 0.0396,\n",
       "  'valid_mcc': 0.5576},\n",
       " {'sensitivity': 0.6523,\n",
       "  'specificity': 0.9723,\n",
       "  'accuracy': 0.9557,\n",
       "  'precision': 0.5626,\n",
       "  'mcc': 0.5826,\n",
       "  'micro_auroc': 0.9304,\n",
       "  'train_bce': 0.0045,\n",
       "  'valid_bce': 0.0503,\n",
       "  'valid_mcc': 0.5974},\n",
       " {'sensitivity': 0.6635,\n",
       "  'specificity': 0.9654,\n",
       "  'accuracy': 0.9498,\n",
       "  'precision': 0.5117,\n",
       "  'mcc': 0.5568,\n",
       "  'micro_auroc': 0.9223,\n",
       "  'train_bce': 0.0041,\n",
       "  'valid_bce': 0.05,\n",
       "  'valid_mcc': 0.554},\n",
       " {'sensitivity': 0.5678,\n",
       "  'specificity': 0.9826,\n",
       "  'accuracy': 0.9611,\n",
       "  'precision': 0.6403,\n",
       "  'mcc': 0.5826,\n",
       "  'micro_auroc': 0.9268,\n",
       "  'train_bce': 0.0034,\n",
       "  'valid_bce': 0.0696,\n",
       "  'valid_mcc': 0.6024},\n",
       " {'sensitivity': 0.6204,\n",
       "  'specificity': 0.9746,\n",
       "  'accuracy': 0.9563,\n",
       "  'precision': 0.5721,\n",
       "  'mcc': 0.5727,\n",
       "  'micro_auroc': 0.9329,\n",
       "  'train_bce': 0.0023,\n",
       "  'valid_bce': 0.0623,\n",
       "  'valid_mcc': 0.6103},\n",
       " {'sensitivity': 0.4434,\n",
       "  'specificity': 0.993,\n",
       "  'accuracy': 0.9646,\n",
       "  'precision': 0.7765,\n",
       "  'mcc': 0.5709,\n",
       "  'micro_auroc': 0.9257,\n",
       "  'train_bce': 0.0031,\n",
       "  'valid_bce': 0.112,\n",
       "  'valid_mcc': 0.6137},\n",
       " {'sensitivity': 0.5502,\n",
       "  'specificity': 0.9853,\n",
       "  'accuracy': 0.9627,\n",
       "  'precision': 0.6712,\n",
       "  'mcc': 0.5886,\n",
       "  'micro_auroc': 0.9227,\n",
       "  'train_bce': 0.0042,\n",
       "  'valid_bce': 0.072,\n",
       "  'valid_mcc': 0.5967},\n",
       " {'sensitivity': 0.5199,\n",
       "  'specificity': 0.9877,\n",
       "  'accuracy': 0.9635,\n",
       "  'precision': 0.6981,\n",
       "  'mcc': 0.5842,\n",
       "  'micro_auroc': 0.9161,\n",
       "  'train_bce': 0.0021,\n",
       "  'valid_bce': 0.0859,\n",
       "  'valid_mcc': 0.6083},\n",
       " {'sensitivity': 0.5455,\n",
       "  'specificity': 0.9855,\n",
       "  'accuracy': 0.9627,\n",
       "  'precision': 0.6732,\n",
       "  'mcc': 0.5869,\n",
       "  'micro_auroc': 0.919,\n",
       "  'train_bce': 0.0029,\n",
       "  'valid_bce': 0.0797,\n",
       "  'valid_mcc': 0.6027},\n",
       " {'sensitivity': 0.5518,\n",
       "  'specificity': 0.9834,\n",
       "  'accuracy': 0.9611,\n",
       "  'precision': 0.6455,\n",
       "  'mcc': 0.5767,\n",
       "  'micro_auroc': 0.9157,\n",
       "  'train_bce': 0.0015,\n",
       "  'valid_bce': 0.0769,\n",
       "  'valid_mcc': 0.6129},\n",
       " {'sensitivity': 0.5104,\n",
       "  'specificity': 0.9883,\n",
       "  'accuracy': 0.9636,\n",
       "  'precision': 0.7048,\n",
       "  'mcc': 0.5817,\n",
       "  'micro_auroc': 0.912,\n",
       "  'train_bce': 0.001,\n",
       "  'valid_bce': 0.0912,\n",
       "  'valid_mcc': 0.6155},\n",
       " {'sensitivity': 0.5407,\n",
       "  'specificity': 0.9848,\n",
       "  'accuracy': 0.9618,\n",
       "  'precision': 0.6595,\n",
       "  'mcc': 0.5775,\n",
       "  'micro_auroc': 0.92,\n",
       "  'train_bce': 0.0012,\n",
       "  'valid_bce': 0.0813,\n",
       "  'valid_mcc': 0.6188},\n",
       " {'sensitivity': 0.5311,\n",
       "  'specificity': 0.9875,\n",
       "  'accuracy': 0.9638,\n",
       "  'precision': 0.6981,\n",
       "  'mcc': 0.5907,\n",
       "  'micro_auroc': 0.9119,\n",
       "  'train_bce': 0.0015,\n",
       "  'valid_bce': 0.0894,\n",
       "  'valid_mcc': 0.6229},\n",
       " {'sensitivity': 0.4833,\n",
       "  'specificity': 0.9904,\n",
       "  'accuracy': 0.9642,\n",
       "  'precision': 0.7337,\n",
       "  'mcc': 0.5783,\n",
       "  'micro_auroc': 0.9098,\n",
       "  'train_bce': 0.0011,\n",
       "  'valid_bce': 0.0993,\n",
       "  'valid_mcc': 0.6374},\n",
       " {'sensitivity': 0.4322,\n",
       "  'specificity': 0.9941,\n",
       "  'accuracy': 0.965,\n",
       "  'precision': 0.7994,\n",
       "  'mcc': 0.5726,\n",
       "  'micro_auroc': 0.9053,\n",
       "  'train_bce': 0.0008,\n",
       "  'valid_bce': 0.1224,\n",
       "  'valid_mcc': 0.6286},\n",
       " {'sensitivity': 0.5295,\n",
       "  'specificity': 0.9874,\n",
       "  'accuracy': 0.9637,\n",
       "  'precision': 0.696,\n",
       "  'mcc': 0.5888,\n",
       "  'micro_auroc': 0.9119,\n",
       "  'train_bce': 0.0006,\n",
       "  'valid_bce': 0.0918,\n",
       "  'valid_mcc': 0.6321},\n",
       " {'sensitivity': 0.3971,\n",
       "  'specificity': 0.9949,\n",
       "  'accuracy': 0.964,\n",
       "  'precision': 0.8111,\n",
       "  'mcc': 0.5527,\n",
       "  'micro_auroc': 0.8909,\n",
       "  'train_bce': 0.0009,\n",
       "  'valid_bce': 0.1326,\n",
       "  'valid_mcc': 0.6276},\n",
       " {'sensitivity': 0.4657,\n",
       "  'specificity': 0.9926,\n",
       "  'accuracy': 0.9653,\n",
       "  'precision': 0.7745,\n",
       "  'mcc': 0.5847,\n",
       "  'micro_auroc': 0.9005,\n",
       "  'train_bce': 0.0007,\n",
       "  'valid_bce': 0.1132,\n",
       "  'valid_mcc': 0.6246},\n",
       " {'sensitivity': 0.4737,\n",
       "  'specificity': 0.9919,\n",
       "  'accuracy': 0.9651,\n",
       "  'precision': 0.7615,\n",
       "  'mcc': 0.5843,\n",
       "  'micro_auroc': 0.9012,\n",
       "  'train_bce': 0.0006,\n",
       "  'valid_bce': 0.1149,\n",
       "  'valid_mcc': 0.6292},\n",
       " {'sensitivity': 0.488,\n",
       "  'specificity': 0.9916,\n",
       "  'accuracy': 0.9656,\n",
       "  'precision': 0.7612,\n",
       "  'mcc': 0.5933,\n",
       "  'micro_auroc': 0.903,\n",
       "  'train_bce': 0.0005,\n",
       "  'valid_bce': 0.1111,\n",
       "  'valid_mcc': 0.6257},\n",
       " {'sensitivity': 0.445,\n",
       "  'specificity': 0.9936,\n",
       "  'accuracy': 0.9652,\n",
       "  'precision': 0.7926,\n",
       "  'mcc': 0.5785,\n",
       "  'micro_auroc': 0.8986,\n",
       "  'train_bce': 0.0005,\n",
       "  'valid_bce': 0.126,\n",
       "  'valid_mcc': 0.6295},\n",
       " {'sensitivity': 0.4641,\n",
       "  'specificity': 0.9927,\n",
       "  'accuracy': 0.9653,\n",
       "  'precision': 0.776,\n",
       "  'mcc': 0.5843,\n",
       "  'micro_auroc': 0.9012,\n",
       "  'train_bce': 0.0002,\n",
       "  'valid_bce': 0.1233,\n",
       "  'valid_mcc': 0.6336},\n",
       " {'sensitivity': 0.4498,\n",
       "  'specificity': 0.9938,\n",
       "  'accuracy': 0.9656,\n",
       "  'precision': 0.7989,\n",
       "  'mcc': 0.5842,\n",
       "  'micro_auroc': 0.8961,\n",
       "  'train_bce': 0.0003,\n",
       "  'valid_bce': 0.1302,\n",
       "  'valid_mcc': 0.6317},\n",
       " {'sensitivity': 0.4019,\n",
       "  'specificity': 0.9951,\n",
       "  'accuracy': 0.9644,\n",
       "  'precision': 0.8182,\n",
       "  'mcc': 0.5588,\n",
       "  'micro_auroc': 0.8873,\n",
       "  'train_bce': 0.0006,\n",
       "  'valid_bce': 0.1461,\n",
       "  'valid_mcc': 0.6119}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.train_until_fit(\n",
    "    patience=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensitivity': 0.6778, 'specificity': 0.8371, 'accuracy': 0.8288, 'precision': 0.1852, 'mcc': 0.2911, 'micro_auroc': 0.8432, 'train_bce': 0.0506, 'valid_bce': 0.0372, 'valid_mcc': 0.3244}\n",
      "{'sensitivity': 0.2759, 'specificity': 0.9906, 'accuracy': 0.9536, 'precision': 0.6157, 'mcc': 0.3922, 'micro_auroc': 0.8711, 'train_bce': 0.0334, 'valid_bce': 0.0754, 'valid_mcc': 0.4393}\n",
      "{'sensitivity': 0.5407, 'specificity': 0.9598, 'accuracy': 0.938, 'precision': 0.4232, 'mcc': 0.4461, 'micro_auroc': 0.8952, 'train_bce': 0.0285, 'valid_bce': 0.0525, 'valid_mcc': 0.4696}\n",
      "{'sensitivity': 0.866, 'specificity': 0.7508, 'accuracy': 0.7567, 'precision': 0.1595, 'mcc': 0.304, 'micro_auroc': 0.8964, 'train_bce': 0.0269, 'valid_bce': 0.0281, 'valid_mcc': 0.3747}\n",
      "{'sensitivity': 0.6013, 'specificity': 0.9565, 'accuracy': 0.9381, 'precision': 0.4304, 'mcc': 0.4771, 'micro_auroc': 0.9143, 'train_bce': 0.0182, 'valid_bce': 0.045, 'valid_mcc': 0.5039}\n",
      "{'sensitivity': 0.7384, 'specificity': 0.9092, 'accuracy': 0.9004, 'precision': 0.3076, 'mcc': 0.435, 'micro_auroc': 0.9135, 'train_bce': 0.0113, 'valid_bce': 0.0359, 'valid_mcc': 0.4546}\n",
      "{'sensitivity': 0.7847, 'specificity': 0.8793, 'accuracy': 0.8744, 'precision': 0.262, 'mcc': 0.4064, 'micro_auroc': 0.9149, 'train_bce': 0.009, 'valid_bce': 0.0344, 'valid_mcc': 0.4514}\n",
      "{'sensitivity': 0.4322, 'specificity': 0.9863, 'accuracy': 0.9576, 'precision': 0.6332, 'mcc': 0.5022, 'micro_auroc': 0.9154, 'train_bce': 0.006, 'valid_bce': 0.0911, 'valid_mcc': 0.5277}\n",
      "{'sensitivity': 0.5662, 'specificity': 0.9567, 'accuracy': 0.9365, 'precision': 0.4167, 'mcc': 0.453, 'micro_auroc': 0.9038, 'train_bce': 0.0053, 'valid_bce': 0.0634, 'valid_mcc': 0.4972}\n",
      "{'sensitivity': 0.5997, 'specificity': 0.967, 'accuracy': 0.948, 'precision': 0.498, 'mcc': 0.5193, 'micro_auroc': 0.9109, 'train_bce': 0.0045, 'valid_bce': 0.0675, 'valid_mcc': 0.5238}\n",
      "{'sensitivity': 0.4848, 'specificity': 0.9815, 'accuracy': 0.9558, 'precision': 0.5891, 'mcc': 0.5116, 'micro_auroc': 0.9074, 'train_bce': 0.0035, 'valid_bce': 0.1037, 'valid_mcc': 0.5198}\n",
      "{'sensitivity': 0.5789, 'specificity': 0.9697, 'accuracy': 0.9494, 'precision': 0.5105, 'mcc': 0.5171, 'micro_auroc': 0.9121, 'train_bce': 0.0025, 'valid_bce': 0.0738, 'valid_mcc': 0.5334}\n",
      "{'sensitivity': 0.4577, 'specificity': 0.9869, 'accuracy': 0.9595, 'precision': 0.6568, 'mcc': 0.5283, 'micro_auroc': 0.9011, 'train_bce': 0.003, 'valid_bce': 0.1187, 'valid_mcc': 0.5263}\n",
      "{'sensitivity': 0.4306, 'specificity': 0.9871, 'accuracy': 0.9583, 'precision': 0.6459, 'mcc': 0.507, 'micro_auroc': 0.9011, 'train_bce': 0.0037, 'valid_bce': 0.1067, 'valid_mcc': 0.5531}\n",
      "{'sensitivity': 0.4402, 'specificity': 0.9868, 'accuracy': 0.9585, 'precision': 0.6464, 'mcc': 0.513, 'micro_auroc': 0.8998, 'train_bce': 0.0023, 'valid_bce': 0.1069, 'valid_mcc': 0.5493}\n",
      "{'sensitivity': 0.3589, 'specificity': 0.9935, 'accuracy': 0.9606, 'precision': 0.75, 'mcc': 0.5022, 'micro_auroc': 0.8967, 'train_bce': 0.002, 'valid_bce': 0.1469, 'valid_mcc': 0.552}\n",
      "{'sensitivity': 0.5439, 'specificity': 0.9774, 'accuracy': 0.955, 'precision': 0.5683, 'mcc': 0.5323, 'micro_auroc': 0.9043, 'train_bce': 0.0014, 'valid_bce': 0.0925, 'valid_mcc': 0.5637}\n",
      "{'sensitivity': 0.4067, 'specificity': 0.9901, 'accuracy': 0.9599, 'precision': 0.6911, 'mcc': 0.5115, 'micro_auroc': 0.8954, 'train_bce': 0.0012, 'valid_bce': 0.1369, 'valid_mcc': 0.5523}\n",
      "{'sensitivity': 0.504, 'specificity': 0.9815, 'accuracy': 0.9568, 'precision': 0.5985, 'mcc': 0.5268, 'micro_auroc': 0.9094, 'train_bce': 0.001, 'valid_bce': 0.1099, 'valid_mcc': 0.5727}\n",
      "{'sensitivity': 0.3732, 'specificity': 0.993, 'accuracy': 0.9609, 'precision': 0.7452, 'mcc': 0.5106, 'micro_auroc': 0.8913, 'train_bce': 0.0012, 'valid_bce': 0.1591, 'valid_mcc': 0.5377}\n",
      "{'sensitivity': 0.3652, 'specificity': 0.9942, 'accuracy': 0.9616, 'precision': 0.7736, 'mcc': 0.5157, 'micro_auroc': 0.8935, 'train_bce': 0.0007, 'valid_bce': 0.1709, 'valid_mcc': 0.5619}\n",
      "{'sensitivity': 0.4003, 'specificity': 0.9925, 'accuracy': 0.9618, 'precision': 0.7448, 'mcc': 0.5292, 'micro_auroc': 0.8971, 'train_bce': 0.0008, 'valid_bce': 0.1574, 'valid_mcc': 0.5663}\n",
      "{'sensitivity': 0.5279, 'specificity': 0.9814, 'accuracy': 0.958, 'precision': 0.6085, 'mcc': 0.5449, 'micro_auroc': 0.9057, 'train_bce': 0.0008, 'valid_bce': 0.1118, 'valid_mcc': 0.5442}\n",
      "{'sensitivity': 0.3206, 'specificity': 0.9964, 'accuracy': 0.9614, 'precision': 0.8306, 'mcc': 0.5019, 'micro_auroc': 0.8789, 'train_bce': 0.0009, 'valid_bce': 0.2061, 'valid_mcc': 0.531}\n",
      "{'sensitivity': 0.3684, 'specificity': 0.9937, 'accuracy': 0.9613, 'precision': 0.7624, 'mcc': 0.5138, 'micro_auroc': 0.8859, 'train_bce': 0.0007, 'valid_bce': 0.1729, 'valid_mcc': 0.5395}\n",
      "{'sensitivity': 0.4498, 'specificity': 0.9887, 'accuracy': 0.9608, 'precision': 0.6845, 'mcc': 0.5359, 'micro_auroc': 0.8993, 'train_bce': 0.0005, 'valid_bce': 0.1385, 'valid_mcc': 0.5669}\n",
      "{'sensitivity': 0.4067, 'specificity': 0.9915, 'accuracy': 0.9613, 'precision': 0.7244, 'mcc': 0.5253, 'micro_auroc': 0.893, 'train_bce': 0.0006, 'valid_bce': 0.157, 'valid_mcc': 0.5627}\n",
      "{'sensitivity': 0.3987, 'specificity': 0.9928, 'accuracy': 0.962, 'precision': 0.7508, 'mcc': 0.5305, 'micro_auroc': 0.8866, 'train_bce': 0.0004, 'valid_bce': 0.1657, 'valid_mcc': 0.5628}\n",
      "{'sensitivity': 0.3828, 'specificity': 0.9934, 'accuracy': 0.9618, 'precision': 0.7595, 'mcc': 0.5228, 'micro_auroc': 0.885, 'train_bce': 0.0003, 'valid_bce': 0.1733, 'valid_mcc': 0.5538}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sensitivity': 0.6778,\n",
       "  'specificity': 0.8371,\n",
       "  'accuracy': 0.8288,\n",
       "  'precision': 0.1852,\n",
       "  'mcc': 0.2911,\n",
       "  'micro_auroc': 0.8432,\n",
       "  'train_bce': 0.0506,\n",
       "  'valid_bce': 0.0372,\n",
       "  'valid_mcc': 0.3244},\n",
       " {'sensitivity': 0.2759,\n",
       "  'specificity': 0.9906,\n",
       "  'accuracy': 0.9536,\n",
       "  'precision': 0.6157,\n",
       "  'mcc': 0.3922,\n",
       "  'micro_auroc': 0.8711,\n",
       "  'train_bce': 0.0334,\n",
       "  'valid_bce': 0.0754,\n",
       "  'valid_mcc': 0.4393},\n",
       " {'sensitivity': 0.5407,\n",
       "  'specificity': 0.9598,\n",
       "  'accuracy': 0.938,\n",
       "  'precision': 0.4232,\n",
       "  'mcc': 0.4461,\n",
       "  'micro_auroc': 0.8952,\n",
       "  'train_bce': 0.0285,\n",
       "  'valid_bce': 0.0525,\n",
       "  'valid_mcc': 0.4696},\n",
       " {'sensitivity': 0.866,\n",
       "  'specificity': 0.7508,\n",
       "  'accuracy': 0.7567,\n",
       "  'precision': 0.1595,\n",
       "  'mcc': 0.304,\n",
       "  'micro_auroc': 0.8964,\n",
       "  'train_bce': 0.0269,\n",
       "  'valid_bce': 0.0281,\n",
       "  'valid_mcc': 0.3747},\n",
       " {'sensitivity': 0.6013,\n",
       "  'specificity': 0.9565,\n",
       "  'accuracy': 0.9381,\n",
       "  'precision': 0.4304,\n",
       "  'mcc': 0.4771,\n",
       "  'micro_auroc': 0.9143,\n",
       "  'train_bce': 0.0182,\n",
       "  'valid_bce': 0.045,\n",
       "  'valid_mcc': 0.5039},\n",
       " {'sensitivity': 0.7384,\n",
       "  'specificity': 0.9092,\n",
       "  'accuracy': 0.9004,\n",
       "  'precision': 0.3076,\n",
       "  'mcc': 0.435,\n",
       "  'micro_auroc': 0.9135,\n",
       "  'train_bce': 0.0113,\n",
       "  'valid_bce': 0.0359,\n",
       "  'valid_mcc': 0.4546},\n",
       " {'sensitivity': 0.7847,\n",
       "  'specificity': 0.8793,\n",
       "  'accuracy': 0.8744,\n",
       "  'precision': 0.262,\n",
       "  'mcc': 0.4064,\n",
       "  'micro_auroc': 0.9149,\n",
       "  'train_bce': 0.009,\n",
       "  'valid_bce': 0.0344,\n",
       "  'valid_mcc': 0.4514},\n",
       " {'sensitivity': 0.4322,\n",
       "  'specificity': 0.9863,\n",
       "  'accuracy': 0.9576,\n",
       "  'precision': 0.6332,\n",
       "  'mcc': 0.5022,\n",
       "  'micro_auroc': 0.9154,\n",
       "  'train_bce': 0.006,\n",
       "  'valid_bce': 0.0911,\n",
       "  'valid_mcc': 0.5277},\n",
       " {'sensitivity': 0.5662,\n",
       "  'specificity': 0.9567,\n",
       "  'accuracy': 0.9365,\n",
       "  'precision': 0.4167,\n",
       "  'mcc': 0.453,\n",
       "  'micro_auroc': 0.9038,\n",
       "  'train_bce': 0.0053,\n",
       "  'valid_bce': 0.0634,\n",
       "  'valid_mcc': 0.4972},\n",
       " {'sensitivity': 0.5997,\n",
       "  'specificity': 0.967,\n",
       "  'accuracy': 0.948,\n",
       "  'precision': 0.498,\n",
       "  'mcc': 0.5193,\n",
       "  'micro_auroc': 0.9109,\n",
       "  'train_bce': 0.0045,\n",
       "  'valid_bce': 0.0675,\n",
       "  'valid_mcc': 0.5238},\n",
       " {'sensitivity': 0.4848,\n",
       "  'specificity': 0.9815,\n",
       "  'accuracy': 0.9558,\n",
       "  'precision': 0.5891,\n",
       "  'mcc': 0.5116,\n",
       "  'micro_auroc': 0.9074,\n",
       "  'train_bce': 0.0035,\n",
       "  'valid_bce': 0.1037,\n",
       "  'valid_mcc': 0.5198},\n",
       " {'sensitivity': 0.5789,\n",
       "  'specificity': 0.9697,\n",
       "  'accuracy': 0.9494,\n",
       "  'precision': 0.5105,\n",
       "  'mcc': 0.5171,\n",
       "  'micro_auroc': 0.9121,\n",
       "  'train_bce': 0.0025,\n",
       "  'valid_bce': 0.0738,\n",
       "  'valid_mcc': 0.5334},\n",
       " {'sensitivity': 0.4577,\n",
       "  'specificity': 0.9869,\n",
       "  'accuracy': 0.9595,\n",
       "  'precision': 0.6568,\n",
       "  'mcc': 0.5283,\n",
       "  'micro_auroc': 0.9011,\n",
       "  'train_bce': 0.003,\n",
       "  'valid_bce': 0.1187,\n",
       "  'valid_mcc': 0.5263},\n",
       " {'sensitivity': 0.4306,\n",
       "  'specificity': 0.9871,\n",
       "  'accuracy': 0.9583,\n",
       "  'precision': 0.6459,\n",
       "  'mcc': 0.507,\n",
       "  'micro_auroc': 0.9011,\n",
       "  'train_bce': 0.0037,\n",
       "  'valid_bce': 0.1067,\n",
       "  'valid_mcc': 0.5531},\n",
       " {'sensitivity': 0.4402,\n",
       "  'specificity': 0.9868,\n",
       "  'accuracy': 0.9585,\n",
       "  'precision': 0.6464,\n",
       "  'mcc': 0.513,\n",
       "  'micro_auroc': 0.8998,\n",
       "  'train_bce': 0.0023,\n",
       "  'valid_bce': 0.1069,\n",
       "  'valid_mcc': 0.5493},\n",
       " {'sensitivity': 0.3589,\n",
       "  'specificity': 0.9935,\n",
       "  'accuracy': 0.9606,\n",
       "  'precision': 0.75,\n",
       "  'mcc': 0.5022,\n",
       "  'micro_auroc': 0.8967,\n",
       "  'train_bce': 0.002,\n",
       "  'valid_bce': 0.1469,\n",
       "  'valid_mcc': 0.552},\n",
       " {'sensitivity': 0.5439,\n",
       "  'specificity': 0.9774,\n",
       "  'accuracy': 0.955,\n",
       "  'precision': 0.5683,\n",
       "  'mcc': 0.5323,\n",
       "  'micro_auroc': 0.9043,\n",
       "  'train_bce': 0.0014,\n",
       "  'valid_bce': 0.0925,\n",
       "  'valid_mcc': 0.5637},\n",
       " {'sensitivity': 0.4067,\n",
       "  'specificity': 0.9901,\n",
       "  'accuracy': 0.9599,\n",
       "  'precision': 0.6911,\n",
       "  'mcc': 0.5115,\n",
       "  'micro_auroc': 0.8954,\n",
       "  'train_bce': 0.0012,\n",
       "  'valid_bce': 0.1369,\n",
       "  'valid_mcc': 0.5523},\n",
       " {'sensitivity': 0.504,\n",
       "  'specificity': 0.9815,\n",
       "  'accuracy': 0.9568,\n",
       "  'precision': 0.5985,\n",
       "  'mcc': 0.5268,\n",
       "  'micro_auroc': 0.9094,\n",
       "  'train_bce': 0.001,\n",
       "  'valid_bce': 0.1099,\n",
       "  'valid_mcc': 0.5727},\n",
       " {'sensitivity': 0.3732,\n",
       "  'specificity': 0.993,\n",
       "  'accuracy': 0.9609,\n",
       "  'precision': 0.7452,\n",
       "  'mcc': 0.5106,\n",
       "  'micro_auroc': 0.8913,\n",
       "  'train_bce': 0.0012,\n",
       "  'valid_bce': 0.1591,\n",
       "  'valid_mcc': 0.5377},\n",
       " {'sensitivity': 0.3652,\n",
       "  'specificity': 0.9942,\n",
       "  'accuracy': 0.9616,\n",
       "  'precision': 0.7736,\n",
       "  'mcc': 0.5157,\n",
       "  'micro_auroc': 0.8935,\n",
       "  'train_bce': 0.0007,\n",
       "  'valid_bce': 0.1709,\n",
       "  'valid_mcc': 0.5619},\n",
       " {'sensitivity': 0.4003,\n",
       "  'specificity': 0.9925,\n",
       "  'accuracy': 0.9618,\n",
       "  'precision': 0.7448,\n",
       "  'mcc': 0.5292,\n",
       "  'micro_auroc': 0.8971,\n",
       "  'train_bce': 0.0008,\n",
       "  'valid_bce': 0.1574,\n",
       "  'valid_mcc': 0.5663},\n",
       " {'sensitivity': 0.5279,\n",
       "  'specificity': 0.9814,\n",
       "  'accuracy': 0.958,\n",
       "  'precision': 0.6085,\n",
       "  'mcc': 0.5449,\n",
       "  'micro_auroc': 0.9057,\n",
       "  'train_bce': 0.0008,\n",
       "  'valid_bce': 0.1118,\n",
       "  'valid_mcc': 0.5442},\n",
       " {'sensitivity': 0.3206,\n",
       "  'specificity': 0.9964,\n",
       "  'accuracy': 0.9614,\n",
       "  'precision': 0.8306,\n",
       "  'mcc': 0.5019,\n",
       "  'micro_auroc': 0.8789,\n",
       "  'train_bce': 0.0009,\n",
       "  'valid_bce': 0.2061,\n",
       "  'valid_mcc': 0.531},\n",
       " {'sensitivity': 0.3684,\n",
       "  'specificity': 0.9937,\n",
       "  'accuracy': 0.9613,\n",
       "  'precision': 0.7624,\n",
       "  'mcc': 0.5138,\n",
       "  'micro_auroc': 0.8859,\n",
       "  'train_bce': 0.0007,\n",
       "  'valid_bce': 0.1729,\n",
       "  'valid_mcc': 0.5395},\n",
       " {'sensitivity': 0.4498,\n",
       "  'specificity': 0.9887,\n",
       "  'accuracy': 0.9608,\n",
       "  'precision': 0.6845,\n",
       "  'mcc': 0.5359,\n",
       "  'micro_auroc': 0.8993,\n",
       "  'train_bce': 0.0005,\n",
       "  'valid_bce': 0.1385,\n",
       "  'valid_mcc': 0.5669},\n",
       " {'sensitivity': 0.4067,\n",
       "  'specificity': 0.9915,\n",
       "  'accuracy': 0.9613,\n",
       "  'precision': 0.7244,\n",
       "  'mcc': 0.5253,\n",
       "  'micro_auroc': 0.893,\n",
       "  'train_bce': 0.0006,\n",
       "  'valid_bce': 0.157,\n",
       "  'valid_mcc': 0.5627},\n",
       " {'sensitivity': 0.3987,\n",
       "  'specificity': 0.9928,\n",
       "  'accuracy': 0.962,\n",
       "  'precision': 0.7508,\n",
       "  'mcc': 0.5305,\n",
       "  'micro_auroc': 0.8866,\n",
       "  'train_bce': 0.0004,\n",
       "  'valid_bce': 0.1657,\n",
       "  'valid_mcc': 0.5628},\n",
       " {'sensitivity': 0.3828,\n",
       "  'specificity': 0.9934,\n",
       "  'accuracy': 0.9618,\n",
       "  'precision': 0.7595,\n",
       "  'mcc': 0.5228,\n",
       "  'micro_auroc': 0.885,\n",
       "  'train_bce': 0.0003,\n",
       "  'valid_bce': 0.1733,\n",
       "  'valid_mcc': 0.5538}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(lr=1e-3, gamma=0.906) # 7번 돌리면 0.5배로 줄어듬\n",
    "\n",
    "pipeline.train_until_fit(\n",
    "    patience=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensitivity': 0.7464, 'specificity': 0.8268, 'accuracy': 0.8226, 'precision': 0.1906, 'mcc': 0.3159, 'micro_auroc': 0.8799, 'train_bce': 0.0443, 'valid_bce': 0.0314, 'valid_mcc': 0.3519}\n",
      "{'sensitivity': 0.5359, 'specificity': 0.9593, 'accuracy': 0.9374, 'precision': 0.4184, 'mcc': 0.441, 'micro_auroc': 0.898, 'train_bce': 0.0301, 'valid_bce': 0.0402, 'valid_mcc': 0.4548}\n",
      "{'sensitivity': 0.8357, 'specificity': 0.8505, 'accuracy': 0.8497, 'precision': 0.2339, 'mcc': 0.3916, 'micro_auroc': 0.9248, 'train_bce': 0.0217, 'valid_bce': 0.0277, 'valid_mcc': 0.4373}\n",
      "{'sensitivity': 0.638, 'specificity': 0.9376, 'accuracy': 0.9221, 'precision': 0.3584, 'mcc': 0.4409, 'micro_auroc': 0.9115, 'train_bce': 0.02, 'valid_bce': 0.0357, 'valid_mcc': 0.527}\n",
      "{'sensitivity': 0.638, 'specificity': 0.9602, 'accuracy': 0.9435, 'precision': 0.4667, 'mcc': 0.5168, 'micro_auroc': 0.9238, 'train_bce': 0.0132, 'valid_bce': 0.0404, 'valid_mcc': 0.5781}\n",
      "{'sensitivity': 0.5949, 'specificity': 0.9671, 'accuracy': 0.9478, 'precision': 0.4967, 'mcc': 0.5163, 'micro_auroc': 0.9268, 'train_bce': 0.0096, 'valid_bce': 0.0468, 'valid_mcc': 0.5488}\n",
      "{'sensitivity': 0.6124, 'specificity': 0.9699, 'accuracy': 0.9513, 'precision': 0.526, 'mcc': 0.5421, 'micro_auroc': 0.9311, 'train_bce': 0.0074, 'valid_bce': 0.0564, 'valid_mcc': 0.5788}\n",
      "{'sensitivity': 0.7927, 'specificity': 0.911, 'accuracy': 0.9048, 'precision': 0.3272, 'mcc': 0.4707, 'micro_auroc': 0.9314, 'train_bce': 0.0055, 'valid_bce': 0.0328, 'valid_mcc': 0.4991}\n",
      "{'sensitivity': 0.8485, 'specificity': 0.8378, 'accuracy': 0.8383, 'precision': 0.2222, 'mcc': 0.3818, 'micro_auroc': 0.9157, 'train_bce': 0.0048, 'valid_bce': 0.0347, 'valid_mcc': 0.3821}\n",
      "{'sensitivity': 0.6364, 'specificity': 0.9723, 'accuracy': 0.9549, 'precision': 0.5565, 'mcc': 0.5714, 'micro_auroc': 0.9308, 'train_bce': 0.0039, 'valid_bce': 0.0504, 'valid_mcc': 0.5914}\n",
      "{'sensitivity': 0.5343, 'specificity': 0.9853, 'accuracy': 0.9619, 'precision': 0.6647, 'mcc': 0.5764, 'micro_auroc': 0.9173, 'train_bce': 0.0033, 'valid_bce': 0.0702, 'valid_mcc': 0.6069}\n",
      "{'sensitivity': 0.6172, 'specificity': 0.9755, 'accuracy': 0.957, 'precision': 0.5793, 'mcc': 0.5753, 'micro_auroc': 0.9287, 'train_bce': 0.0021, 'valid_bce': 0.0564, 'valid_mcc': 0.6029}\n",
      "{'sensitivity': 0.547, 'specificity': 0.9837, 'accuracy': 0.9611, 'precision': 0.6472, 'mcc': 0.5749, 'micro_auroc': 0.9198, 'train_bce': 0.003, 'valid_bce': 0.0702, 'valid_mcc': 0.6013}\n",
      "{'sensitivity': 0.4083, 'specificity': 0.993, 'accuracy': 0.9627, 'precision': 0.7619, 'mcc': 0.5414, 'micro_auroc': 0.899, 'train_bce': 0.0026, 'valid_bce': 0.1012, 'valid_mcc': 0.6237}\n",
      "{'sensitivity': 0.5359, 'specificity': 0.9853, 'accuracy': 0.962, 'precision': 0.6653, 'mcc': 0.5777, 'micro_auroc': 0.9206, 'train_bce': 0.002, 'valid_bce': 0.0848, 'valid_mcc': 0.6224}\n",
      "{'sensitivity': 0.4769, 'specificity': 0.9909, 'accuracy': 0.9642, 'precision': 0.7401, 'mcc': 0.5771, 'micro_auroc': 0.9138, 'train_bce': 0.0016, 'valid_bce': 0.1017, 'valid_mcc': 0.6119}\n",
      "{'sensitivity': 0.5678, 'specificity': 0.9824, 'accuracy': 0.9609, 'precision': 0.638, 'mcc': 0.5815, 'micro_auroc': 0.9179, 'train_bce': 0.0012, 'valid_bce': 0.0821, 'valid_mcc': 0.6305}\n",
      "{'sensitivity': 0.5311, 'specificity': 0.9877, 'accuracy': 0.9641, 'precision': 0.7025, 'mcc': 0.5928, 'micro_auroc': 0.9146, 'train_bce': 0.0012, 'valid_bce': 0.0965, 'valid_mcc': 0.6262}\n",
      "{'sensitivity': 0.5152, 'specificity': 0.9882, 'accuracy': 0.9637, 'precision': 0.7052, 'mcc': 0.5847, 'micro_auroc': 0.9136, 'train_bce': 0.0014, 'valid_bce': 0.1021, 'valid_mcc': 0.6344}\n",
      "{'sensitivity': 0.445, 'specificity': 0.9935, 'accuracy': 0.9651, 'precision': 0.7881, 'mcc': 0.5767, 'micro_auroc': 0.8978, 'train_bce': 0.0015, 'valid_bce': 0.1238, 'valid_mcc': 0.6089}\n",
      "{'sensitivity': 0.5215, 'specificity': 0.9894, 'accuracy': 0.9651, 'precision': 0.7283, 'mcc': 0.5991, 'micro_auroc': 0.9156, 'train_bce': 0.001, 'valid_bce': 0.108, 'valid_mcc': 0.6299}\n",
      "{'sensitivity': 0.4242, 'specificity': 0.9937, 'accuracy': 0.9642, 'precision': 0.787, 'mcc': 0.5622, 'micro_auroc': 0.905, 'train_bce': 0.001, 'valid_bce': 0.131, 'valid_mcc': 0.618}\n",
      "{'sensitivity': 0.5694, 'specificity': 0.9834, 'accuracy': 0.962, 'precision': 0.6527, 'mcc': 0.5898, 'micro_auroc': 0.9149, 'train_bce': 0.0006, 'valid_bce': 0.086, 'valid_mcc': 0.6255}\n",
      "{'sensitivity': 0.4099, 'specificity': 0.9943, 'accuracy': 0.964, 'precision': 0.7957, 'mcc': 0.5558, 'micro_auroc': 0.8976, 'train_bce': 0.0009, 'valid_bce': 0.1286, 'valid_mcc': 0.6285}\n",
      "{'sensitivity': 0.4354, 'specificity': 0.9943, 'accuracy': 0.9654, 'precision': 0.8077, 'mcc': 0.5781, 'micro_auroc': 0.896, 'train_bce': 0.0006, 'valid_bce': 0.1274, 'valid_mcc': 0.6186}\n",
      "{'sensitivity': 0.4545, 'specificity': 0.9934, 'accuracy': 0.9655, 'precision': 0.7895, 'mcc': 0.5836, 'micro_auroc': 0.8982, 'train_bce': 0.0004, 'valid_bce': 0.1257, 'valid_mcc': 0.6274}\n",
      "{'sensitivity': 0.4817, 'specificity': 0.9918, 'accuracy': 0.9654, 'precision': 0.7626, 'mcc': 0.5899, 'micro_auroc': 0.9009, 'train_bce': 0.0004, 'valid_bce': 0.1197, 'valid_mcc': 0.63}\n",
      "{'sensitivity': 0.4274, 'specificity': 0.9949, 'accuracy': 0.9655, 'precision': 0.8196, 'mcc': 0.5773, 'micro_auroc': 0.8948, 'train_bce': 0.0004, 'valid_bce': 0.1388, 'valid_mcc': 0.6184}\n",
      "{'sensitivity': 0.4466, 'specificity': 0.9929, 'accuracy': 0.9646, 'precision': 0.7756, 'mcc': 0.5726, 'micro_auroc': 0.8959, 'train_bce': 0.0002, 'valid_bce': 0.1339, 'valid_mcc': 0.6186}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'sensitivity': 0.7464,\n",
       "  'specificity': 0.8268,\n",
       "  'accuracy': 0.8226,\n",
       "  'precision': 0.1906,\n",
       "  'mcc': 0.3159,\n",
       "  'micro_auroc': 0.8799,\n",
       "  'train_bce': 0.0443,\n",
       "  'valid_bce': 0.0314,\n",
       "  'valid_mcc': 0.3519},\n",
       " {'sensitivity': 0.5359,\n",
       "  'specificity': 0.9593,\n",
       "  'accuracy': 0.9374,\n",
       "  'precision': 0.4184,\n",
       "  'mcc': 0.441,\n",
       "  'micro_auroc': 0.898,\n",
       "  'train_bce': 0.0301,\n",
       "  'valid_bce': 0.0402,\n",
       "  'valid_mcc': 0.4548},\n",
       " {'sensitivity': 0.8357,\n",
       "  'specificity': 0.8505,\n",
       "  'accuracy': 0.8497,\n",
       "  'precision': 0.2339,\n",
       "  'mcc': 0.3916,\n",
       "  'micro_auroc': 0.9248,\n",
       "  'train_bce': 0.0217,\n",
       "  'valid_bce': 0.0277,\n",
       "  'valid_mcc': 0.4373},\n",
       " {'sensitivity': 0.638,\n",
       "  'specificity': 0.9376,\n",
       "  'accuracy': 0.9221,\n",
       "  'precision': 0.3584,\n",
       "  'mcc': 0.4409,\n",
       "  'micro_auroc': 0.9115,\n",
       "  'train_bce': 0.02,\n",
       "  'valid_bce': 0.0357,\n",
       "  'valid_mcc': 0.527},\n",
       " {'sensitivity': 0.638,\n",
       "  'specificity': 0.9602,\n",
       "  'accuracy': 0.9435,\n",
       "  'precision': 0.4667,\n",
       "  'mcc': 0.5168,\n",
       "  'micro_auroc': 0.9238,\n",
       "  'train_bce': 0.0132,\n",
       "  'valid_bce': 0.0404,\n",
       "  'valid_mcc': 0.5781},\n",
       " {'sensitivity': 0.5949,\n",
       "  'specificity': 0.9671,\n",
       "  'accuracy': 0.9478,\n",
       "  'precision': 0.4967,\n",
       "  'mcc': 0.5163,\n",
       "  'micro_auroc': 0.9268,\n",
       "  'train_bce': 0.0096,\n",
       "  'valid_bce': 0.0468,\n",
       "  'valid_mcc': 0.5488},\n",
       " {'sensitivity': 0.6124,\n",
       "  'specificity': 0.9699,\n",
       "  'accuracy': 0.9513,\n",
       "  'precision': 0.526,\n",
       "  'mcc': 0.5421,\n",
       "  'micro_auroc': 0.9311,\n",
       "  'train_bce': 0.0074,\n",
       "  'valid_bce': 0.0564,\n",
       "  'valid_mcc': 0.5788},\n",
       " {'sensitivity': 0.7927,\n",
       "  'specificity': 0.911,\n",
       "  'accuracy': 0.9048,\n",
       "  'precision': 0.3272,\n",
       "  'mcc': 0.4707,\n",
       "  'micro_auroc': 0.9314,\n",
       "  'train_bce': 0.0055,\n",
       "  'valid_bce': 0.0328,\n",
       "  'valid_mcc': 0.4991},\n",
       " {'sensitivity': 0.8485,\n",
       "  'specificity': 0.8378,\n",
       "  'accuracy': 0.8383,\n",
       "  'precision': 0.2222,\n",
       "  'mcc': 0.3818,\n",
       "  'micro_auroc': 0.9157,\n",
       "  'train_bce': 0.0048,\n",
       "  'valid_bce': 0.0347,\n",
       "  'valid_mcc': 0.3821},\n",
       " {'sensitivity': 0.6364,\n",
       "  'specificity': 0.9723,\n",
       "  'accuracy': 0.9549,\n",
       "  'precision': 0.5565,\n",
       "  'mcc': 0.5714,\n",
       "  'micro_auroc': 0.9308,\n",
       "  'train_bce': 0.0039,\n",
       "  'valid_bce': 0.0504,\n",
       "  'valid_mcc': 0.5914},\n",
       " {'sensitivity': 0.5343,\n",
       "  'specificity': 0.9853,\n",
       "  'accuracy': 0.9619,\n",
       "  'precision': 0.6647,\n",
       "  'mcc': 0.5764,\n",
       "  'micro_auroc': 0.9173,\n",
       "  'train_bce': 0.0033,\n",
       "  'valid_bce': 0.0702,\n",
       "  'valid_mcc': 0.6069},\n",
       " {'sensitivity': 0.6172,\n",
       "  'specificity': 0.9755,\n",
       "  'accuracy': 0.957,\n",
       "  'precision': 0.5793,\n",
       "  'mcc': 0.5753,\n",
       "  'micro_auroc': 0.9287,\n",
       "  'train_bce': 0.0021,\n",
       "  'valid_bce': 0.0564,\n",
       "  'valid_mcc': 0.6029},\n",
       " {'sensitivity': 0.547,\n",
       "  'specificity': 0.9837,\n",
       "  'accuracy': 0.9611,\n",
       "  'precision': 0.6472,\n",
       "  'mcc': 0.5749,\n",
       "  'micro_auroc': 0.9198,\n",
       "  'train_bce': 0.003,\n",
       "  'valid_bce': 0.0702,\n",
       "  'valid_mcc': 0.6013},\n",
       " {'sensitivity': 0.4083,\n",
       "  'specificity': 0.993,\n",
       "  'accuracy': 0.9627,\n",
       "  'precision': 0.7619,\n",
       "  'mcc': 0.5414,\n",
       "  'micro_auroc': 0.899,\n",
       "  'train_bce': 0.0026,\n",
       "  'valid_bce': 0.1012,\n",
       "  'valid_mcc': 0.6237},\n",
       " {'sensitivity': 0.5359,\n",
       "  'specificity': 0.9853,\n",
       "  'accuracy': 0.962,\n",
       "  'precision': 0.6653,\n",
       "  'mcc': 0.5777,\n",
       "  'micro_auroc': 0.9206,\n",
       "  'train_bce': 0.002,\n",
       "  'valid_bce': 0.0848,\n",
       "  'valid_mcc': 0.6224},\n",
       " {'sensitivity': 0.4769,\n",
       "  'specificity': 0.9909,\n",
       "  'accuracy': 0.9642,\n",
       "  'precision': 0.7401,\n",
       "  'mcc': 0.5771,\n",
       "  'micro_auroc': 0.9138,\n",
       "  'train_bce': 0.0016,\n",
       "  'valid_bce': 0.1017,\n",
       "  'valid_mcc': 0.6119},\n",
       " {'sensitivity': 0.5678,\n",
       "  'specificity': 0.9824,\n",
       "  'accuracy': 0.9609,\n",
       "  'precision': 0.638,\n",
       "  'mcc': 0.5815,\n",
       "  'micro_auroc': 0.9179,\n",
       "  'train_bce': 0.0012,\n",
       "  'valid_bce': 0.0821,\n",
       "  'valid_mcc': 0.6305},\n",
       " {'sensitivity': 0.5311,\n",
       "  'specificity': 0.9877,\n",
       "  'accuracy': 0.9641,\n",
       "  'precision': 0.7025,\n",
       "  'mcc': 0.5928,\n",
       "  'micro_auroc': 0.9146,\n",
       "  'train_bce': 0.0012,\n",
       "  'valid_bce': 0.0965,\n",
       "  'valid_mcc': 0.6262},\n",
       " {'sensitivity': 0.5152,\n",
       "  'specificity': 0.9882,\n",
       "  'accuracy': 0.9637,\n",
       "  'precision': 0.7052,\n",
       "  'mcc': 0.5847,\n",
       "  'micro_auroc': 0.9136,\n",
       "  'train_bce': 0.0014,\n",
       "  'valid_bce': 0.1021,\n",
       "  'valid_mcc': 0.6344},\n",
       " {'sensitivity': 0.445,\n",
       "  'specificity': 0.9935,\n",
       "  'accuracy': 0.9651,\n",
       "  'precision': 0.7881,\n",
       "  'mcc': 0.5767,\n",
       "  'micro_auroc': 0.8978,\n",
       "  'train_bce': 0.0015,\n",
       "  'valid_bce': 0.1238,\n",
       "  'valid_mcc': 0.6089},\n",
       " {'sensitivity': 0.5215,\n",
       "  'specificity': 0.9894,\n",
       "  'accuracy': 0.9651,\n",
       "  'precision': 0.7283,\n",
       "  'mcc': 0.5991,\n",
       "  'micro_auroc': 0.9156,\n",
       "  'train_bce': 0.001,\n",
       "  'valid_bce': 0.108,\n",
       "  'valid_mcc': 0.6299},\n",
       " {'sensitivity': 0.4242,\n",
       "  'specificity': 0.9937,\n",
       "  'accuracy': 0.9642,\n",
       "  'precision': 0.787,\n",
       "  'mcc': 0.5622,\n",
       "  'micro_auroc': 0.905,\n",
       "  'train_bce': 0.001,\n",
       "  'valid_bce': 0.131,\n",
       "  'valid_mcc': 0.618},\n",
       " {'sensitivity': 0.5694,\n",
       "  'specificity': 0.9834,\n",
       "  'accuracy': 0.962,\n",
       "  'precision': 0.6527,\n",
       "  'mcc': 0.5898,\n",
       "  'micro_auroc': 0.9149,\n",
       "  'train_bce': 0.0006,\n",
       "  'valid_bce': 0.086,\n",
       "  'valid_mcc': 0.6255},\n",
       " {'sensitivity': 0.4099,\n",
       "  'specificity': 0.9943,\n",
       "  'accuracy': 0.964,\n",
       "  'precision': 0.7957,\n",
       "  'mcc': 0.5558,\n",
       "  'micro_auroc': 0.8976,\n",
       "  'train_bce': 0.0009,\n",
       "  'valid_bce': 0.1286,\n",
       "  'valid_mcc': 0.6285},\n",
       " {'sensitivity': 0.4354,\n",
       "  'specificity': 0.9943,\n",
       "  'accuracy': 0.9654,\n",
       "  'precision': 0.8077,\n",
       "  'mcc': 0.5781,\n",
       "  'micro_auroc': 0.896,\n",
       "  'train_bce': 0.0006,\n",
       "  'valid_bce': 0.1274,\n",
       "  'valid_mcc': 0.6186},\n",
       " {'sensitivity': 0.4545,\n",
       "  'specificity': 0.9934,\n",
       "  'accuracy': 0.9655,\n",
       "  'precision': 0.7895,\n",
       "  'mcc': 0.5836,\n",
       "  'micro_auroc': 0.8982,\n",
       "  'train_bce': 0.0004,\n",
       "  'valid_bce': 0.1257,\n",
       "  'valid_mcc': 0.6274},\n",
       " {'sensitivity': 0.4817,\n",
       "  'specificity': 0.9918,\n",
       "  'accuracy': 0.9654,\n",
       "  'precision': 0.7626,\n",
       "  'mcc': 0.5899,\n",
       "  'micro_auroc': 0.9009,\n",
       "  'train_bce': 0.0004,\n",
       "  'valid_bce': 0.1197,\n",
       "  'valid_mcc': 0.63},\n",
       " {'sensitivity': 0.4274,\n",
       "  'specificity': 0.9949,\n",
       "  'accuracy': 0.9655,\n",
       "  'precision': 0.8196,\n",
       "  'mcc': 0.5773,\n",
       "  'micro_auroc': 0.8948,\n",
       "  'train_bce': 0.0004,\n",
       "  'valid_bce': 0.1388,\n",
       "  'valid_mcc': 0.6184},\n",
       " {'sensitivity': 0.4466,\n",
       "  'specificity': 0.9929,\n",
       "  'accuracy': 0.9646,\n",
       "  'precision': 0.7756,\n",
       "  'mcc': 0.5726,\n",
       "  'micro_auroc': 0.8959,\n",
       "  'train_bce': 0.0002,\n",
       "  'valid_bce': 0.1339,\n",
       "  'valid_mcc': 0.6186}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(lr=5e-4, gamma=0.926) # 9번 돌리면 0.5배로 줄어듬\n",
    "\n",
    "pipeline.train_until_fit(\n",
    "    patience=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
