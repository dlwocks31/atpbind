{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get dataset atpbind3d\n",
      "Split num:  [337, 41, 41]\n",
      "train samples: 337, valid samples: 41, test samples: 41\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from lib.pipeline import Pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchdrug import utils, data\n",
    "from lib.disable_logger import DisableLogger\n",
    "\n",
    "GPU = 1\n",
    "device = f'cuda:{GPU}'\n",
    "pipeline = Pipeline(\n",
    "    model='lm-gearnet',\n",
    "    dataset='atpbind3d',\n",
    "    gpus=[GPU],\n",
    "    model_kwargs={\n",
    "        'gpu': GPU,\n",
    "        'gearnet_hidden_dim_size': 512,\n",
    "        'gearnet_hidden_dim_count': 4,\n",
    "        'bert_freeze': False,\n",
    "        'bert_freeze_layer_count': 29,\n",
    "    },\n",
    "    batch_size=16,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:03:55   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "15:03:55   Evaluate on test\n",
      "15:03:58   ------------------------------\n",
      "15:03:58   accuracy: 0.961755\n",
      "15:03:58   mcc: 0.602686\n",
      "15:03:58   micro_auroc: 0.918718\n",
      "15:03:58   precision: 0.636667\n",
      "15:03:58   sensitivity: 0.60925\n",
      "15:03:58   specificity: 0.981009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sensitivity': 0.6092504262924194,\n",
       " 'specificity': 0.9810088276863098,\n",
       " 'accuracy': 0.9617545008659363,\n",
       " 'precision': 0.6366666555404663,\n",
       " 'mcc': 0.6026855116250789,\n",
       " 'micro_auroc': 0.9187183380126953}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = 'rus_5_0_0.6151.pth'\n",
    "\n",
    "pipeline.task.load_state_dict(torch.load(sample_weight, map_location=device), strict=False)\n",
    "pipeline.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-17.3298, -13.4945, -18.2039, -18.6461, -21.5239, -16.4441, -18.9187,\n",
       "        -13.5679, -20.7809, -17.0364, -19.8048, -23.1246, -13.9346, -18.5860,\n",
       "        -21.9744, -13.0965, -17.6263, -18.4483, -12.7355,  -7.1648, -14.3571,\n",
       "        -14.7658, -19.6489, -14.5633, -16.9808,  -9.8912,  -9.9540, -10.7494,\n",
       "        -13.9948, -16.5773, -14.5978, -10.6935, -17.8283, -15.3989, -24.0926,\n",
       "        -24.9417, -14.6402, -19.4090, -14.0754, -17.2853, -18.2780, -13.2628,\n",
       "        -10.0945, -19.3690, -13.4677,  -7.4248,  -9.1188, -15.4757,  -7.8211,\n",
       "         -1.2059, -17.9829, -18.0884, -19.3422, -13.7677, -17.3163, -19.6624,\n",
       "        -15.1668, -14.9212, -19.8480, -12.7032, -16.1524, -13.5441, -15.8736,\n",
       "        -23.1825, -16.7432, -21.6519, -20.3948, -19.5762, -18.5159, -21.4604,\n",
       "        -13.4027, -23.6826, -20.0617, -13.5578, -15.3785, -20.7205, -15.1174,\n",
       "        -14.9235, -20.8893, -24.3910, -19.8693, -19.2163, -18.1511, -18.7869,\n",
       "        -21.7641, -14.3211, -19.3652, -21.8818, -22.0049, -24.3006, -18.2163,\n",
       "        -16.5427, -13.0588, -11.8593, -20.3134, -13.3393, -14.0973, -19.6358,\n",
       "        -16.5899, -14.7844, -17.2770, -26.0975, -17.3350, -14.5263, -16.3596,\n",
       "        -22.3279, -16.6800, -18.5581, -18.6363, -22.3193, -17.1929, -18.8253,\n",
       "        -25.9277, -17.6834, -20.6580, -18.3029, -18.7591, -21.5386, -23.5328,\n",
       "        -18.6055, -11.4547, -12.6356, -19.5362, -15.3127, -22.3662, -24.4287,\n",
       "        -17.0289, -18.1347, -12.2836, -14.6575,  -4.0021, -15.9982, -16.7547,\n",
       "         -7.7615, -15.2742, -18.1377, -16.9886, -10.1274, -15.2498, -18.6934,\n",
       "        -20.9174, -26.3741, -24.3693, -17.9486, -24.2267, -18.1685, -20.2387,\n",
       "        -12.7095, -26.0181, -22.0333, -17.0379, -20.2340, -21.6445, -23.6202,\n",
       "        -11.5794, -19.0710, -15.2302, -16.7805, -11.3773, -13.6999, -21.7898,\n",
       "        -22.7150, -21.5648, -22.1802, -20.0959, -29.2442, -19.3812, -10.7526,\n",
       "        -22.0552, -19.8925, -23.4326, -17.2054, -18.7641, -15.7829,  -8.9079,\n",
       "        -14.9948, -18.3803, -15.6744, -11.3190, -22.1535, -15.8828, -15.5058,\n",
       "        -17.1708, -19.2015, -17.7626, -26.7315, -18.3282, -18.8926, -24.0272,\n",
       "        -27.5709, -25.4953, -22.9246, -15.9523, -15.3167, -11.1257,  -8.6246,\n",
       "        -12.4421, -14.7195,  -9.2100,  -7.9552, -16.4002, -12.2940, -12.4652,\n",
       "        -13.1372, -15.1459, -15.6184, -10.4009,  -5.7421,  -5.0185, -23.7839,\n",
       "        -17.0140, -18.7137, -11.0403, -21.3912, -23.4603, -13.0680, -14.0813,\n",
       "        -20.3342, -17.1386, -17.1622, -23.9825, -18.2386, -20.9008,  -7.2000,\n",
       "        -14.7206, -17.8831, -13.1493, -14.8269, -18.9710, -19.0682, -29.8819,\n",
       "        -24.9448, -13.6087, -22.4309, -18.7959, -22.1099, -14.6575, -12.9516,\n",
       "        -17.9991, -22.5422, -22.5719, -23.1538, -20.0183, -18.8576, -13.6053,\n",
       "        -12.8991, -11.3157,  -7.3835,  -3.1575, -16.2545,  -6.8243,  -8.3340,\n",
       "        -16.1543, -17.3286, -19.9810, -13.7519,  -5.7208,  -5.4513,  -7.4515,\n",
       "         -7.5740,  -7.6283, -17.8683, -10.3377,  -6.2041, -16.0144,  -7.0386,\n",
       "        -11.6984, -11.2260,  -5.6022,  -8.1246, -20.5322, -16.0019, -12.7460,\n",
       "         -8.6574, -12.2664, -20.9959, -11.1456, -10.8349, -10.1986, -13.9814,\n",
       "         -8.5521,  -9.9995, -11.1244, -11.5141, -12.5892, -12.4076, -14.5449,\n",
       "         -7.4155, -21.7503,  -7.3428, -10.5429, -10.2777, -11.9034, -11.6464,\n",
       "         -8.0992, -15.4648, -16.1611, -16.9862, -11.2447, -19.4618, -16.5063,\n",
       "         -9.2968, -18.1353, -16.2011, -18.9148, -22.9190, -21.8639, -22.2257,\n",
       "        -27.8936, -20.6222, -13.0755,  -3.7206,  -9.5723, -12.2020,   9.7543,\n",
       "          6.3626,   5.5549,  -0.0662,  -9.5768,  -3.8542,   5.2809,   4.3819,\n",
       "         -9.3513,   9.4873, -14.2402, -12.2240, -14.5394, -18.4273, -14.1215,\n",
       "        -15.7588, -14.5453,  -6.2317,   8.5449, -18.3655,   7.4654, -23.1374,\n",
       "         -8.1132,  -4.4859, -10.3418, -19.1129, -11.5943,  -8.7548, -13.1993,\n",
       "         -1.4209, -14.0592, -16.4041, -17.8045, -13.9243, -12.8289, -15.0809],\n",
       "       device='cuda:1', grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pipeline.train_set\n",
    "pipeline.task.eval()\n",
    "dataloader = data.DataLoader(train_set, batch_size=1, shuffle=False)\n",
    "first_batch = utils.cuda(next(iter(dataloader)), device=device)\n",
    "\n",
    "pred = pipeline.task.predict(first_batch)\n",
    "pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pipeline.task.target(first_batch)\n",
    "label = target['label'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "for i in label:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "def create_pred_dataframe(pipeline, dataset, weights):\n",
    "    weights_loaded = [\n",
    "        torch.load(weight, map_location='cpu') for weight in weights\n",
    "    ]\n",
    "    df = pd.DataFrame()\n",
    "    pipeline.task.eval()\n",
    "    for protein_index, batch in enumerate(data.DataLoader(dataset, batch_size=1, shuffle=False)):\n",
    "        batch = utils.cuda(batch, device=device)\n",
    "        if protein_index % 10 == 9:\n",
    "            print(f'processing protein {protein_index + 1} / {len(dataset)}')\n",
    "        label = pipeline.task.target(batch)['label'].flatten()\n",
    "        \n",
    "        new_data = {\n",
    "            'protein_index': protein_index,\n",
    "            'residue_index': list(range(len(label))),\n",
    "            'target': label.tolist(),\n",
    "        }\n",
    "        for i, weight in enumerate(weights_loaded):\n",
    "            pipeline.task.load_state_dict(utils.cuda(weight, device=device) , strict=False)\n",
    "            pred = pipeline.task.predict(batch).flatten()\n",
    "            assert(len(label) == len(pred))\n",
    "            new_data[f'pred_{i}'] = [round(t, 5) for t in pred.tolist()]\n",
    "        new_data = pd.DataFrame(new_data)\n",
    "        df = pd.concat([df, new_data])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing protein 10 / 41\n",
      "processing protein 20 / 41\n",
      "processing protein 30 / 41\n",
      "processing protein 40 / 41\n"
     ]
    }
   ],
   "source": [
    "weights = [\n",
    "    'rus_5_0_0.6151.pth',\n",
    "    'rus_5_1_0.6221.pth',\n",
    "    'rus_5_2_0.6193.pth',\n",
    "    'rus_5_3_0.6266.pth',\n",
    "    'rus_5_4_0.6052.pth',\n",
    "    'rus_5_5_0.6085.pth',\n",
    "    'rus_5_6_0.5986.pth',\n",
    "    'rus_5_7_0.6108.pth',\n",
    "    'rus_5_8_0.6046.pth',\n",
    "    'rus_5_9_0.6080.pth',\n",
    "]\n",
    "\n",
    "df_valid = create_pred_dataframe(\n",
    "    pipeline, \n",
    "    dataset=pipeline.valid_set,\n",
    "    weights=weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_index</th>\n",
       "      <th>residue_index</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.97174</td>\n",
       "      <td>-7.91394</td>\n",
       "      <td>-16.05915</td>\n",
       "      <td>-12.74630</td>\n",
       "      <td>-11.08699</td>\n",
       "      <td>-7.19023</td>\n",
       "      <td>-13.97244</td>\n",
       "      <td>-6.04126</td>\n",
       "      <td>-9.91471</td>\n",
       "      <td>-12.43732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.93672</td>\n",
       "      <td>-9.47368</td>\n",
       "      <td>-10.20510</td>\n",
       "      <td>-11.30398</td>\n",
       "      <td>-4.25183</td>\n",
       "      <td>-7.08744</td>\n",
       "      <td>-14.01429</td>\n",
       "      <td>-3.18227</td>\n",
       "      <td>-3.96673</td>\n",
       "      <td>-11.00722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.56091</td>\n",
       "      <td>-15.97469</td>\n",
       "      <td>-15.18720</td>\n",
       "      <td>-21.67062</td>\n",
       "      <td>-15.45335</td>\n",
       "      <td>-13.68504</td>\n",
       "      <td>-18.13901</td>\n",
       "      <td>-13.80445</td>\n",
       "      <td>-13.61160</td>\n",
       "      <td>-16.70308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.38626</td>\n",
       "      <td>-16.23427</td>\n",
       "      <td>-12.79903</td>\n",
       "      <td>-14.91800</td>\n",
       "      <td>-13.64695</td>\n",
       "      <td>-13.11994</td>\n",
       "      <td>-15.92172</td>\n",
       "      <td>-9.01989</td>\n",
       "      <td>-11.00765</td>\n",
       "      <td>-15.36380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.65767</td>\n",
       "      <td>-15.40561</td>\n",
       "      <td>-16.41979</td>\n",
       "      <td>-15.94792</td>\n",
       "      <td>-18.58216</td>\n",
       "      <td>-14.66701</td>\n",
       "      <td>-21.26510</td>\n",
       "      <td>-7.42877</td>\n",
       "      <td>-15.56406</td>\n",
       "      <td>-14.34236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>40</td>\n",
       "      <td>278</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.46217</td>\n",
       "      <td>-14.70327</td>\n",
       "      <td>-20.71081</td>\n",
       "      <td>-20.23520</td>\n",
       "      <td>-17.61584</td>\n",
       "      <td>-17.37701</td>\n",
       "      <td>-28.19762</td>\n",
       "      <td>-27.83505</td>\n",
       "      <td>-18.98898</td>\n",
       "      <td>-15.21086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>40</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.57654</td>\n",
       "      <td>-3.02167</td>\n",
       "      <td>-7.41655</td>\n",
       "      <td>-16.22624</td>\n",
       "      <td>-7.21401</td>\n",
       "      <td>-10.21475</td>\n",
       "      <td>-6.51724</td>\n",
       "      <td>-15.95897</td>\n",
       "      <td>-10.69379</td>\n",
       "      <td>-8.39563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>40</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>-20.50487</td>\n",
       "      <td>-15.59969</td>\n",
       "      <td>-10.36148</td>\n",
       "      <td>-22.97976</td>\n",
       "      <td>-14.24386</td>\n",
       "      <td>-13.29326</td>\n",
       "      <td>-14.06623</td>\n",
       "      <td>-21.75292</td>\n",
       "      <td>-16.84909</td>\n",
       "      <td>-14.99062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>40</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>-10.51467</td>\n",
       "      <td>-3.77928</td>\n",
       "      <td>-9.50453</td>\n",
       "      <td>-19.51342</td>\n",
       "      <td>-14.90506</td>\n",
       "      <td>-11.95329</td>\n",
       "      <td>-14.86140</td>\n",
       "      <td>-24.65895</td>\n",
       "      <td>-17.68014</td>\n",
       "      <td>-11.50816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>40</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.60902</td>\n",
       "      <td>-14.93028</td>\n",
       "      <td>-16.32818</td>\n",
       "      <td>-25.15844</td>\n",
       "      <td>-20.23669</td>\n",
       "      <td>-14.34312</td>\n",
       "      <td>-16.79999</td>\n",
       "      <td>-27.87189</td>\n",
       "      <td>-14.62924</td>\n",
       "      <td>-17.59373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12803 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     protein_index  residue_index  target    pred_0    pred_1    pred_2  \\\n",
       "0                0              0       0 -16.97174  -7.91394 -16.05915   \n",
       "1                0              1       0  -3.93672  -9.47368 -10.20510   \n",
       "2                0              2       0 -21.56091 -15.97469 -15.18720   \n",
       "3                0              3       0 -18.38626 -16.23427 -12.79903   \n",
       "4                0              4       0 -14.65767 -15.40561 -16.41979   \n",
       "..             ...            ...     ...       ...       ...       ...   \n",
       "278             40            278       0 -18.46217 -14.70327 -20.71081   \n",
       "279             40            279       0 -10.57654  -3.02167  -7.41655   \n",
       "280             40            280       0 -20.50487 -15.59969 -10.36148   \n",
       "281             40            281       0 -10.51467  -3.77928  -9.50453   \n",
       "282             40            282       0 -16.60902 -14.93028 -16.32818   \n",
       "\n",
       "       pred_3    pred_4    pred_5    pred_6    pred_7    pred_8    pred_9  \n",
       "0   -12.74630 -11.08699  -7.19023 -13.97244  -6.04126  -9.91471 -12.43732  \n",
       "1   -11.30398  -4.25183  -7.08744 -14.01429  -3.18227  -3.96673 -11.00722  \n",
       "2   -21.67062 -15.45335 -13.68504 -18.13901 -13.80445 -13.61160 -16.70308  \n",
       "3   -14.91800 -13.64695 -13.11994 -15.92172  -9.01989 -11.00765 -15.36380  \n",
       "4   -15.94792 -18.58216 -14.66701 -21.26510  -7.42877 -15.56406 -14.34236  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "278 -20.23520 -17.61584 -17.37701 -28.19762 -27.83505 -18.98898 -15.21086  \n",
       "279 -16.22624  -7.21401 -10.21475  -6.51724 -15.95897 -10.69379  -8.39563  \n",
       "280 -22.97976 -14.24386 -13.29326 -14.06623 -21.75292 -16.84909 -14.99062  \n",
       "281 -19.51342 -14.90506 -11.95329 -14.86140 -24.65895 -17.68014 -11.50816  \n",
       "282 -25.15844 -20.23669 -14.34312 -16.79999 -27.87189 -14.62924 -17.59373  \n",
       "\n",
       "[12803 rows x 13 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein_index</th>\n",
       "      <th>residue_index</th>\n",
       "      <th>target</th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>pred_4</th>\n",
       "      <th>pred_5</th>\n",
       "      <th>pred_6</th>\n",
       "      <th>pred_7</th>\n",
       "      <th>pred_8</th>\n",
       "      <th>pred_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16160</td>\n",
       "      <td>-1.21214</td>\n",
       "      <td>-2.43465</td>\n",
       "      <td>2.80233</td>\n",
       "      <td>5.37596</td>\n",
       "      <td>3.12021</td>\n",
       "      <td>-1.18887</td>\n",
       "      <td>2.23289</td>\n",
       "      <td>3.14200</td>\n",
       "      <td>3.93285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>0</td>\n",
       "      <td>3.86974</td>\n",
       "      <td>2.06259</td>\n",
       "      <td>4.75878</td>\n",
       "      <td>0.59927</td>\n",
       "      <td>3.70603</td>\n",
       "      <td>2.16602</td>\n",
       "      <td>2.13296</td>\n",
       "      <td>1.97036</td>\n",
       "      <td>1.53800</td>\n",
       "      <td>0.38363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>5.07940</td>\n",
       "      <td>1.53355</td>\n",
       "      <td>10.49345</td>\n",
       "      <td>6.98770</td>\n",
       "      <td>7.38976</td>\n",
       "      <td>5.20673</td>\n",
       "      <td>5.27371</td>\n",
       "      <td>6.02002</td>\n",
       "      <td>2.30119</td>\n",
       "      <td>6.67236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>3.55344</td>\n",
       "      <td>3.48452</td>\n",
       "      <td>-0.22793</td>\n",
       "      <td>0.26693</td>\n",
       "      <td>3.30486</td>\n",
       "      <td>-1.30311</td>\n",
       "      <td>-1.15516</td>\n",
       "      <td>1.65353</td>\n",
       "      <td>1.59179</td>\n",
       "      <td>3.57754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.82517</td>\n",
       "      <td>-0.47990</td>\n",
       "      <td>6.02652</td>\n",
       "      <td>2.64298</td>\n",
       "      <td>6.06695</td>\n",
       "      <td>-2.05129</td>\n",
       "      <td>0.88586</td>\n",
       "      <td>1.81419</td>\n",
       "      <td>4.90267</td>\n",
       "      <td>4.34896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>37</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>6.16719</td>\n",
       "      <td>6.63751</td>\n",
       "      <td>8.22852</td>\n",
       "      <td>11.81406</td>\n",
       "      <td>9.99815</td>\n",
       "      <td>11.91978</td>\n",
       "      <td>6.21871</td>\n",
       "      <td>5.66318</td>\n",
       "      <td>6.85949</td>\n",
       "      <td>11.58592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>37</td>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.32284</td>\n",
       "      <td>-0.26843</td>\n",
       "      <td>-0.26857</td>\n",
       "      <td>0.04339</td>\n",
       "      <td>2.97709</td>\n",
       "      <td>3.10297</td>\n",
       "      <td>-0.33467</td>\n",
       "      <td>4.16424</td>\n",
       "      <td>-1.19000</td>\n",
       "      <td>1.47427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85641</td>\n",
       "      <td>3.63775</td>\n",
       "      <td>3.75041</td>\n",
       "      <td>4.84171</td>\n",
       "      <td>2.83292</td>\n",
       "      <td>2.84886</td>\n",
       "      <td>6.25854</td>\n",
       "      <td>8.96903</td>\n",
       "      <td>7.12968</td>\n",
       "      <td>6.84633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>38</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>3.91629</td>\n",
       "      <td>3.24369</td>\n",
       "      <td>-2.35969</td>\n",
       "      <td>5.31365</td>\n",
       "      <td>2.63783</td>\n",
       "      <td>3.91696</td>\n",
       "      <td>0.75238</td>\n",
       "      <td>6.73494</td>\n",
       "      <td>3.73079</td>\n",
       "      <td>3.00311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>38</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>7.52901</td>\n",
       "      <td>5.60490</td>\n",
       "      <td>6.33661</td>\n",
       "      <td>4.93757</td>\n",
       "      <td>1.33719</td>\n",
       "      <td>6.93488</td>\n",
       "      <td>2.95996</td>\n",
       "      <td>4.61952</td>\n",
       "      <td>7.39694</td>\n",
       "      <td>4.35391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     protein_index  residue_index  target   pred_0   pred_1    pred_2  \\\n",
       "36               1             36       0  0.16160 -1.21214  -2.43465   \n",
       "162              1            162       0  3.86974  2.06259   4.75878   \n",
       "195              1            195       0  5.07940  1.53355  10.49345   \n",
       "64               2             64       0  3.55344  3.48452  -0.22793   \n",
       "89               2             89       0 -0.82517 -0.47990   6.02652   \n",
       "..             ...            ...     ...      ...      ...       ...   \n",
       "52              37             52       0  6.16719  6.63751   8.22852   \n",
       "105             37            105       0 -1.32284 -0.26843  -0.26857   \n",
       "138             38            138       0  4.85641  3.63775   3.75041   \n",
       "169             38            169       0  3.91629  3.24369  -2.35969   \n",
       "170             38            170       0  7.52901  5.60490   6.33661   \n",
       "\n",
       "       pred_3   pred_4    pred_5   pred_6   pred_7   pred_8    pred_9  \n",
       "36    2.80233  5.37596   3.12021 -1.18887  2.23289  3.14200   3.93285  \n",
       "162   0.59927  3.70603   2.16602  2.13296  1.97036  1.53800   0.38363  \n",
       "195   6.98770  7.38976   5.20673  5.27371  6.02002  2.30119   6.67236  \n",
       "64    0.26693  3.30486  -1.30311 -1.15516  1.65353  1.59179   3.57754  \n",
       "89    2.64298  6.06695  -2.05129  0.88586  1.81419  4.90267   4.34896  \n",
       "..        ...      ...       ...      ...      ...      ...       ...  \n",
       "52   11.81406  9.99815  11.91978  6.21871  5.66318  6.85949  11.58592  \n",
       "105   0.04339  2.97709   3.10297 -0.33467  4.16424 -1.19000   1.47427  \n",
       "138   4.84171  2.83292   2.84886  6.25854  8.96903  7.12968   6.84633  \n",
       "169   5.31365  2.63783   3.91696  0.75238  6.73494  3.73079   3.00311  \n",
       "170   4.93757  1.33719   6.93488  2.95996  4.61952  7.39694   4.35391  \n",
       "\n",
       "[118 rows x 13 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.query('target == 0 and pred_0 + pred_1 + pred_2 + pred_3 + pred_4 + pred_5 +pred_6 +pred_7 + pred_8 + pred_9 > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing protein 10 / 41\n",
      "processing protein 20 / 41\n",
      "processing protein 30 / 41\n",
      "processing protein 40 / 41\n"
     ]
    }
   ],
   "source": [
    "df_test = create_pred_dataframe(\n",
    "    pipeline, \n",
    "    dataset=pipeline.test_set,\n",
    "    weights=weights,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset for learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.X = torch.tensor(dataframe[['pred_0', 'pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5', 'pred_6', 'pred_7', 'pred_8', 'pred_9']].values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(dataframe['target'].values, dtype=torch.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "valid_dataset = CustomDataset(df_valid)\n",
    "test_dataset = CustomDataset(df_test)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity (Recall): 0.5422647527910686\n",
      "Specificity: 0.9911142085547522\n",
      "Accuracy: 0.9678671733024946\n",
      "Precision: 0.7692307692307693\n",
      "MCC: 0.630212175762319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef, recall_score, accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "sum_preds = df_test[['pred_0', 'pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5', 'pred_6', 'pred_7', 'pred_8', 'pred_9']].sum(axis=1)\n",
    "final_prediction = (sum_preds > 0).astype(int)\n",
    "# Sensitivity (Recall)\n",
    "sensitivity = recall_score(df_test['target'], final_prediction)\n",
    "\n",
    "# Specificity\n",
    "tn, fp, fn, tp = confusion_matrix(df_test['target'], final_prediction).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(df_test['target'], final_prediction)\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(df_test['target'], final_prediction)\n",
    "mcc = matthews_corrcoef(df_test['target'], final_prediction)\n",
    "\n",
    "print(f'Sensitivity (Recall): {sensitivity}')\n",
    "print(f'Specificity: {specificity}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print('MCC:', mcc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 17.7515\n",
      "Epoch [2/10], Loss: 16.5698\n",
      "Epoch [3/10], Loss: 16.2776\n",
      "Epoch [4/10], Loss: 16.0787\n",
      "Epoch [5/10], Loss: 15.9375\n",
      "Epoch [6/10], Loss: 15.8504\n",
      "Epoch [7/10], Loss: 15.7574\n",
      "Epoch [8/10], Loss: 15.6544\n",
      "Epoch [9/10], Loss: 15.5815\n",
      "Epoch [10/10], Loss: 15.5368\n",
      "Matthews Correlation Coefficient on Test Set: 0.6202251588586377\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x.squeeze()\n",
    "\n",
    "input_size = 10\n",
    "hidden_size = 32\n",
    "output_size = 1\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    sum_loss = 0.0\n",
    "    for inputs, targets in valid_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        sum_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, sum_loss))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        all_preds.extend(predictions.numpy())\n",
    "        all_targets.extend(targets.numpy())\n",
    "\n",
    "mcc = matthews_corrcoef(all_targets, all_preds)\n",
    "print('Matthews Correlation Coefficient on Test Set:', mcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaechanlee/miniconda3/envs/jc/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient on Test Set: 0.5868540518431951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaechanlee/miniconda3/envs/jc/lib/python3.9/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient on Test Set: 0.6021520755539236\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "\n",
    "X_valid = df_valid[['pred_0', 'pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5', 'pred_6', 'pred_7', 'pred_8', 'pred_9']]\n",
    "y_valid = df_valid['target']\n",
    "\n",
    "X_test = df_test[['pred_0', 'pred_1', 'pred_2', 'pred_3', 'pred_4', 'pred_5', 'pred_6', 'pred_7', 'pred_8', 'pred_9']]\n",
    "y_test = df_test['target']\n",
    "\n",
    "def create_xgb_classifier():\n",
    "    return xgb.XGBClassifier(\n",
    "        booster='gbtree',\n",
    "        learning_rate=0.1,\n",
    "        gamma=0.1,\n",
    "        max_depth=10,\n",
    "        min_child_weight=1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        colsample_bylevel=0.8,\n",
    "        colsample_bynode=0.8,\n",
    "        reg_lambda=1,\n",
    "        reg_alpha=0,\n",
    "        scale_pos_weight=1,\n",
    "        n_estimators=500,\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "    )\n",
    "clf = create_xgb_classifier()\n",
    "clf.fit(X_valid, y_valid)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print('Matthews Correlation Coefficient on Test Set:', mcc)\n",
    "\n",
    "# How about applying sigmoid:\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "X_valid_sigmoid = X_valid.applymap(sigmoid)\n",
    "X_test_sigmoid = X_test.applymap(sigmoid)\n",
    "\n",
    "clf = create_xgb_classifier()\n",
    "clf.fit(X_valid_sigmoid, y_valid)\n",
    "y_pred = clf.predict(X_test_sigmoid)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "print('Matthews Correlation Coefficient on Test Set:', mcc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient: 0.6346424533239282\n",
      "Assuming linear regression of coefficient all 1, then Matthews Correlation Coefficient: 0.630212175762319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaechanlee/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=10)\n",
    "model.fit(X_valid, y_valid)\n",
    "coefficients = model.coef_[0]\n",
    "y_pred_probabilities = model.predict_proba(X_test)[:,1]\n",
    "y_pred = (y_pred_probabilities > 0.5).astype(int)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print('Matthews Correlation Coefficient:', mcc)\n",
    "\n",
    "\n",
    "model.coef_[0] = np.array([1] * 10)\n",
    "y_pred_probabilities = model.predict_proba(X_test)[:,1]\n",
    "y_pred = (y_pred_probabilities > 0.5).astype(int)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "print('Assuming linear regression of coefficient all 1, then Matthews Correlation Coefficient:', mcc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
