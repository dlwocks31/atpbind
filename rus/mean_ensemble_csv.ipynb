{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def aggregate_pred_dataframe(files):\n",
    "    dfs = [pd.read_csv(f) for f in files]\n",
    "    final_df = dfs[0].rename(columns={'pred': 'pred_0'})\n",
    "    for i in range(1, len(dfs)):\n",
    "        final_df[f'pred_{i}'] = dfs[i]['pred']\n",
    "    return final_df.reset_index()\n",
    "\n",
    "def get_preds_with_prefix(prefix, seed_start=0, seed_end=20):\n",
    "    csv_files = [file for file in os.listdir('preds') if file.endswith('.csv')]\n",
    "    csv_files.sort()\n",
    "    len(csv_files)\n",
    "    preds = []\n",
    "    for seed in range(seed_start, seed_end):\n",
    "        filtered = [file for file in csv_files if file.startswith(f'{prefix}_{seed}')]\n",
    "        if filtered:\n",
    "            preds.append((filtered[-1], filtered[-2]))\n",
    "    return preds\n",
    "\n",
    "def aggregate_preds(preds):\n",
    "    df_valid = aggregate_pred_dataframe([f'preds/{i[0]}' for i in preds])\n",
    "    df_test = aggregate_pred_dataframe([f'preds/{i[1]}' for i in preds])\n",
    "    \n",
    "    return df_valid, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix, recall_score, accuracy_score, precision_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def round_dict(d, n):\n",
    "    return {k: round(v, n) if isinstance(v, float) else v\n",
    "                for k, v in d.items()}\n",
    "\n",
    "def generate_mean_ensemble_metrics(df, threshold=0):\n",
    "    sum_preds = df[list(filter(lambda a: a.startswith('pred_'), df.columns.tolist()))].mean(axis=1)\n",
    "    final_prediction = (sum_preds > threshold).astype(int)\n",
    "\n",
    "    # Sensitivity (Recall)\n",
    "    sensitivity = recall_score(df['target'], final_prediction)\n",
    "\n",
    "    # Specificity\n",
    "    tn, fp, fn, tp = confusion_matrix(df['target'], final_prediction).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(df['target'], final_prediction)\n",
    "\n",
    "    # Precision\n",
    "    precision = precision_score(df['target'], final_prediction)\n",
    "    mcc = matthews_corrcoef(df['target'], final_prediction)\n",
    "    return {\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"mcc\": mcc,\n",
    "    }\n",
    "    \n",
    "def draw_mean_ensemble_thrshold_chart(df_valid, df_test, start=-3, end=1, plot=True):\n",
    "    # Create a list of thresholds to test\n",
    "    thresholds = np.arange(start, end, 0.1)  # Adjust the step size as necessary\n",
    "    valid_mccs = []\n",
    "    test_metrics = []\n",
    "\n",
    "    # Loop through thresholds and compute MCC\n",
    "    for threshold in thresholds:\n",
    "        metrics = generate_mean_ensemble_metrics(df_valid, threshold)\n",
    "        valid_mccs.append(metrics['mcc'])\n",
    "        \n",
    "        metrics_test = generate_mean_ensemble_metrics(df_test, threshold)\n",
    "        test_metrics.append(metrics_test)\n",
    "\n",
    "    # Identify threshold with the best MCC\n",
    "    best_threshold_arg = np.argmax(valid_mccs)\n",
    "    best_threshold = thresholds[best_threshold_arg]\n",
    "\n",
    "    label = f'Best Threshold: {best_threshold:.1f}, Valid MCC: {valid_mccs[best_threshold_arg]:.3f}, Test MCC: {test_metrics[best_threshold_arg][\"mcc\"]:.3f}'\n",
    "    # Plot\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(thresholds, valid_mccs, label='Valid MCC', color='blue')\n",
    "        plt.plot(thresholds, [i['mcc'] for i in test_metrics], label='Test MCC', color='green')\n",
    "        plt.axvline(x=best_threshold, color='red', linestyle='--', label=label)\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('MCC Value')\n",
    "        plt.title('MCC vs. Threshold')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    return {\n",
    "        'best_threshold': best_threshold, \n",
    "        'valid_mcc': valid_mccs[best_threshold_arg],\n",
    "        **test_metrics[best_threshold_arg]\n",
    "    }\n",
    "\n",
    "\n",
    "def random_small_ensembles(preds, n, trial):\n",
    "    from random import sample\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(trial):\n",
    "        sample_preds = sample(preds, n)\n",
    "        df_valid = aggregate_pred_dataframe([f'preds/{i[0]}' for i in sample_preds])\n",
    "        df_test = aggregate_pred_dataframe([f'preds/{i[1]}' for i in sample_preds])\n",
    "        new_row = [draw_mean_ensemble_thrshold_chart(df_valid, df_test, start=-3, end=1, plot=False)]\n",
    "        new_df = pd.DataFrame(new_row)\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def summarize_prefix(prefix, n):\n",
    "    preds = get_preds_with_prefix(prefix, seed_start=0, seed_end=20)\n",
    "    df_valid, df_test = aggregate_preds(preds)\n",
    "    print(f'Ensemble of all {len(preds)} models:')\n",
    "    print(round_dict(draw_mean_ensemble_thrshold_chart(df_valid, df_test, start=-3, end=1, plot=False), 4))\n",
    "\n",
    "    print(f'Ensemble of {n} random models:')\n",
    "    df = random_small_ensembles(preds, n, 10)\n",
    "    return df.aggregate(['mean', 'std', 'max']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of all 20 models:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m summarize_prefix(\u001b[39m'\u001b[39;49m\u001b[39mv001\u001b[39;49m\u001b[39m'\u001b[39;49m, n\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[2], line 91\u001b[0m, in \u001b[0;36msummarize_prefix\u001b[0;34m(prefix, n)\u001b[0m\n\u001b[1;32m     89\u001b[0m df_valid, df_test \u001b[39m=\u001b[39m aggregate_preds(preds)\n\u001b[1;32m     90\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEnsemble of all \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(preds)\u001b[39m}\u001b[39;00m\u001b[39m models:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m \u001b[39mprint\u001b[39m(round_dict(draw_mean_ensemble_thrshold_chart(df_valid, df_test, start\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m3\u001b[39;49m, end\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, plot\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), \u001b[39m4\u001b[39m))\n\u001b[1;32m     93\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEnsemble of \u001b[39m\u001b[39m{\u001b[39;00mn\u001b[39m}\u001b[39;00m\u001b[39m random models:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m df \u001b[39m=\u001b[39m random_small_ensembles(preds, n, \u001b[39m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 43\u001b[0m, in \u001b[0;36mdraw_mean_ensemble_thrshold_chart\u001b[0;34m(df_valid, df_test, start, end, plot)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39m# Loop through thresholds and compute MCC\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m threshold \u001b[39min\u001b[39;00m thresholds:\n\u001b[0;32m---> 43\u001b[0m     metrics \u001b[39m=\u001b[39m generate_mean_ensemble_metrics(df_valid, threshold)\n\u001b[1;32m     44\u001b[0m     valid_mccs\u001b[39m.\u001b[39mappend(metrics[\u001b[39m'\u001b[39m\u001b[39mmcc\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     46\u001b[0m     metrics_test \u001b[39m=\u001b[39m generate_mean_ensemble_metrics(df_test, threshold)\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mgenerate_mean_ensemble_metrics\u001b[0;34m(df, threshold)\u001b[0m\n\u001b[1;32m     12\u001b[0m final_prediction \u001b[39m=\u001b[39m (sum_preds \u001b[39m>\u001b[39m threshold)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Sensitivity (Recall)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m sensitivity \u001b[39m=\u001b[39m recall_score(df[\u001b[39m'\u001b[39;49m\u001b[39mtarget\u001b[39;49m\u001b[39m'\u001b[39;49m], final_prediction)\n\u001b[1;32m     17\u001b[0m \u001b[39m# Specificity\u001b[39;00m\n\u001b[1;32m     18\u001b[0m tn, fp, fn, tp \u001b[39m=\u001b[39m confusion_matrix(df[\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m], final_prediction)\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2299\u001b[0m, in \u001b[0;36mrecall_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   2140\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m   2141\u001b[0m     {\n\u001b[1;32m   2142\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2166\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2167\u001b[0m ):\n\u001b[1;32m   2168\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute the recall.\u001b[39;00m\n\u001b[1;32m   2169\u001b[0m \n\u001b[1;32m   2170\u001b[0m \u001b[39m    The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2297\u001b[0m \u001b[39m    array([1. , 1. , 0.5])\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2299\u001b[0m     _, r, _, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   2300\u001b[0m         y_true,\n\u001b[1;32m   2301\u001b[0m         y_pred,\n\u001b[1;32m   2302\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   2303\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   2304\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   2305\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   2306\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   2307\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   2308\u001b[0m     )\n\u001b[1;32m   2309\u001b[0m     \u001b[39mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1725\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1725\u001b[0m MCM \u001b[39m=\u001b[39m multilabel_confusion_matrix(\n\u001b[1;32m   1726\u001b[0m     y_true,\n\u001b[1;32m   1727\u001b[0m     y_pred,\n\u001b[1;32m   1728\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1729\u001b[0m     labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1730\u001b[0m     samplewise\u001b[39m=\u001b[39;49msamplewise,\n\u001b[1;32m   1731\u001b[0m )\n\u001b[1;32m   1732\u001b[0m tp_sum \u001b[39m=\u001b[39m MCM[:, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m]\n\u001b[1;32m   1733\u001b[0m pred_sum \u001b[39m=\u001b[39m tp_sum \u001b[39m+\u001b[39m MCM[:, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[39m=\u001b[39m get_config()[\u001b[39m\"\u001b[39m\u001b[39mskip_parameter_validation\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[39m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[39m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:505\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    396\u001b[0m     {\n\u001b[1;32m    397\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, samplewise\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    407\u001b[0m ):\n\u001b[1;32m    408\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute a confusion matrix for each class or sample.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[39m    .. versionadded:: 0.21\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39m            [1, 2]]])\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 505\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    506\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m         sample_weight \u001b[39m=\u001b[39m column_or_1d(sample_weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/utils/multiclass.py:387\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[39m# Check multiclass\u001b[39;00m\n\u001b[1;32m    386\u001b[0m first_row \u001b[39m=\u001b[39m y[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m issparse(y) \u001b[39melse\u001b[39;00m y\u001b[39m.\u001b[39mgetrow(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mdata\n\u001b[0;32m--> 387\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39;49munique_values(y)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(first_row) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/sklearn/utils/_array_api.py:262\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.unique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39munique_values\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 262\u001b[0m     \u001b[39mreturn\u001b[39;00m numpy\u001b[39m.\u001b[39;49munique(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jc/lib/python3.9/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summarize_prefix('v001', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of all 20 models:\n",
      "{'best_threshold': -1.0, 'valid_mcc': 0.6344, 'sensitivity': 0.5502, 'specificity': 0.9902, 'accuracy': 0.9674, 'precision': 0.7533, 'mcc': 0.6277}\n",
      "Ensemble of 10 random models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_threshold</th>\n",
       "      <td>-1.350000</td>\n",
       "      <td>0.334166</td>\n",
       "      <td>-0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_mcc</th>\n",
       "      <td>0.628503</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.639985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitivity</th>\n",
       "      <td>0.566507</td>\n",
       "      <td>0.015910</td>\n",
       "      <td>0.591707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.988144</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>0.990853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.966306</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>0.967702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.724548</td>\n",
       "      <td>0.027103</td>\n",
       "      <td>0.764574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.623343</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.629970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean       std       max\n",
       "best_threshold -1.350000  0.334166 -0.900000\n",
       "valid_mcc       0.628503  0.004834  0.639985\n",
       "sensitivity     0.566507  0.015910  0.591707\n",
       "specificity     0.988144  0.001933  0.990853\n",
       "accuracy        0.966306  0.001052  0.967702\n",
       "precision       0.724548  0.027103  0.764574\n",
       "mcc             0.623343  0.005105  0.629970"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_prefix('v002', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of all 20 models:\n",
      "{'best_threshold': -1.0, 'valid_mcc': 0.6311, 'sensitivity': 0.5646, 'specificity': 0.9894, 'accuracy': 0.9674, 'precision': 0.7437, 'mcc': 0.6316}\n",
      "Ensemble of 10 random models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_threshold</th>\n",
       "      <td>-0.910000</td>\n",
       "      <td>0.366515</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_mcc</th>\n",
       "      <td>0.626113</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.632314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitivity</th>\n",
       "      <td>0.562360</td>\n",
       "      <td>0.017296</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.988997</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.991637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.966901</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.968280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.737745</td>\n",
       "      <td>0.025957</td>\n",
       "      <td>0.779310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.627232</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.634304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean       std       max\n",
       "best_threshold -0.910000  0.366515 -0.500000\n",
       "valid_mcc       0.626113  0.003223  0.632314\n",
       "sensitivity     0.562360  0.017296  0.596491\n",
       "specificity     0.988997  0.001829  0.991637\n",
       "accuracy        0.966901  0.000994  0.968280\n",
       "precision       0.737745  0.025957  0.779310\n",
       "mcc             0.627232  0.006275  0.634304"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_prefix('v003', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of all 13 models:\n",
      "{'best_threshold': -1.6, 'valid_mcc': 0.6235, 'sensitivity': 0.5805, 'specificity': 0.9863, 'accuracy': 0.9653, 'precision': 0.6987, 'mcc': 0.619}\n",
      "Ensemble of 10 random models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_threshold</th>\n",
       "      <td>-0.930000</td>\n",
       "      <td>0.632543</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_mcc</th>\n",
       "      <td>0.622823</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.626438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitivity</th>\n",
       "      <td>0.558373</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.594896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.988361</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.991637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.966091</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.967124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.726133</td>\n",
       "      <td>0.029762</td>\n",
       "      <td>0.771971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.619151</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.627392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean       std       max\n",
       "best_threshold -0.930000  0.632543  0.100000\n",
       "valid_mcc       0.622823  0.002391  0.626438\n",
       "sensitivity     0.558373  0.027300  0.594896\n",
       "specificity     0.988361  0.002257  0.991637\n",
       "accuracy        0.966091  0.000840  0.967124\n",
       "precision       0.726133  0.029762  0.771971\n",
       "mcc             0.619151  0.004823  0.627392"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_prefix('v004', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of all 20 models:\n",
      "{'best_threshold': -1.0, 'valid_mcc': 0.6307, 'sensitivity': 0.555, 'specificity': 0.9895, 'accuracy': 0.967, 'precision': 0.742, 'mcc': 0.6253}\n",
      "Ensemble of 10 random models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_threshold</th>\n",
       "      <td>-1.800000</td>\n",
       "      <td>0.678233</td>\n",
       "      <td>-0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_mcc</th>\n",
       "      <td>0.628339</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.635400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitivity</th>\n",
       "      <td>0.582616</td>\n",
       "      <td>0.016644</td>\n",
       "      <td>0.615630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.986175</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.989807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.965273</td>\n",
       "      <td>0.001310</td>\n",
       "      <td>0.967372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.698896</td>\n",
       "      <td>0.028599</td>\n",
       "      <td>0.748927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.619921</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.629431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean       std       max\n",
       "best_threshold -1.800000  0.678233 -0.600000\n",
       "valid_mcc       0.628339  0.004138  0.635400\n",
       "sensitivity     0.582616  0.016644  0.615630\n",
       "specificity     0.986175  0.002256  0.989807\n",
       "accuracy        0.965273  0.001310  0.967372\n",
       "precision       0.698896  0.028599  0.748927\n",
       "mcc             0.619921  0.005779  0.629431"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_prefix('v005', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of all 20 models:\n",
      "{'best_threshold': -2.1, 'valid_mcc': 0.6283, 'sensitivity': 0.5933, 'specificity': 0.9862, 'accuracy': 0.9659, 'precision': 0.7019, 'mcc': 0.6277}\n",
      "Ensemble of 10 random models:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>best_threshold</th>\n",
       "      <td>-1.750000</td>\n",
       "      <td>0.330824</td>\n",
       "      <td>-1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_mcc</th>\n",
       "      <td>0.625160</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.631102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sensitivity</th>\n",
       "      <td>0.580064</td>\n",
       "      <td>0.010948</td>\n",
       "      <td>0.596491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.987569</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.989459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.966463</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0.967537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.719259</td>\n",
       "      <td>0.023954</td>\n",
       "      <td>0.745798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.628647</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.639425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mean       std       max\n",
       "best_threshold -1.750000  0.330824 -1.400000\n",
       "valid_mcc       0.625160  0.003694  0.631102\n",
       "sensitivity     0.580064  0.010948  0.596491\n",
       "specificity     0.987569  0.001735  0.989459\n",
       "accuracy        0.966463  0.001265  0.967537\n",
       "precision       0.719259  0.023954  0.745798\n",
       "mcc             0.628647  0.008680  0.639425"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_prefix('v006', n=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
