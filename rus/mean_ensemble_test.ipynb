{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get dataset atpbind3d\n",
      "Split num:  [337, 41, 41]\n",
      "train samples: 337, valid samples: 41, test samples: 41\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from lib.pipeline import Pipeline\n",
    "import torch\n",
    "\n",
    "GPU = 1\n",
    "\n",
    "def make_pipeline(weight_file):\n",
    "    pipeline = Pipeline(\n",
    "        model='lm-gearnet',\n",
    "        dataset='atpbind3d',\n",
    "        gpus=[GPU],\n",
    "        model_kwargs={\n",
    "            'gpu': GPU,\n",
    "            'gearnet_hidden_dim_size': 512,\n",
    "            'gearnet_hidden_dim_count': 4,\n",
    "            'bert_freeze': False,\n",
    "            'bert_freeze_layer_count': 29,\n",
    "        },\n",
    "        optimizer_kwargs={\n",
    "            'lr': 5e-4,\n",
    "        },\n",
    "        task_kwargs={\n",
    "            'use_rus': True,\n",
    "            'rus_seed': 0,\n",
    "        },\n",
    "        bce_weight=1,\n",
    "        batch_size=4,\n",
    "    )\n",
    "    if weight_file is not None:\n",
    "        state_dict = torch.load(weight_file, map_location=f'cuda:{GPU}')\n",
    "        pipeline.task.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "trained_rus_model_file = {\n",
    "    0: 'rus_pipeline_0_0.59850.pth',\n",
    "    1: 'rus_pipeline_1_0.59290pth',\n",
    "}\n",
    "p1 = make_pipeline('rus_pipeline_0_0.432289.pth')\n",
    "p2 = make_pipeline('rus_pipeline_0_0.432289.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import core, models\n",
    "from lib.tasks import NodePropertyPrediction\n",
    "from lib.custom_models import LMGearNetModel\n",
    "from torchdrug import transforms, data, core, layers, tasks, metrics, utils, models\n",
    "from torchdrug.layers import functional, geometry\n",
    "from torchdrug.core import Registry as R\n",
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "from torch.nn import functional as F\n",
    "import contextlib\n",
    "import logging\n",
    "import numpy as np\n",
    "from functools import cache\n",
    "\n",
    "# This task should only be used in inference, thus we only have to care about predict?\n",
    "# engine.evaluate only cares about task.predict_and_target and task.evaluate\n",
    "class MeanEnsembleNodePropertyPrediction(NodePropertyPrediction):\n",
    "    def __init__(self, model, ensembled_task_file, *args, **kwargs):\n",
    "        super().__init__(model, *args, **kwargs)\n",
    "        self.ensembled_task_file = ensembled_task_file\n",
    "    \n",
    "    def predict(self, batch, all_loss=None, metric=None):\n",
    "        mean_prediction = None\n",
    "        for rus_seed, model_file in self.ensembled_task_file.items():\n",
    "            self.load_state_dict(torch.load(model_file, map_location=self.device), strict=False)\n",
    "            self.use_rus = True\n",
    "            self.rus_seed = rus_seed\n",
    "            current_prediction = super(MeanEnsembleNodePropertyPrediction, self).predict(batch, all_loss, metric)\n",
    "            if mean_prediction is None:\n",
    "                mean_prediction = current_prediction\n",
    "            else:\n",
    "                mean_prediction += current_prediction\n",
    "        mean_prediction /= len(self.ensembled_task_file)\n",
    "\n",
    "        return mean_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LMGearNetModel(\n",
    "#     gpu=GPU,\n",
    "#     gearnet_hidden_dim_size=512,\n",
    "#     gearnet_hidden_dim_count=4,\n",
    "#     bert_freeze=False,\n",
    "#     bert_freeze_layer_count=29,\n",
    "# )\n",
    "\n",
    "# edge_layers = [\n",
    "#     geometry.SpatialEdge(radius=10, min_distance=5),\n",
    "#     geometry.KNNEdge(k=10, min_distance=5),\n",
    "#     geometry.SequentialEdge(max_distance=2),\n",
    "# ]\n",
    "    \n",
    "# graph_construction_model = layers.GraphConstruction(\n",
    "#     node_layers=[geometry.AlphaCarbonNode()],\n",
    "#     edge_layers=edge_layers,\n",
    "#     edge_feature=\"gearnet\"\n",
    "# )\n",
    "# me_task = MeanEnsembleNodePropertyPrediction(\n",
    "#     model=model, \n",
    "#     ensembled_task_file={\n",
    "#         0: 'rus_pipeline_0_0.59580.pth',\n",
    "#         1: 'rus_pipeline_1_0.59290.pth',\n",
    "#         2: 'rus_pipeline_2_0.55640.pth',\n",
    "#     },\n",
    "#     graph_construction_model=graph_construction_model,\n",
    "#     normalization=False,\n",
    "#     num_mlp_layer=2,\n",
    "#     metric=(\"sensitivity\", \"specificity\", \"accuracy\", \"precision\", \"mcc\", \"micro_auroc\",),\n",
    "#     bce_weight=torch.tensor([1], device=torch.device(f'cuda:{GPU}')),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembled_task_file={\n",
    "    0: 'rus_pipeline_0_0.59580.pth',\n",
    "    1: 'rus_pipeline_1_0.59290.pth',\n",
    "    2: 'rus_pipeline_2_0.55640.pth',\n",
    "    3: 'rus_pipeline_3_0.56080.pth',\n",
    "    4: 'rus_pipeline_4_0.59780.pth',\n",
    "    5: 'rus_pipeline_5_0.54520.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import transforms, data, core, layers, tasks, metrics, utils, models\n",
    "from torchdrug.layers import functional, geometry\n",
    "from torchdrug.core import Registry as R\n",
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "from torch.nn import functional as F\n",
    "import contextlib\n",
    "import logging\n",
    "import numpy as np\n",
    "from functools import cache\n",
    "\n",
    "from lib.tasks import NodePropertyPrediction\n",
    "from lib.datasets import ATPBind, ATPBind3D\n",
    "from lib.bert import BertWrapModel\n",
    "from lib.custom_models import GearNetWrapModel, LMGearNetModel\n",
    "from lib.utils import dict_tensor_to_num, round_dict\n",
    "from lib.pipeline import get_dataset\n",
    "class DisableLogger():\n",
    "    def __enter__(self):\n",
    "       logging.disable(logging.CRITICAL)\n",
    "    def __exit__(self, exit_type, exit_value, exit_traceback):\n",
    "       logging.disable(logging.NOTSET)\n",
    "\n",
    "\n",
    "METRICS_USING = (\"sensitivity\", \"specificity\", \"accuracy\", \"precision\", \"mcc\", \"micro_auroc\",)\n",
    "class CustomPipeline:\n",
    "    possible_models = ['bert', 'gearnet', 'lm-gearnet', 'cnn']\n",
    "    possible_datasets = ['atpbind', 'atpbind3d', 'atpbind3d-minimal']\n",
    "    threshold = 0\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 dataset,\n",
    "                 gpus,\n",
    "                 model_kwargs={},\n",
    "                 optimizer_kwargs={},\n",
    "                 task_kwargs={},\n",
    "                 graph_knn_k=10,\n",
    "                 graph_spatial_radius=10.0,\n",
    "                 graph_sequential_max_distance=2,\n",
    "                 batch_size=1,\n",
    "                 bce_weight=1,\n",
    "                 verbose=False,\n",
    "                 ):\n",
    "        self.gpus = gpus\n",
    "\n",
    "        if model not in self.possible_models:\n",
    "            raise ValueError('Model must be one of {}'.format(self.possible_models))\n",
    "    \n",
    "        if dataset not in self.possible_datasets:\n",
    "            raise ValueError('Dataset must be one of {}'.format(self.possible_datasets))\n",
    "           \n",
    "        with DisableLogger():     \n",
    "            if model == 'bert':\n",
    "                self.model = BertWrapModel(**model_kwargs)\n",
    "            elif model == 'gearnet':\n",
    "                self.model = GearNetWrapModel(graph_sequential_max_distance=graph_sequential_max_distance, **model_kwargs)\n",
    "            elif model == 'lm-gearnet':\n",
    "                self.model = LMGearNetModel(graph_sequential_max_distance=graph_sequential_max_distance, **model_kwargs)\n",
    "            elif model == 'cnn':\n",
    "                self.model = models.ProteinCNN(**model_kwargs)\n",
    "        \n",
    "        self.train_set, self.valid_set, self.test_set = get_dataset(dataset)\n",
    "        \n",
    "        if dataset == 'atpbind':\n",
    "            self.task = MeanEnsembleNodePropertyPrediction(\n",
    "                self.model, \n",
    "                normalization=False,\n",
    "                num_mlp_layer=2,\n",
    "                metric=METRICS_USING,\n",
    "                bce_weight=torch.tensor([bce_weight], device=torch.device(f'cuda:{self.gpus[0]}')),\n",
    "                **task_kwargs,\n",
    "            )\n",
    "        elif dataset == 'atpbind3d' or dataset == 'atpbind3d-minimal':\n",
    "            edge_layers = [\n",
    "                geometry.SpatialEdge(radius=graph_spatial_radius, min_distance=5),\n",
    "                geometry.KNNEdge(k=graph_knn_k, min_distance=5),\n",
    "                geometry.SequentialEdge(max_distance=graph_sequential_max_distance),\n",
    "            ]\n",
    "                \n",
    "            graph_construction_model = layers.GraphConstruction(\n",
    "                node_layers=[geometry.AlphaCarbonNode()],\n",
    "                edge_layers=edge_layers,\n",
    "                edge_feature=\"gearnet\"\n",
    "            )\n",
    "            self.task = MeanEnsembleNodePropertyPrediction(\n",
    "                self.model,\n",
    "                ensembled_task_file=ensembled_task_file,\n",
    "                graph_construction_model=graph_construction_model,\n",
    "                normalization=False,\n",
    "                num_mlp_layer=2,\n",
    "                metric=METRICS_USING,\n",
    "                bce_weight=torch.tensor([bce_weight], device=torch.device(f'cuda:{self.gpus[0]}')),\n",
    "                **task_kwargs,\n",
    "            )\n",
    "        \n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), **optimizer_kwargs)\n",
    "        with DisableLogger():\n",
    "            self.solver = core.Engine(self.task,\n",
    "                                        self.train_set,\n",
    "                                        self.valid_set,\n",
    "                                        self.test_set,\n",
    "                                        optimizer,\n",
    "                                        batch_size=batch_size,\n",
    "                                        log_interval=1000000000,\n",
    "                                        gpus=gpus\n",
    "            )\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def train(self, num_epoch):\n",
    "        return self.solver.train(num_epoch=num_epoch)\n",
    "    \n",
    "    def train_until_fit(self, patience=1):\n",
    "        from timer_cm import Timer\n",
    "        from itertools import count\n",
    "        train_record = []\n",
    "        for epoch in count(start=1):\n",
    "            cm = contextlib.nullcontext() if self.verbose else DisableLogger()\n",
    "            with cm:\n",
    "                self.train(num_epoch=1)\n",
    "                cur_result = self.evaluate()\n",
    "                cur_result['train_bce'] = self.get_last_bce()\n",
    "                cur_result['valid_bce'] = self.calculate_valid_loss()\n",
    "                cur_result['valid_mcc'] = self.calculate_best_mcc_and_threshold(\n",
    "                    threshold_set='valid'\n",
    "                )['best_mcc']\n",
    "                cur_result = round_dict(cur_result, 4)\n",
    "                train_record.append(cur_result)\n",
    "                print(cur_result)\n",
    "                max_mcc_index = np.argmax([record['valid_mcc'] for record in train_record])\n",
    "                if max_mcc_index < len(train_record) - patience:\n",
    "                    break\n",
    "        return train_record\n",
    "        \n",
    "\n",
    "    def get_last_bce(self):\n",
    "        from statistics import mean\n",
    "        meter = self.solver.meter\n",
    "        index = slice(meter.epoch2batch[-2], meter.epoch2batch[-1])\n",
    "        bce_records = meter.records['binary cross entropy'][index]\n",
    "        return mean(bce_records)\n",
    "    \n",
    "    def calculate_valid_loss(self):\n",
    "        from statistics import mean\n",
    "        dataloader = data.DataLoader(self.valid_set, batch_size=1, shuffle=False)\n",
    "        model = self.task\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        metrics = []\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                batch = utils.cuda(batch, device=f'cuda:{self.gpus[0]}')\n",
    "                loss, metric = model(batch)\n",
    "                metrics.append(metric['binary cross entropy'].item())\n",
    "        \n",
    "        return mean(metrics)\n",
    "\n",
    "\n",
    "    def calculate_best_mcc_and_threshold(self, threshold_set='valid'):\n",
    "        dataloader = data.DataLoader(\n",
    "            self.valid_set if threshold_set == 'valid' else self.test_set,\n",
    "            batch_size=1,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        preds = []\n",
    "        targets = []\n",
    "        thresholds = np.linspace(-3, 1, num=41)\n",
    "        mcc_values = [0 for i in range(len(thresholds))]\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                batch = utils.cuda(batch, device=torch.device(f'cuda:{self.gpus[0]}'))\n",
    "                pred, target = self.task.predict_and_target(batch)\n",
    "                preds.append(pred)\n",
    "                targets.append(target)\n",
    "        \n",
    "        pred = utils.cat(preds)\n",
    "        target = utils.cat(targets)\n",
    "\n",
    "        for i, threshold in enumerate(thresholds):\n",
    "            mcc = self.task.evaluate(\n",
    "                pred, target, threshold\n",
    "            )['mcc']\n",
    "            mcc_values[i] = mcc_values[i] + mcc\n",
    "\n",
    "        max_mcc_idx = np.argmax(mcc_values)\n",
    "        \n",
    "        return {\n",
    "            'best_mcc': mcc_values[max_mcc_idx],\n",
    "            'best_threshold': thresholds[max_mcc_idx]\n",
    "        }\n",
    "\n",
    "\n",
    "    def evaluate(self, threshold_set='valid', verbose=False):\n",
    "        mcc_and_threshold = self.calculate_best_mcc_and_threshold(threshold_set)\n",
    "        if verbose:\n",
    "            print(f'threshold: {mcc_and_threshold}\\n')\n",
    "        self.task.threshold = mcc_and_threshold['best_threshold']\n",
    "        return dict_tensor_to_num(self.solver.evaluate(\"test\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:37:28   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "17:37:28   Evaluate on test\n",
      "17:37:50   ------------------------------\n",
      "17:37:50   accuracy: 0.966876\n",
      "17:37:50   mcc: 0.630999\n",
      "17:37:50   micro_auroc: 0.942937\n",
      "17:37:50   precision: 0.726908\n",
      "17:37:50   sensitivity: 0.577352\n",
      "17:37:50   specificity: 0.988152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sensitivity': 0.5773524641990662,\n",
       " 'specificity': 0.988152265548706,\n",
       " 'accuracy': 0.9668759107589722,\n",
       " 'precision': 0.7269076108932495,\n",
       " 'mcc': 0.6309990197220169,\n",
       " 'micro_auroc': 0.942936897277832}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = CustomPipeline(\n",
    "    model='lm-gearnet',\n",
    "    dataset='atpbind3d',\n",
    "    gpus=[GPU],\n",
    "    model_kwargs={\n",
    "        'gpu': GPU,\n",
    "        'gearnet_hidden_dim_size': 512,\n",
    "        'gearnet_hidden_dim_count': 4,\n",
    "        'bert_freeze': False,\n",
    "        'bert_freeze_layer_count': 29,\n",
    "    },\n",
    "    optimizer_kwargs={\n",
    "        'lr': 5e-4,\n",
    "    },\n",
    "    task_kwargs={\n",
    "        'use_rus': True,\n",
    "        'rus_seed': 0,\n",
    "    },\n",
    "    bce_weight=1,\n",
    "    batch_size=4,\n",
    ")\n",
    "\n",
    "pipeline.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
