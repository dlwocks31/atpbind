{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get dataset atpbind3d\n",
      "Split num:  [337, 41, 41]\n",
      "train samples: 337, valid samples: 41, test samples: 41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LM-Gearnet Pretrained: finetune it\n",
    "from lib.pipeline import Pipeline\n",
    "import torch\n",
    "\n",
    "GPU = 0\n",
    "pipeline = Pipeline(\n",
    "    model='lm-gearnet',\n",
    "    dataset='atpbind3d',\n",
    "    gpus=[GPU],\n",
    "    model_kwargs={\n",
    "        'gpu': 0,\n",
    "        'gearnet_hidden_dim_size': 512,\n",
    "        'gearnet_hidden_dim_count': 4,\n",
    "        'bert_freeze': False,\n",
    "        'bert_freeze_layer_count': 29,\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "state_dict = torch.load('ResidueType_lmg_4_512_0.57268.pth')\n",
    "pipeline.model.gearnet.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:25:02   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "01:25:02   Epoch 4 begin\n",
      "01:26:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "01:26:47   Epoch 4 end\n",
      "01:26:47   duration: 1.27 hours\n",
      "01:26:47   speed: 0.07 batch / sec\n",
      "01:26:47   ETA: 0.00 secs\n",
      "01:26:47   max GPU memory: 6690.6 MiB\n",
      "01:26:47   ------------------------------\n",
      "01:26:47   average binary cross entropy: 0.0236077\n"
     ]
    }
   ],
   "source": [
    "pipeline.train(num_epoch=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pipeline.model.state_dict(), 'lm_gearnet_finetuned_demo.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.model.load_state_dict(torch.load('lm_gearnet_finetuned_demo.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:27:20   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "01:27:20   Evaluate on test\n",
      "01:27:30   ------------------------------\n",
      "01:27:30   mcc: 0.522607\n",
      "01:27:30   micro_auroc: 0.917182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'micro_auroc': 0.9171818494796753, 'mcc': 0.5226066587138549}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binding site: [9, 10, 11, 12, 13, 14, 52, 53, 78, 80, 81, 82, 83, 84, 87, 202]\n",
      "graph:  PackedProtein(batch_size=1, num_atoms=[1400], num_bonds=[2798], num_residues=[350], device='cuda:0')\n",
      "Sequence:  DTAVLVLAAGPGTRMRSDTPKVLHTLAGRSMLSHVLHAIAKLAPQRLIVVLGHDHQRIAPLVGELADTLGRTIDVALQDRPLGTGHAVLCGLSALPDDYAGNVVVTSGDTPLLDADTLADLIATHRAVSAAVTVLTTTLDDPFGYGRILRTQDHEVMAIVEQTDATPSQREIREVNAGVYAFDIAALRSALSRLSSNNAQQELYLTDVIAILRSDGQTVHASHVDDSALVAGVNNRVQLAELASELNRRVVAAHQLAGVTVVDPATTWIDVDVTIGRDTVIHPGTQLLGRTQIGGRCVVGPDTTLTDVAVGDGASVVRTHGSSSSIGDGAAVGPFTYLRPGTALGADGKL\n",
      "prediction:  [10, 11, 13, 52, 53, 80, 81, 82, 83, 84, 87, 202]\n",
      "-------\n",
      "true positive:  [10, 11, 13, 52, 53, 80, 81, 82, 83, 84, 87, 202]\n",
      "false negative:  [9, 12, 14, 78]\n",
      "false positive:  []\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import data, utils\n",
    "# https://www.rcsb.org/structure/4K6R\n",
    "DEMO_PDB = '4K6RA'\n",
    "DEMO_ID = 5\n",
    "RESIDUE_OFFSET = 6\n",
    "\n",
    "dataloader = data.DataLoader(\n",
    "    [pipeline.train_set[DEMO_ID]], batch_size=1, shuffle=False)\n",
    "batch = utils.cuda(next(iter(dataloader)), device=torch.device('cuda:{}'.format(GPU)))\n",
    "pred, target = pipeline.task.predict_and_target(batch)\n",
    "\n",
    "target_index = [i+1 for i, item in enumerate(target['label']) if item.item() == 1]\n",
    "predict_index = [i+1 for i, item in enumerate(pred) if item.item() > -2]\n",
    "print('binding site:', target_index)\n",
    "print('graph: ', batch['graph'])\n",
    "print('Sequence: ', batch['graph'].to_sequence()[0])\n",
    "print('prediction: ', predict_index)\n",
    "\n",
    "print('-------')\n",
    "true_positive_index = [item for item in predict_index if item in target_index]\n",
    "false_negative_index = [item for item in target_index if item not in predict_index]\n",
    "false_positive_index = [item for item in predict_index if item not in target_index]\n",
    "print('true positive: ', true_positive_index)\n",
    "print('false negative: ', false_negative_index)\n",
    "print('false positive: ', false_positive_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63de7f181cc442dbb710d6ecf266859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NGLWidget()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "import nglview\n",
    "from random import random\n",
    "mol = Chem.MolFromPDBFile(f'data/pdb/{DEMO_PDB}.pdb')\n",
    "js_function = \"\"\"\n",
    "this.atomColor = function (atom) {\n",
    "    if (%s.includes(atom.serial)) { // true positive\n",
    "        return 0x00FF00\n",
    "    } else if (%s.includes(atom.serial)) { // false negative\n",
    "        return 0xFF0000\n",
    "    } else if (%s.includes(atom.serial)) { // false positive\n",
    "        return 0x0000FF\n",
    "    } else {\n",
    "        return 0x808080\n",
    "    }\n",
    "}\n",
    "\"\"\" % ([i + RESIDUE_OFFSET - 1 for i in true_positive_index],\n",
    "        [i + RESIDUE_OFFSET - 1 for i in false_negative_index],\n",
    "        [i + RESIDUE_OFFSET - 1 for i in false_positive_index])\n",
    "\n",
    "scheme_name_rnd = \"awesome-\" + str(random())\n",
    "nglview.color.ColormakerRegistry.add_scheme_func(scheme_name_rnd, js_function)\n",
    "view = nglview.show_rdkit(mol, default_representation=False)\n",
    "view.center()\n",
    "view.add_cartoon(color=scheme_name_rnd)\n",
    "view\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc",
   "language": "python",
   "name": "jc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
