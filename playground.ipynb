{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(path):\n",
    "    sequences, targets, pdb_ids = [], [], []\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        num_samples = len(lines)\n",
    "        for line in lines:\n",
    "            sequence = line.split(' : ')[-1].strip()\n",
    "            sequences.append(sequence)\n",
    "\n",
    "            target = line.split(' : ')[-2].split(' ')\n",
    "            target_indices = []\n",
    "            for index in target:\n",
    "                target_indices.append(int(index[1:]))\n",
    "            target = []\n",
    "            for index in range(len(sequence)):\n",
    "                if index+1 in target_indices:\n",
    "                    target.append(1)\n",
    "                else:\n",
    "                    target.append(0)\n",
    "            targets.append(target)\n",
    "\n",
    "            pdb_id = line.split(' : ')[0]\n",
    "            pdb_ids.append(pdb_id)\n",
    "    return num_samples, sequences, targets, pdb_ids\n",
    "\n",
    "\n",
    "num_samples, sequences, targets, pdb_ids = read_file('lib/train.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdrug as td\n",
    "from torchdrug import data, utils\n",
    "from Bio.PDB import PDBParser\n",
    "from Bio.PDB import Select, PDBIO\n",
    "import pylcs\n",
    "import torch\n",
    "import os\n",
    "\n",
    "class ChainSelect(Select):\n",
    "    def __init__(self, chain):\n",
    "        self.chain = chain\n",
    "\n",
    "    def accept_chain(self, chain):\n",
    "        if chain.get_id() == self.chain:\n",
    "            return 1\n",
    "        else:          \n",
    "            return 0\n",
    "\n",
    "def make_protein(sequence, pdb_id):\n",
    "    if os.path.exists(\"./pdb/%s.pdb\" % pdb_id[:4]):\n",
    "        pdb_file = \"./pdb/%s.pdb\" % pdb_id[:4]\n",
    "    else:\n",
    "        pdb_file = utils.download(\"https://files.rcsb.org/download/%s.pdb\" % pdb_id[:4], \"./pdb\")\n",
    "    \n",
    "    with open(pdb_file, 'r') as o:\n",
    "        structure = PDBParser().get_structure('?', o)\n",
    "        pdbio = PDBIO()\n",
    "        pdbio.set_structure(structure)\n",
    "        pdb_file = \"./pdb/%s.pdb\" % pdb_id\n",
    "        pdbio.save(pdb_file, ChainSelect(pdb_id[4]))\n",
    "    \n",
    "    protein = data.Protein.from_pdb(pdb_file, atom_feature=\"position\", bond_feature=None, residue_feature=\"symbol\")\n",
    "\n",
    "    lcs = pylcs.lcs_sequence_idx(sequence, protein.to_sequence().replace('.', ''))\n",
    "    if -1 in lcs:\n",
    "        print('warning: -1 in lcs. pdb_id: %s' % pdb_id)\n",
    "    mask = torch.zeros(protein.num_residue, dtype=torch.bool, device=protein.device)\n",
    "    mask[[i for i in lcs if i != -1]] = True\n",
    "    protein = protein.subresidue(mask)\n",
    "    return protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_and_validate(sequence, pdb_id, replace=True):\n",
    "    protein = make_protein(sequence, pdb_id)\n",
    "    print('unstripped protein length: %s' % len(protein.to_sequence()))\n",
    "    print('stripped protein length: %s' % len(protein.to_sequence().replace('.', '')))\n",
    "    full_sequence = protein.to_sequence()\n",
    "    lcs = pylcs.lcs_sequence_idx(sequence, full_sequence.replace('.', ''))\n",
    "    segments = []\n",
    "    l, r = 0, 0\n",
    "    while l < len(lcs):\n",
    "        r += 1\n",
    "        while r < len(lcs) and lcs[r] == lcs[r-1] + 1:\n",
    "            r += 1\n",
    "        segments.append((lcs[l], lcs[r-1]))\n",
    "        l = r\n",
    "    return segments\n",
    "\n",
    "make_and_validate(sequences[3], pdb_ids[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter([i.item() for i in protein.chain_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_log(message):\n",
    "    with open('example.log', 'a') as f:\n",
    "        f.write(message + '\\n')\n",
    "\n",
    "def protein_to_coordinates(protein):\n",
    "    # find N, CA, C, O atoms\n",
    "    coords = []\n",
    "    mask = torch.zeros(protein.num_residue,\n",
    "                       dtype=torch.bool, device=protein.device)\n",
    "    \n",
    "    for i in range(protein.num_residue):\n",
    "        atom_ids = protein.residue2atom(i).sort()[0]\n",
    "        atom_positions = {}\n",
    "        for atom, position in zip(protein.atom_name[atom_ids].tolist(), protein.node_position[atom_ids].tolist()):\n",
    "            atom_name = data.Protein.id2atom_name[atom]\n",
    "            if atom_name in ['N', 'CA', 'C', 'O']:\n",
    "                atom_positions[atom_name] = [round(i, 5) for i in position]\n",
    "        try:\n",
    "            coords.append([\n",
    "                atom_positions['N'],\n",
    "                atom_positions['CA'],\n",
    "                atom_positions['C'],\n",
    "                atom_positions['O'],\n",
    "            ])\n",
    "            mask[i] = True\n",
    "        except:\n",
    "            append_to_log('error: missing atom. atom at: %s' % i)\n",
    "            mask[i] = False\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein = make_protein(sequences[0], pdb_ids[0])\n",
    "coords = protein_to_coordinates(protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "def load_all_in_file(filename):\n",
    "    num_samples, sequences, targets, pdb_ids = read_file(filename)\n",
    "    result = []\n",
    "    f = IntProgress(min=0, max=num_samples)\n",
    "    display(f)\n",
    "    for sequence, pdb_id in zip(sequences, pdb_ids):\n",
    "        append_to_log('processing %s' % pdb_id)\n",
    "        try:\n",
    "            protein = make_protein(sequence, pdb_id)\n",
    "        except Exception as e:\n",
    "            append_to_log('error while creating protein: %s' % e)\n",
    "        coords = protein_to_coordinates(protein)\n",
    "        result.append({\n",
    "            'name': pdb_id,\n",
    "            'seq': sequence,\n",
    "            'coords': coords,\n",
    "        })\n",
    "        f.value += 1\n",
    "    \n",
    "    with open(filename + '.json', 'w') as o:\n",
    "        json.dump(result, o)\n",
    "    \n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_all_in_file('lib/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lib/train.txt.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "train_data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gvp.data\n",
    "\n",
    "dataset = gvp.data.ProteinGraphDataset(train_data[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gvp.models\n",
    "node_in_dim = (6, 3)\n",
    "edge_in_dim = (32, 1)\n",
    "node_h_dim = [20, 20]\n",
    "edge_h_dim = [20, 20]\n",
    "\n",
    "cpd_model = gvp.models.CPDModel(node_in_dim, node_h_dim, \n",
    "                        edge_in_dim, edge_h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpd_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc",
   "language": "python",
   "name": "jc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
