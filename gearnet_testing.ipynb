{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.datasets import ATPBind3D\n",
    "\n",
    "from torchdrug import transforms\n",
    "from torchdrug import data, core, layers, tasks, metrics, utils, models\n",
    "from torchdrug.layers import functional\n",
    "from torchdrug.core import Registry as R\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "from torch.nn import functional as F\n",
    "from lib.tasks import NodePropertyPrediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split num:  [337, 42, 41]\n",
      "train samples: 337, valid samples: 42, test samples: 41\n"
     ]
    }
   ],
   "source": [
    "truncuate_transform = transforms.TruncateProtein(max_length=350, random=False)\n",
    "protein_view_transform = transforms.ProteinView(view='residue')\n",
    "transform = transforms.Compose([truncuate_transform, protein_view_transform])\n",
    "\n",
    "dataset = ATPBind3D(transform=transform)\n",
    "\n",
    "train_set, valid_set, test_set = dataset.split()\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" %\n",
    "      (len(train_set), len(valid_set), len(test_set)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedProtein(batch_size=1, num_atoms=[1400], num_bonds=[2798], num_residues=[350])\n",
      "PackedProtein(batch_size=1, num_atoms=[350], num_bonds=[6029], num_residues=[350])\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import tasks, core, layers\n",
    "from torchdrug.layers import geometry\n",
    "graph_construction_model = layers.GraphConstruction(node_layers=[geometry.AlphaCarbonNode()],\n",
    "                                                    edge_layers=[geometry.SpatialEdge(radius=10.0, min_distance=5),\n",
    "                                                                 geometry.KNNEdge(\n",
    "                                                                     k=10, min_distance=5),\n",
    "                                                                 geometry.SequentialEdge(max_distance=2)],\n",
    "                                                    edge_feature=\"residue_type\")\n",
    "\n",
    "zipped_protein = data.Protein.pack([train_set[0]['graph']])\n",
    "constructed_protein = graph_construction_model(zipped_protein)\n",
    "print(zipped_protein)\n",
    "print(graph_construction_model(zipped_protein))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import models\n",
    "\n",
    "gearnet = models.GearNet(input_dim=21, hidden_dims=[512, 512, 512], num_relation=7,\n",
    "                         batch_norm=True, concat_hidden=True, short_cut=True, readout=\"sum\").to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:18:53   Preprocess training set\n",
      "17:18:53   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': None,\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.0001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'tasks.MultipleBinaryClassification',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': {'class': 'layers.GraphConstruction',\n",
      "                                       'edge_feature': 'residue_type',\n",
      "                                       'edge_layers': [SpatialEdge(),\n",
      "                                                       KNNEdge(),\n",
      "                                                       SequentialEdge()],\n",
      "                                       'node_layers': [AlphaCarbonNode()]},\n",
      "          'metric': ['auprc@micro', 'f1_max'],\n",
      "          'model': {'activation': 'relu',\n",
      "                    'batch_norm': True,\n",
      "                    'class': 'models.GearNet',\n",
      "                    'concat_hidden': True,\n",
      "                    'edge_input_dim': None,\n",
      "                    'hidden_dims': [512, 512, 512],\n",
      "                    'input_dim': 21,\n",
      "                    'num_angle_bin': None,\n",
      "                    'num_relation': 7,\n",
      "                    'readout': 'sum',\n",
      "                    'short_cut': True},\n",
      "          'normalization': True,\n",
      "          'num_mlp_layer': 3,\n",
      "          'reweight': False,\n",
      "          'task': [0],\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'class': 'ATPBind3D',\n",
      "                          'path': None,\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fc13c764460>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7fc13c764760>]},\n",
      "                          'valid_ratio': 0.1,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(379, 420)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'class': 'ATPBind3D',\n",
      "                           'path': None,\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fc13c764460>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fc13c764760>]},\n",
      "                           'valid_ratio': 0.1,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 337)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'class': 'ATPBind3D',\n",
      "                           'path': None,\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7fc13c764460>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7fc13c764760>]},\n",
      "                           'valid_ratio': 0.1,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(337, 379)}}\n",
      "17:18:53   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "17:18:53   Epoch 0 begin\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Could not run 'aten::view' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::view' is only available for these backends: [CPU, CUDA, QuantizedCPU, QuantizedCUDA, MkldnnCPU, BackendSelect, Named, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradNestedTensor, UNKNOWN_TENSOR_TYPE_ID, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, Autocast, Batched, VmapMode].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:5925 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:7100 [kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:641 [kernel]\nQuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCUDA.cpp:181 [kernel]\nMkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterMkldnnCPU.cpp:284 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:10706 [kernel]\nAutocast: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:250 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/BatchingRegistrations.cpp:1020 [kernel]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(task\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m)\n\u001b[1;32m     14\u001b[0m solver \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mEngine(task, train_set, valid_set, test_set, optimizer,\n\u001b[1;32m     15\u001b[0m                      gpus\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m solver\u001b[39m.\u001b[39;49mtrain(num_epoch\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     17\u001b[0m solver\u001b[39m.\u001b[39mevaluate(\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/core/engine.py:155\u001b[0m, in \u001b[0;36mEngine.train\u001b[0;34m(self, num_epoch, batch_per_epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    153\u001b[0m     batch \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mcuda(batch, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 155\u001b[0m loss, metric \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m loss\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    157\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLoss doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt require grad. Did you define any loss in the task?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/tasks/property_prediction.py:279\u001b[0m, in \u001b[0;36mMultipleBinaryClassification.forward\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    276\u001b[0m all_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m0\u001b[39m, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    277\u001b[0m metric \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 279\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(batch, all_loss, metric)\n\u001b[1;32m    280\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget(batch)\n\u001b[1;32m    282\u001b[0m \u001b[39mfor\u001b[39;00m criterion, weight \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/tasks/property_prediction.py:300\u001b[0m, in \u001b[0;36mMultipleBinaryClassification.predict\u001b[0;34m(self, batch, all_loss, metric)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_construction_model:\n\u001b[1;32m    299\u001b[0m     graph \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgraph_construction_model(graph)\n\u001b[0;32m--> 300\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(graph, graph\u001b[39m.\u001b[39;49mnode_feature\u001b[39m.\u001b[39;49mfloat(), all_loss\u001b[39m=\u001b[39;49mall_loss, metric\u001b[39m=\u001b[39;49mmetric)\n\u001b[1;32m    301\u001b[0m pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp(output[\u001b[39m\"\u001b[39m\u001b[39mgraph_feature\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    302\u001b[0m \u001b[39mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/models/gearnet.py:95\u001b[0m, in \u001b[0;36mGeometryAwareRelationalGraphNeuralNetwork.forward\u001b[0;34m(self, graph, input, all_loss, metric)\u001b[0m\n\u001b[1;32m     92\u001b[0m     edge_input \u001b[39m=\u001b[39m line_graph\u001b[39m.\u001b[39mnode_feature\u001b[39m.\u001b[39mfloat()\n\u001b[1;32m     94\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers)):\n\u001b[0;32m---> 95\u001b[0m     hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[i](graph, layer_input)\n\u001b[1;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshort_cut \u001b[39mand\u001b[39;00m hidden\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m layer_input\u001b[39m.\u001b[39mshape:\n\u001b[1;32m     97\u001b[0m         hidden \u001b[39m=\u001b[39m hidden \u001b[39m+\u001b[39m layer_input\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m itertools\u001b[39m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[39m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, result)\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/layers/conv.py:91\u001b[0m, in \u001b[0;36mMessagePassingBase.forward\u001b[0;34m(self, graph, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     update \u001b[39m=\u001b[39m checkpoint\u001b[39m.\u001b[39mcheckpoint(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_and_aggregate, \u001b[39m*\u001b[39mgraph\u001b[39m.\u001b[39mto_tensors(), \u001b[39minput\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     update \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage_and_aggregate(graph, \u001b[39minput\u001b[39;49m)\n\u001b[1;32m     92\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcombine(\u001b[39minput\u001b[39m, update)\n\u001b[1;32m     93\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/data/project/aigenintern/aigenintern2/miniconda3/envs/jc/lib/python3.9/site-packages/torchdrug/layers/conv.py:813\u001b[0m, in \u001b[0;36mGeometricRelationalGraphConv.message_and_aggregate\u001b[0;34m(self, graph, input)\u001b[0m\n\u001b[1;32m    809\u001b[0m     edge_update \u001b[39m=\u001b[39m scatter_add(edge_input \u001b[39m*\u001b[39m edge_weight, node_out, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    810\u001b[0m                               dim_size\u001b[39m=\u001b[39mgraph\u001b[39m.\u001b[39mnum_node \u001b[39m*\u001b[39m graph\u001b[39m.\u001b[39mnum_relation)\n\u001b[1;32m    811\u001b[0m     update \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m edge_update\n\u001b[0;32m--> 813\u001b[0m \u001b[39mreturn\u001b[39;00m update\u001b[39m.\u001b[39;49mview(graph\u001b[39m.\u001b[39;49mnum_node, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_relation \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_dim)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not run 'aten::view' with arguments from the 'SparseCPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::view' is only available for these backends: [CPU, CUDA, QuantizedCPU, QuantizedCUDA, MkldnnCPU, BackendSelect, Named, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradNestedTensor, UNKNOWN_TENSOR_TYPE_ID, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, Autocast, Batched, VmapMode].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:5925 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:7100 [kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:641 [kernel]\nQuantizedCUDA: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCUDA.cpp:181 [kernel]\nMkldnnCPU: registered at /pytorch/build/aten/src/ATen/RegisterMkldnnCPU.cpp:284 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_3.cpp:10140 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_3.cpp:10706 [kernel]\nAutocast: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:250 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/BatchingRegistrations.cpp:1020 [kernel]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import tasks, core, layers\n",
    "from torchdrug.layers import geometry\n",
    "import torch\n",
    "graph_construction_model = layers.GraphConstruction(node_layers=[geometry.AlphaCarbonNode()],\n",
    "                                                    edge_layers=[geometry.SpatialEdge(radius=10.0, min_distance=5),\n",
    "                                                                 geometry.KNNEdge(\n",
    "                                                                     k=10, min_distance=5),\n",
    "                                                                 geometry.SequentialEdge(max_distance=2)],\n",
    "                                                    edge_feature=\"residue_type\")\n",
    "task = tasks.MultipleBinaryClassification(gearnet, graph_construction_model=graph_construction_model, num_mlp_layer=3,\n",
    "                                          task=[_ for _ in range(len(dataset.tasks))], criterion=\"bce\", metric=[\"auprc@micro\", \"f1_max\"])\n",
    "\n",
    "optimizer = torch.optim.Adam(task.parameters(), lr=1e-4)\n",
    "solver = core.Engine(task, train_set, valid_set, test_set, optimizer,\n",
    "                     gpus=None, batch_size=1)\n",
    "solver.train(num_epoch=1)\n",
    "solver.evaluate(\"valid\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jc",
   "language": "python",
   "name": "jc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
