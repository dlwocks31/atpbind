{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/project/aigenintern/aigenintern3/miniconda3/envs/wonconda/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import transforms\n",
    "from torchdrug import data, core, layers, tasks, metrics, utils, models\n",
    "from torchdrug.layers import functional\n",
    "from torchdrug.core import Registry as R\n",
    "\n",
    "import torch\n",
    "from torch.utils import data as torch_data\n",
    "from torch.nn import functional as F\n",
    "from lib.tasks import NodePropertyPrediction\n",
    "from lib.datasets import ATPBind\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "truncuate_transform = transforms.TruncateProtein(max_length=350, random=False)\n",
    "protein_view_transform = transforms.ProteinView(view='residue')\n",
    "transform = transforms.Compose([truncuate_transform, protein_view_transform])\n",
    "\n",
    "\n",
    "def _freeze_bert(\n",
    "    bert_model: BertModel, freeze_bert=True, freeze_layer_count=-1\n",
    "):\n",
    "    \"\"\"Freeze parameters in BertModel (in place)\n",
    "\n",
    "    Args:\n",
    "        bert_model: HuggingFace bert model\n",
    "        freeze_bert: Bool whether or not to freeze the bert model\n",
    "        freeze_layer_count: If freeze_bert, up to what layer to freeze.\n",
    "\n",
    "    Returns:\n",
    "        bert_model\n",
    "    \"\"\"\n",
    "    if freeze_bert:\n",
    "        # freeze the entire bert model\n",
    "        for param in bert_model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        # freeze the embeddings\n",
    "        for param in bert_model.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "        if freeze_layer_count != -1:\n",
    "            # freeze layers in bert_model.encoder\n",
    "            for layer in bert_model.encoder.layer[:freeze_layer_count]:\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "    return None\n",
    "\n",
    "# Cusom model Wrapping BERT: check https://torchdrug.ai/docs/notes/model.html\n",
    "\n",
    "\n",
    "class BertWrapModel(torch.nn.Module, core.Configurable):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(\n",
    "            \"Rostlab/prot_bert\", do_lower_case=False)\n",
    "        self.bert_model = BertModel.from_pretrained(\n",
    "            \"Rostlab/prot_bert\").to('cuda')\n",
    "        _freeze_bert(self.bert_model, freeze_bert=True, freeze_layer_count=-1)\n",
    "        self.input_dim = 21\n",
    "        self.output_dim = self.bert_model.config.hidden_size\n",
    "\n",
    "    def forward(self, graph, _, all_loss=None, metric=None):\n",
    "        # print(\"graph: \", graph)\n",
    "        # print(\"sequence: \", graph.to_sequence())\n",
    "        input = [seq.replace('.', ' ') for seq in graph.to_sequence()]\n",
    "\n",
    "        encoded_input = self.bert_tokenizer(\n",
    "            input, return_tensors='pt').to('cuda')\n",
    "        # print(\"Input size: \", encoded_input[\"input_ids\"].size())\n",
    "        x = self.bert_model(**encoded_input)\n",
    "        # print(\"Output size just after model: \", x.last_hidden_state.size())\n",
    "\n",
    "        # skip residue feature for [CLS] and [SEP], since they are not in the original sequence\n",
    "        return {\"residue_feature\": torch.squeeze(x.last_hidden_state)[1:-1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid ratio: 0.100000\n",
      "Split num:  [346, 42, 41]\n",
      "train samples: 346, valid samples: 42, test samples: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:09:49   Preprocess training set\n",
      "03:09:49   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100000,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'NodePropertyPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('micro_auroc',\n",
      "                     'micro_auprc',\n",
      "                     'macro_auprc',\n",
      "                     'macro_auroc'),\n",
      "          'model': {'class': 'BertWrapModel'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'ATPBind',\n",
      "                          'path': None,\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                          'valid_ratio': 0.1,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(388, 429)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.1,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 346)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.1,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(346, 388)}}\n",
      "03:09:49   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:09:49   Epoch 0 begin\n",
      "03:09:49   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:09:49   binary cross entropy: 0.69777\n",
      "03:10:12   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:10:12   Epoch 0 end\n",
      "03:10:12   duration: 22.73 secs\n",
      "03:10:12   speed: 15.22 batch / sec\n",
      "03:10:12   ETA: 0.00 secs\n",
      "03:10:12   max GPU memory: 3381.7 MiB\n",
      "03:10:12   ------------------------------\n",
      "03:10:12   average binary cross entropy: 0.17808\n",
      "03:10:12   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:10:12   Evaluate on test\n",
      "03:10:14   ------------------------------\n",
      "03:10:14   macro_auprc: 0.441783\n",
      "03:10:14   macro_auroc: 0.828679\n",
      "03:10:14   micro_auprc: 0.384185\n",
      "03:10:14   micro_auroc: 0.844592\n",
      "valid ratio: 0.200000\n",
      "Split num:  [303, 85, 41]\n",
      "train samples: 303, valid samples: 85, test samples: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:10:26   Preprocess training set\n",
      "03:10:26   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100000,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'NodePropertyPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('micro_auroc',\n",
      "                     'micro_auprc',\n",
      "                     'macro_auprc',\n",
      "                     'macro_auroc'),\n",
      "          'model': {'class': 'BertWrapModel'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'ATPBind',\n",
      "                          'path': None,\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                          'valid_ratio': 0.2,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(388, 429)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.2,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 303)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.2,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(303, 388)}}\n",
      "03:10:26   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:10:26   Epoch 0 begin\n",
      "03:10:26   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:10:26   binary cross entropy: 0.684927\n",
      "03:10:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:10:47   Epoch 0 end\n",
      "03:10:47   duration: 20.97 secs\n",
      "03:10:47   speed: 14.45 batch / sec\n",
      "03:10:47   ETA: 0.00 secs\n",
      "03:10:47   max GPU memory: 3381.7 MiB\n",
      "03:10:47   ------------------------------\n",
      "03:10:47   average binary cross entropy: 0.177703\n",
      "03:10:47   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:10:47   Evaluate on test\n",
      "03:10:49   ------------------------------\n",
      "03:10:49   macro_auprc: 0.416974\n",
      "03:10:49   macro_auroc: 0.816737\n",
      "03:10:49   micro_auprc: 0.367892\n",
      "03:10:49   micro_auroc: 0.835452\n",
      "valid ratio: 0.300000\n",
      "Split num:  [260, 128, 41]\n",
      "train samples: 260, valid samples: 128, test samples: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:11:00   Preprocess training set\n",
      "03:11:00   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100000,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'NodePropertyPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('micro_auroc',\n",
      "                     'micro_auprc',\n",
      "                     'macro_auprc',\n",
      "                     'macro_auroc'),\n",
      "          'model': {'class': 'BertWrapModel'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'ATPBind',\n",
      "                          'path': None,\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                          'valid_ratio': 0.30000000000000004,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(388, 429)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.30000000000000004,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 260)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.30000000000000004,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(260, 388)}}\n",
      "03:11:00   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:11:00   Epoch 0 begin\n",
      "03:11:00   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:11:00   binary cross entropy: 0.684111\n",
      "03:11:18   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:11:18   Epoch 0 end\n",
      "03:11:18   duration: 17.50 secs\n",
      "03:11:18   speed: 14.86 batch / sec\n",
      "03:11:18   ETA: 0.00 secs\n",
      "03:11:18   max GPU memory: 3381.8 MiB\n",
      "03:11:18   ------------------------------\n",
      "03:11:18   average binary cross entropy: 0.182184\n",
      "03:11:18   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:11:18   Evaluate on test\n",
      "03:11:20   ------------------------------\n",
      "03:11:20   macro_auprc: 0.406637\n",
      "03:11:20   macro_auroc: 0.815339\n",
      "03:11:20   micro_auprc: 0.343018\n",
      "03:11:20   micro_auroc: 0.826614\n",
      "valid ratio: 0.400000\n",
      "Split num:  [217, 171, 41]\n",
      "train samples: 217, valid samples: 171, test samples: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:11:32   Preprocess training set\n",
      "03:11:32   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100000,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'NodePropertyPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('micro_auroc',\n",
      "                     'micro_auprc',\n",
      "                     'macro_auprc',\n",
      "                     'macro_auroc'),\n",
      "          'model': {'class': 'BertWrapModel'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'ATPBind',\n",
      "                          'path': None,\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                          'valid_ratio': 0.4,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(388, 429)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.4,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 217)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.4,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(217, 388)}}\n",
      "03:11:32   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:11:32   Epoch 0 begin\n",
      "03:11:32   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:11:32   binary cross entropy: 0.698781\n",
      "03:11:46   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:11:46   Epoch 0 end\n",
      "03:11:46   duration: 14.50 secs\n",
      "03:11:46   speed: 14.96 batch / sec\n",
      "03:11:46   ETA: 0.00 secs\n",
      "03:11:46   max GPU memory: 3381.9 MiB\n",
      "03:11:46   ------------------------------\n",
      "03:11:46   average binary cross entropy: 0.186712\n",
      "03:11:46   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:11:46   Evaluate on test\n",
      "03:11:49   ------------------------------\n",
      "03:11:49   macro_auprc: 0.427694\n",
      "03:11:49   macro_auroc: 0.825277\n",
      "03:11:49   micro_auprc: 0.37454\n",
      "03:11:49   micro_auroc: 0.842962\n",
      "valid ratio: 0.500000\n",
      "Split num:  [174, 214, 41]\n",
      "train samples: 174, valid samples: 214, test samples: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:12:01   Preprocess training set\n",
      "03:12:01   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100000,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'NodePropertyPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('micro_auroc',\n",
      "                     'micro_auprc',\n",
      "                     'macro_auprc',\n",
      "                     'macro_auroc'),\n",
      "          'model': {'class': 'BertWrapModel'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'ATPBind',\n",
      "                          'path': None,\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                          'valid_ratio': 0.5,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(388, 429)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.5,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 174)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.5,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(174, 388)}}\n",
      "03:12:01   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:01   Epoch 0 begin\n",
      "03:12:01   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:01   binary cross entropy: 0.686949\n",
      "03:12:13   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:13   Epoch 0 end\n",
      "03:12:13   duration: 12.00 secs\n",
      "03:12:13   speed: 14.50 batch / sec\n",
      "03:12:13   ETA: 0.00 secs\n",
      "03:12:13   max GPU memory: 3381.8 MiB\n",
      "03:12:13   ------------------------------\n",
      "03:12:13   average binary cross entropy: 0.19919\n",
      "03:12:13   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:13   Evaluate on test\n",
      "03:12:15   ------------------------------\n",
      "03:12:15   macro_auprc: 0.411673\n",
      "03:12:15   macro_auroc: 0.813283\n",
      "03:12:15   micro_auprc: 0.354664\n",
      "03:12:15   micro_auroc: 0.82682\n",
      "valid ratio: 0.600000\n",
      "Split num:  [131, 257, 41]\n",
      "train samples: 131, valid samples: 257, test samples: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:12:28   Preprocess training set\n",
      "03:12:28   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100000,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'NodePropertyPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('micro_auroc',\n",
      "                     'micro_auprc',\n",
      "                     'macro_auprc',\n",
      "                     'macro_auroc'),\n",
      "          'model': {'class': 'BertWrapModel'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'ATPBind',\n",
      "                          'path': None,\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                          'valid_ratio': 0.6000000000000001,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(388, 429)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.6000000000000001,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 131)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.6000000000000001,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(131, 388)}}\n",
      "03:12:28   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:28   Epoch 0 begin\n",
      "03:12:28   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:28   binary cross entropy: 0.679375\n",
      "03:12:37   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:37   Epoch 0 end\n",
      "03:12:37   duration: 8.73 secs\n",
      "03:12:37   speed: 15.01 batch / sec\n",
      "03:12:37   ETA: 0.00 secs\n",
      "03:12:37   max GPU memory: 3381.8 MiB\n",
      "03:12:37   ------------------------------\n",
      "03:12:37   average binary cross entropy: 0.203527\n",
      "03:12:37   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:37   Evaluate on test\n",
      "03:12:39   ------------------------------\n",
      "03:12:39   macro_auprc: 0.404429\n",
      "03:12:39   macro_auroc: 0.814768\n",
      "03:12:39   micro_auprc: 0.325204\n",
      "03:12:39   micro_auroc: 0.818191\n",
      "valid ratio: 0.700000\n",
      "Split num:  [88, 300, 41]\n",
      "train samples: 88, valid samples: 300, test samples: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:12:51   Preprocess training set\n",
      "03:12:51   {'batch_size': 1,\n",
      " 'class': 'core.Engine',\n",
      " 'gpus': [0],\n",
      " 'gradient_interval': 1,\n",
      " 'log_interval': 100000,\n",
      " 'logger': 'logging',\n",
      " 'num_worker': 0,\n",
      " 'optimizer': {'amsgrad': False,\n",
      "               'betas': (0.9, 0.999),\n",
      "               'class': 'optim.Adam',\n",
      "               'eps': 1e-08,\n",
      "               'lr': 0.001,\n",
      "               'weight_decay': 0},\n",
      " 'scheduler': None,\n",
      " 'task': {'class': 'NodePropertyPrediction',\n",
      "          'criterion': 'bce',\n",
      "          'graph_construction_model': None,\n",
      "          'metric': ('micro_auroc',\n",
      "                     'micro_auprc',\n",
      "                     'macro_auprc',\n",
      "                     'macro_auroc'),\n",
      "          'model': {'class': 'BertWrapModel'},\n",
      "          'normalization': False,\n",
      "          'num_class': None,\n",
      "          'num_mlp_layer': 2,\n",
      "          'verbose': 0},\n",
      " 'test_set': {'class': 'dataset.Subset',\n",
      "              'dataset': {'atom_feature': None,\n",
      "                          'bond_feature': None,\n",
      "                          'class': 'ATPBind',\n",
      "                          'path': None,\n",
      "                          'residue_feature': 'default',\n",
      "                          'transform': {'class': 'transforms.Compose',\n",
      "                                        'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                       <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                          'valid_ratio': 0.7000000000000001,\n",
      "                          'verbose': 1},\n",
      "              'indices': range(388, 429)},\n",
      " 'train_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.7000000000000001,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(0, 88)},\n",
      " 'valid_set': {'class': 'dataset.Subset',\n",
      "               'dataset': {'atom_feature': None,\n",
      "                           'bond_feature': None,\n",
      "                           'class': 'ATPBind',\n",
      "                           'path': None,\n",
      "                           'residue_feature': 'default',\n",
      "                           'transform': {'class': 'transforms.Compose',\n",
      "                                         'transforms': [<torchdrug.transforms.transform.TruncateProtein object at 0x7f2571aa32e0>,\n",
      "                                                        <torchdrug.transforms.transform.ProteinView object at 0x7f24fc5ccfa0>]},\n",
      "                           'valid_ratio': 0.7000000000000001,\n",
      "                           'verbose': 1},\n",
      "               'indices': range(88, 388)}}\n",
      "03:12:51   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:51   Epoch 0 begin\n",
      "03:12:51   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:51   binary cross entropy: 0.684982\n",
      "03:12:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:57   Epoch 0 end\n",
      "03:12:57   duration: 5.91 secs\n",
      "03:12:57   speed: 14.88 batch / sec\n",
      "03:12:57   ETA: 0.00 secs\n",
      "03:12:57   max GPU memory: 3381.8 MiB\n",
      "03:12:57   ------------------------------\n",
      "03:12:57   average binary cross entropy: 0.225751\n",
      "03:12:57   >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "03:12:57   Evaluate on test\n",
      "03:13:00   ------------------------------\n",
      "03:13:00   macro_auprc: 0.365308\n",
      "03:13:00   macro_auroc: 0.794331\n",
      "03:13:00   micro_auprc: 0.295544\n",
      "03:13:00   micro_auroc: 0.800286\n",
      "valid ratio: 0.800000\n",
      "Split num:  [45, 343, 41]\n",
      "train samples: 45, valid samples: 343, test samples: 41\n"
     ]
    }
   ],
   "source": [
    "import logging \n",
    "\n",
    "class DisableLogger():\n",
    "    def __enter__(self):\n",
    "       logging.disable(logging.CRITICAL)\n",
    "    def __exit__(self, exit_type, exit_value, exit_traceback):\n",
    "       logging.disable(logging.NOTSET)\n",
    "    \n",
    "logging.basicConfig(level='error')\n",
    "ls = []\n",
    "\n",
    "\n",
    "for i in range(1, 9):\n",
    "#     with DisableLogger():\n",
    "        valid_ratio = 0.1 * i\n",
    "        print(\"valid ratio: %f\" % valid_ratio)\n",
    "        dataset = ATPBind(valid_ratio = valid_ratio, atom_feature=None, bond_feature=None,\n",
    "                          residue_feature=\"default\", transform=transform)\n",
    "        train_set, valid_set, test_set = dataset.split()\n",
    "        print(\"train samples: %d, valid samples: %d, test samples: %d\" %\n",
    "              (len(train_set), len(valid_set), len(test_set)))\n",
    "\n",
    "        bert_wrap_model = BertWrapModel()\n",
    "        bert_task = NodePropertyPrediction(\n",
    "            bert_wrap_model, \n",
    "            normalization=False,\n",
    "            num_mlp_layer=2,\n",
    "            metric=(\"micro_auroc\", \"micro_auprc\", \"macro_auprc\", \"macro_auroc\")\n",
    "        )\n",
    "        optimizer = torch.optim.Adam(bert_task.parameters(), lr=1e-3)\n",
    "        solver = core.Engine(bert_task, train_set, valid_set, test_set, optimizer, batch_size=1, log_interval=100000, gpus=[0])\n",
    "        solver.train(num_epoch=1)\n",
    "        res = solver.evaluate(\"test\")\n",
    "#         print(f\"valid ratio: {valid_ratio}, auroc = {res['micro_auroc']}, bce = {res['average_binary_cross_entropy']}\")\n",
    "        ls.append(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bce is captured from standard output of the previous cell\n",
    "bce = [0.177868, 0.696411, 0.695101, 0.689387, 0.692833, 0.700273, 0.708808, 0.713516]\n",
    "auroc = [i['micro_auroc'].item() for i in ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Create an array for the x-axis representing the index of each element in the arrays\n",
    "# x = np.arange(len(bce))\n",
    "x = [0.8, 0.7,0.6,0.5,0.4,0.3,0.2,0.1]\n",
    "# x = [.1, .2, .3, .4, .5, .6, .7, .8]\n",
    "# x = np.arange(len(auroc))\n",
    "\n",
    "# Plot the lines for bce and auroc\n",
    "plt.plot(x, bce, label='Loss on training data (BCE)', marker='o')\n",
    "plt.plot(x, auroc, label='AUROC on test data', marker='o')\n",
    "\n",
    "# Set up the labels and title for the chart\n",
    "plt.xlabel('Proportion of Training data of all data')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Training Loss and AUROC changes on test set size')\n",
    "\n",
    "# Add a legend to indicate which line represents which array\n",
    "plt.legend()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wonconda",
   "language": "python",
   "name": "wonconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
